
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>29. Image classification &#8212; An interactive and visual Machine Learning book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/drawio.css" />
    <link rel="stylesheet" type="text/css" href="../_static/youtube.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "ocademy-ai/machine-learning-utterances");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "üí¨ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"></script>
    <script>quizdown.init({"quizdown_js": "https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"});</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="30. Image segmentation" href="image-segmentation.html" />
    <link rel="prev" title="28. Summary of deep learning (TBD)" href="dl-summary.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo-long.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">An interactive and visual Machine Learning book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PREREQUISITES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../prerequisites/python-programming-introduction.html">
   1. Python programming introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../prerequisites/python-programming-basics.html">
   2. Python programming basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../prerequisites/python-programming-advanced.html">
   3. Python programming advanced
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATA SCIENCE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science/introduction/introduction.html">
   4. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/introduction/defining-data-science.html">
     4.1. Defining data science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/introduction/data-science-ethics.html">
     4.2. Data Science ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/introduction/defining-data.html">
     4.3. Defining data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/introduction/introduction-to-statistics-and-probability.html">
     4.4. Introduction to statistics and probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science/working-with-data/working-with-data.html">
   5. Working with data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/working-with-data/relational-databases.html">
     5.1. Relational databases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/working-with-data/non-relational-data.html">
     5.2. Non-relational data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/working-with-data/numpy.html">
     5.3. NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/working-with-data/pandas.html">
     5.4. Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/working-with-data/data-preparation.html">
     5.5. Data preparation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science/data-visualization/data-visualization.html">
   6. Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-visualization/visualization-distributions.html">
     6.1. Visualizing distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-visualization/visualization-proportions.html">
     6.2. Visualizing proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-visualization/visualization-relationships.html">
     6.3. Visualizing relationships: all about honey üçØ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-visualization/meaningful-visualizations.html">
     6.4. Making meaningful visualizations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science/data-science-lifecycle/data-science-lifecycle.html">
   7. Data Science lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-lifecycle/introduction.html">
     7.1. Introduction to the Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-lifecycle/analyzing.html">
     7.2. Analyzing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-lifecycle/communication.html">
     7.3. Communication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science/data-science-in-the-cloud/data-science-in-the-cloud.html">
   8. Data Science in the cloud
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-in-the-cloud/introduction.html">
     8.1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-in-the-cloud/the-low-code-no-code-way.html">
     8.2. The ‚Äúlow code/no code‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-in-the-cloud/the-azure-ml-sdk-way.html">
     8.3. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-science/data-science-in-the-wild.html">
   9. Data Science in the real world
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING BASICS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ml-fundamentals/ml-overview.html">
   10. Machine Learning overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml-fundamentals/regression/regression-models-for-machine-learning.html">
   11. Regression models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/regression/tools-of-the-trade.html">
     11.1. Tools of the trade
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/regression/managing-data.html">
     11.2. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/regression/linear-and-polynomial-regression.html">
     11.3. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/regression/logistic-regression.html">
     11.4. Logistic regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml-fundamentals/build-a-web-app-to-use-a-machine-learning-model.html">
   12. Build a web app to use a Machine Learning model
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml-fundamentals/classification/getting-started-with-classification.html">
   13. Getting started with classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/classification/introduction-to-classification.html">
     13.1. Introduction to classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/classification/more-classifiers.html">
     13.2. More classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/classification/yet-other-classifiers.html">
     13.3. Yet other classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/classification/applied-ml-build-a-web-app.html">
     13.4. Applied Machine Learning : build a web app
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ADVANCED MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml-advanced/clustering/clustering-models-for-machine-learning.html">
   14. Clustering models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/clustering/introduction-to-clustering.html">
     14.1. Introduction to clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/clustering/k-means-clustering.html">
     14.2. K-Means clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml-advanced/ensemble-learning/getting-started-with-ensemble-learning.html">
   15. Getting started with ensemble learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/ensemble-learning/bagging.html">
     15.1. Bagging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/ensemble-learning/random-forest.html">
     15.2. Random forest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/ensemble-learning/feature-importance.html">
     15.3. Feature importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml-advanced/gradient-boosting/introduction-to-gradient-boosting.html">
   16. Introduction to Gradient Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/gradient-boosting/gradient-boosting.html">
     16.1. Gradient Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/gradient-boosting/gradient-boosting-example.html">
     16.2. Gradient boosting example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/gradient-boosting/xgboost.html">
     16.3. XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/gradient-boosting/xgboost-k-fold-cv-feature-importance.html">
     16.4. XGBoost + k-fold CV + Feature Importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml-advanced/unsupervised-learning.html">
   17. Unsupervised learning (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml-advanced/kernel-method.html">
   18. Kernel method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml-advanced/model-selection.html">
   19. Model selection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="dl-overview.html">
   20. Deep learning overview (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cnn.html">
   21. Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gan.html">
   22. Generative adversarial networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rnn.html">
   23. Recurrent Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="autoencoder.html">
   24. Autoencoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lstm.html">
   25. Long-short term memory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="time-series.html">
   26. Time series
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dqn.html">
   27. Deep Q-learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dl-summary.html">
   28. Summary of deep learning (TBD)
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   29. Image classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="image-segmentation.html">
   30. Image segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="difussion-model.html">
   31. Diffusion Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="object-detection.html">
   32. Object detection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING OPERATIONS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../machine-learning-productionization/overview.html">
   33. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../machine-learning-productionization/problem-framing.html">
   34. Problem framing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../machine-learning-productionization/data-engineering.html">
   35. Data engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../machine-learning-productionization/model-training-and-evaluation.html">
   36. Model training &amp; evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../machine-learning-productionization/model-deployment.html">
   37. Model deployment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  SUPPORTING MATERIALS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../supporting-materials/unbalanced-problems.html">
   38. Unbalanced problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../supporting-materials/automl.html">
   39. AutoML (TBD)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OTHERS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../assignments/README.html">
   40. Self-paced assignments
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/set-up-env/first-assignment.html">
     40.3. First assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/set-up-env/second-assignment.html">
     40.4. Second assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/project-plan-template.html">
     40.5. Project Plan‚Äã Template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/prerequisites/python-programming-introduction.html">
     40.6. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/prerequisites/python-programming-basics.html">
     40.7. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/prerequisites/python-programming-advanced.html">
     40.8. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/analyzing-text-about-data-science.html">
     40.9. Analyzing text about Data Science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/data-science-scenarios.html">
     40.10. Data Science scenarios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/write-a-data-ethics-case-study.html">
     40.11. Write a data ethics case study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/lines-scatters-and-bars.html">
     40.12. Lines, scatters and bars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/apply-your-skills.html">
     40.13. Apply your skills
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/try-it-in-excel.html">
     40.14. Try it in Excel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/dive-into-the-beehive.html">
     40.15. Dive into the beehive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/build-your-own-custom-vis.html">
     40.16. Build your own custom vis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/classifying-datasets.html">
     40.17. Classifying datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/small-diabetes-study.html">
     40.18. Small diabetes study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/introduction-to-statistics-and-probability.html">
     40.19. Introduction to probability and statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/displaying-airport-data.html">
     40.20. Displaying airport data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/soda-profits.html">
     40.21. Soda profits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/analyzing-COVID-19-papers.html">
     40.22. Analyzing COVID-19 papers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/estimation-of-COVID-19-pandemic.html">
     40.23. Estimation of COVID-19 pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/data-processing-in-python.html">
     40.24. Data processing in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/evaluating-data-from-a-form.html">
     40.25. Evaluating data from a form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/data-preparation.html">
     40.26. Data preparation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/analyzing-data.html">
     40.27. Analyzing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/nyc-taxi-data-in-winter-and-summer.html">
     40.28. NYC taxi data in winter and summer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/matplotlib-applied.html">
     40.29. Matplotlib applied
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/tell-a-story.html">
     40.35. Tell a story
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/explore-a-planetary-computer-dataset.html">
     40.36. Explore a planetary computer dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/exploring-for-anwser.html">
     40.37. Exploring for answers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/market-research.html">
     40.38. Market research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/low-code-no-code-data-science-project-on-azure-ml.html">
     40.39. Low code/no code Data Science project on Azure ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/data-science-project-using-azure-ml-sdk.html">
     40.40. Data Science project using Azure ML SDK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/data-science-in-the-cloud-the-azure-ml-sdk-way.html">
     40.41. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-overview-iris.html">
     40.42. Machine Learning overview - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-overview-mnist-digits.html">
     40.43. Machine Learning overview - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/regression-with-scikit-learn.html">
     40.44. Regression with Scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-linear-regression-1.html">
     40.45. ML linear regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-linear-regression-2.html">
     40.46. ML linear regression - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-logistic-regression-1.html">
     40.47. ML logistic regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-neural-network-1.html">
     40.48. ML neural network - Assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/regression-tools.html">
     40.49. Regression tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/managing-data.html">
     40.50. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/exploring-visualizations.html">
     40.51. Exploring visualizations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/try-a-different-model.html">
     40.52. Try a different model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/create-a-regression-model.html">
     40.53. Create a regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/linear-and-polynomial-regression.html">
     40.54. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/retrying-some-regression.html">
     40.55. Retrying some regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/pumpkin-varieties-and-color.html">
     40.56. Pumpkin varieties and color
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/delicious-asian-and-indian-cuisines.html">
     40.57. Delicious asian and indian cuisines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/explore-classification-methods.html">
     40.58. Explore classification methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/kernel-method/kernel-method-assignment-1.html">
     40.59. Kernel method assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/kernel-method/support_vector_machines_for_regression.html">
     40.60. Support Vector Machines (SVM) - Intro and SVM for Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/kernel-method/support_vector_machines_for_classification.html">
     40.61. Support Vector Machines (SVM) - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/kernel-method/decision_trees_for_regression.html">
     40.62. Decision Trees - Intro and Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/kernel-method/decision_trees_for_classification.html">
     40.63. Decision Trees - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/model-selection/model-selection-assignment-1.html">
     40.64. Model selection assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/model-selection/learning-curve-to-identify-overfit-underfit.html">
     40.65. Learning Curve To Identify Overfit &amp; Underfit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/model-selection/dropout-and-batch-normalization.html">
     40.66. Dropout and Batch Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/model-selection/lasso-and-ridge-regression.html">
     40.67. Lasso and Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/model-selection/regularized-linear-models.html">
     40.68. Regularized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/ensemble-learning/random-forests-intro-and-regression.html">
     40.69. Random forests intro and regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/ensemble-learning/random-forests-for-classification.html">
     40.70. Random forests for classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.html">
     40.71. Beyond random forests: more ensemble models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/ensemble-learning/decision-trees.html">
     40.72. Decision trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/gradient-boosting/hyperparameter-tuning-gradient-boosting.html">
     40.73. Hyperparameter tuning gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/machine-learning-productionization/data-engineering.html">
     40.74. Data engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/machine-learning-productionization/counterintuitive-challenges-in-ml-debugging.html">
     40.75. Counterintuitive Challenges in ML Debugging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/machine-learning-productionization/debugging-in-classification.html">
     40.76. Case Study: Debugging in Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/machine-learning-productionization/debugging-in-regression.html">
     40.77. Case Study: Debugging in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/study-the-solvers.html">
     40.78. Study the solvers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/build-classification-models.html">
     40.79. Build classification models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/build-classification-model.html">
     40.80. Build Classification Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/parameter-play.html">
     40.81. Parameter play
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/cnn/how-to-choose-cnn-architecture-mnist.html">
     40.82. How to choose cnn architecture mnist
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/cnn/sign-language-digits-classification-with-cnn.html">
     40.84. Sign Language Digits Classification with CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/cnn/object-recognition-in-images-using-cnn.html">
     40.86. Object Recognition in Images using CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/tensorflow/intro_to_tensorflow_for_deeplearning.html">
     40.87. Intro to TensorFlow for Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/lstm/bitcoin-lstm-model-with-tweet-volume-and-sentiment.html">
     40.89. Bitcoin LSTM Model with Tweet Volume and Sentiment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/rnn/google-stock-price-prediction-rnn.html">
     40.91. Google Stock Price Prediction RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/autoencoder/autoencoder.html">
     40.93. Intro to Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/autoencoder/base-denoising-autoencoder-dimension-reduction.html">
     40.94. Base/Denoising Autoencoder &amp; Dimension Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/autoencoder/variational-autoencoder-and-faces-generation.html">
     40.95. Fun with Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/time-series-forecasting-assignment.html">
     40.96. Time Series Forecasting Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/nn-for-classification-assignment.html">
     40.98. Neural Networks for Classification with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/nn-classify-15-fruits-assignment.html">
     40.99. NN Classify 15 Fruits Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/dqn/dqn-on-foreign-exchange-market.html">
     40.104. DQN On Foreign Exchange Market
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/gan/art-by-gan.html">
     40.105. Art by gan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/gan/gan-introduction.html">
     40.107. Generative Adversarial Networks (GANs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/overview/basic-classification-classify-images-of-clothing.html">
     40.108. Basic classification: Classify images of clothing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../slides/introduction.html">
   41. Slides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/python-programming/python-programming-introduction.html">
     41.1. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/python-programming/python-programming-basics.html">
     41.2. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/python-programming/python-programming-advanced.html">
     41.3. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/data-science-introduction.html">
     41.4. Data Science introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/relational-vs-non-relational-database.html">
     41.5. Relational vs. non-relational database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/numpy-and-pandas.html">
     41.6. NumPy and Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/data-visualization.html">
     41.7. Data visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/data-science-lifecycle.html">
     41.8. Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/data-science-in-the-cloud.html">
     41.9. Data Science in the cloud
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/data-science-in-real-world.html">
     41.10. Data Science in real world
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-fundamentals/ml-overview.html">
     41.11. Machine Learning overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-fundamentals/linear-regression.html">
     41.12. Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-fundamentals/logistic-regression.html">
     41.13. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-fundamentals/neural-network.html">
     41.14. Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-fundamentals/build-an-ml-web-app.html">
     41.15. Build an machine learning web application
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-advanced/unsupervised-learning.html">
     41.16. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-advanced/kernel-method.html">
     41.17. Kernel method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-advanced/model-selection.html">
     41.18. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/deep-learning/cnn.html">
     41.19. Convolutional Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/deep-learning/gan.html">
     41.20. Generative Adversarial Network
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ocademy-ai/machine-learning/release?urlpath=lab/tree/open-machine-learning-jupyter-book/deep-learning/image-classification.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ocademy-ai/machine-learning/blob/release/open-machine-learning-jupyter-book/deep-learning/image-classification.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning//issues/new?title=Issue%20on%20page%20%2Fdeep-learning/image-classification.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/edit/release/open-machine-learning-jupyter-book/deep-learning/image-classification.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/deep-learning/image-classification.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="../_sources/deep-learning/image-classification.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-image-classification">
   29.1. What is image classification?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#challenges">
   29.2. Challenges
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pipeline-of-image-classification">
   29.3. Pipeline of image classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#history-classic-models">
   29.4. History &amp; classic models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vggnet">
     29.4.1. VGGNet
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#code">
       29.4.1.1. Code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#resnet">
     29.4.2. Resnet
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       29.4.2.1. Code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#densenet">
     29.4.3. DenseNet
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       29.4.3.1. Code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mobilenet">
     29.4.4. MobileNet
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       29.4.4.1. Code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vit">
     29.4.5. ViT
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id11">
       29.4.5.1. Code
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classic-datasets">
   29.5. Classic datasets
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cifar-10-100">
     29.5.1. CIFAR-10/100
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imagenet-1000">
     29.5.2. ImageNet-1000
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standards">
   29.6. Standards
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#top-1-accuracy">
     29.6.1. Top-1 accuracy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#top-5-accuracy">
     29.6.2. Top-5 accuracy
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-turn">
   29.7. Your turn! üöÄ
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   29.8. Acknowledgments
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Image classification</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-image-classification">
   29.1. What is image classification?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#challenges">
   29.2. Challenges
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pipeline-of-image-classification">
   29.3. Pipeline of image classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#history-classic-models">
   29.4. History &amp; classic models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vggnet">
     29.4.1. VGGNet
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#code">
       29.4.1.1. Code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#resnet">
     29.4.2. Resnet
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       29.4.2.1. Code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#densenet">
     29.4.3. DenseNet
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       29.4.3.1. Code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mobilenet">
     29.4.4. MobileNet
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       29.4.4.1. Code
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vit">
     29.4.5. ViT
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id11">
       29.4.5.1. Code
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classic-datasets">
   29.5. Classic datasets
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cifar-10-100">
     29.5.1. CIFAR-10/100
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imagenet-1000">
     29.5.2. ImageNet-1000
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standards">
   29.6. Standards
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#top-1-accuracy">
     29.6.1. Top-1 accuracy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#top-5-accuracy">
     29.6.2. Top-5 accuracy
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-turn">
   29.7. Your turn! üöÄ
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   29.8. Acknowledgments
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="image-classification">
<h1><span class="section-number">29. </span>Image classification<a class="headerlink" href="#image-classification" title="Permalink to this headline">#</a></h1>
<section id="what-is-image-classification">
<h2><span class="section-number">29.1. </span>What is image classification?<a class="headerlink" href="#what-is-image-classification" title="Permalink to this headline">#</a></h2>
<p>In this chapter we will introduce the image classification problem, which is the task of assigning an input image one label from a fixed set of categories. This is one of the core problems in Computer Vision that, despite its simplicity, has a large variety of practical applications.</p>
<p style="text-align: center;">
<iframe src="../assets/html/cls-demo/index.html" width="105%" height="700px;" style="border:none;"></iframe>
A demo of image classification. <a href="http://vision.stanford.edu/teaching/cs231n/">[source]</a>
</p>
<p>Let me give you an example. In the image below an image classification model takes a single image and assigns probabilities to 4 labels, {cat, dog, hat, mug}. As shown in the image, keep in mind that to a computer an image is represented as one large 3-dimensional array of numbers. In this example, the cat image is 248 pixels wide, 400 pixels tall, and has three color channels Red,Green,Blue (or RGB for short). Therefore, the image consists of 248 x 400 x 3 numbers, or a total of 297,600 numbers. Each number is an integer that ranges from 0 (black) to 255 (white). Our task is to turn this quarter of a million numbers into a single label, such as ‚Äúcat‚Äù.</p>
<figure class="align-default" id="example-of-cls">
<a class="bg-white mb-1 reference internal image-reference" href="../_images/01_classify_eg.png"><img alt="../_images/01_classify_eg.png" class="bg-white mb-1" src="../_images/01_classify_eg.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 29.1 </span><span class="caption-text">Example of the image classification task</span><a class="headerlink" href="#example-of-cls" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The task in image classification is to predict a single label (or a distribution over labels as shown here to indicate our confidence) for a given image. Images are 3-dimensional arrays of integers from 0 to 255, of size Width x Height x 3. The 3 represents the three color channels Red, Green, Blue.</p>
</section>
<section id="challenges">
<h2><span class="section-number">29.2. </span>Challenges<a class="headerlink" href="#challenges" title="Permalink to this headline">#</a></h2>
<p>Since this task of recognizing a visual concept (e.g. cat) is relatively trivial for a human to perform, it is worth considering the challenges involved from the perspective of a Computer Vision algorithm. As we present (an inexhaustive) list of challenges below, keep in mind the raw representation of images as a 3-D array of brightness values:</p>
<ul class="simple">
<li><p>Viewpoint variation. A single instance of an object can be oriented in many ways with respect to the camera.</p></li>
<li><p>Scale variation. Visual classes often exhibit variation in their size (size in the real world, not only in terms of their extent in the image).</p></li>
<li><p>Deformation. Many objects of interest are not rigid bodies and can be deformed in extreme ways.</p></li>
<li><p>Occlusion. The objects of interest can be occluded. Sometimes only a small portion of an object (as little as few pixels) could be visible.</p></li>
<li><p>Illumination conditions. The effects of illumination are drastic on the pixel level.</p></li>
<li><p>Background clutter. The objects of interest may blend into their environment, making them hard to identify.</p></li>
<li><p>Intra-class variation. The classes of interest can often be relatively broad, such as chair. There are many different types of these objects, each with their own appearance.</p></li>
</ul>
<p>A good image classification model must be invariant to the cross product of all these variations, while simultaneously retaining sensitivity to the inter-class variations.</p>
</section>
<section id="pipeline-of-image-classification">
<h2><span class="section-number">29.3. </span>Pipeline of image classification<a class="headerlink" href="#pipeline-of-image-classification" title="Permalink to this headline">#</a></h2>
<p>We‚Äôve seen that the task in image classification is to take an array of pixels that represents a single image and assign a label to it. Our complete pipeline can be formalized as follows:</p>
<ul class="simple">
<li><p>Input: Our input consists of a set of N images, each labeled with one of K different classes. We refer to this data as the training set,</p></li>
<li><p>Learning: Our task is to use the training set to learn what every one of the classes looks like. We refer to this step as training a classifier, or learning a model,</p></li>
<li><p>Evaluation: In the end, we evaluate the quality of the classifier by asking it to predict labels for a new set of images that it has never seen before. We will then compare the true labels of these images to the ones predicted by the classifier. Intuitively, we‚Äôre hoping that a lot of the predictions match up with the true answers (which we call the ground truth).</p></li>
</ul>
</section>
<section id="history-classic-models">
<h2><span class="section-number">29.4. </span>History &amp; classic models<a class="headerlink" href="#history-classic-models" title="Permalink to this headline">#</a></h2>
<p>Since image classification is a classic task for computer vision, there are several models that are well-performed in the past. We can list them as follows: LeNet, AlexNet, VGGNet, GoogleNet, ResNet, DenseNet, SENet, MobileNet, ShuffleNet and ViT. In this part, we will introduce some of them.</p>
<section id="vggnet">
<h3><span class="section-number">29.4.1. </span>VGGNet<a class="headerlink" href="#vggnet" title="Permalink to this headline">#</a></h3>
<p>The VGG (Visual Geometry Group) multilayer network model has 19 more layers than AlexNet, verifying that increasing the depth in the network structure can directly affect the model performance. The design idea of VGG is to increase the depth of the network and use a small size convolutional kernel instead. As shown in the figure below, three 3√ó3 convolutional kernels are used to replace the 7√ó7 convolutional kernels in AlexNet, and two 3√ó3 convolutional kernels are used to replace the 5√ó5 convolutional kernels, which can increase the depth of the network and improve the model effect while ensuring the same perceptual field. The number of model parameters and operations can be reduced by using smaller 3√ó3 Filters, and the image feature information can be better retained. The specific advantages of the improvement are summarized as follows.</p>
<ul class="simple">
<li><p>Using small 3√ó3 filters to replace large convolutional kernels.</p></li>
<li><p>After replacing the convolution kernel, the convolution layers have the same perceptual field.</p></li>
<li><p>Each layer is trained by Re LU activation function and batch gradient descent after convolution operation.</p></li>
<li><p>It is verified that increasing the network depth can improve the model performance Although, VGG has achieved good results in image classification and localization problems in 2014 due to its deeper network structure and low computational complexity, it uses 140 million parameters and is computationally intensive, which is its shortcoming.</p></li>
</ul>
<figure class="align-default" id="vgg-structure">
<a class="bg-white mb-1 reference internal image-reference" href="../_images/02_VGG.png"><img alt="../_images/02_VGG.png" class="bg-white mb-1" src="../_images/02_VGG.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 29.2 </span><span class="caption-text">Structure of VGGNet <span id="id1">[<a class="reference internal" href="#id81" title="Andrew Zisserman Karen Simonyan. Vggnet structure. URL: https://arxiv.org/pdf/1409.1556.pdf (visited on 2023).">KS</a>]</span></span><a class="headerlink" href="#vgg-structure" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<section id="code">
<h4><span class="section-number">29.4.1.1. </span>Code<a class="headerlink" href="#code" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_addons</span> <span class="k">as</span> <span class="nn">tfa</span>
<span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>

<span class="n">AUTOTUNE</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span>

<span class="c1">#This code defines a function `conv_bn` that returns a sequential model consisting of a zero-padding layer, </span>
<span class="c1"># a convolution layer, and a batch normalization layer.</span>

<span class="k">def</span> <span class="nf">conv_bn</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ZeroPadding2D</span><span class="p">(</span><span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
                <span class="n">filters</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
                <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
                <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;conv&quot;</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;bn&quot;</span><span class="p">),</span>
        <span class="p">]</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This function is useful for constructing convolutional neural network architectures, as it provides a simple way to combine convolution and batch normalization layers.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">out_channels</span></code> specifies the number of output channels for the convolution layer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernel_size</span></code> specifies the size of the convolution kernel.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">strides</span></code> specifies the stride size for the convolution operation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding</span></code> specifies the padding size for the zero-padding layer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">groups</span></code> specifies the number of groups for the group convolution operation.</p></li>
</ul>
<p>The function returns a sequential model that consists of three layers:
a zero-padding layer, a convolution layer, and a batch normalization layer.</p>
<p>The convolution layer has <code class="docutils literal notranslate"><span class="pre">out_channels</span></code> filters, a kernel size of <code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>, and a stride size of <code class="docutils literal notranslate"><span class="pre">strides</span></code>. The zero-padding layer has a padding size of <code class="docutils literal notranslate"><span class="pre">padding</span></code>. The batch normalization layer normalizes the activations of the convolution layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RepVGGBlock</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">deploy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RepVGGBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deploy</span> <span class="o">=</span> <span class="n">deploy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>

        <span class="k">assert</span> <span class="n">kernel_size</span> <span class="o">==</span> <span class="mi">3</span>
        <span class="k">assert</span> <span class="n">padding</span> <span class="o">==</span> <span class="mi">1</span>

        <span class="n">padding_11</span> <span class="o">=</span> <span class="n">padding</span> <span class="o">-</span> <span class="n">kernel_size</span> <span class="o">//</span> <span class="mi">2</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nonlinearity</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">deploy</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rbr_reparam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ZeroPadding2D</span><span class="p">(</span><span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">),</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
                        <span class="n">filters</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                        <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                        <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
                        <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
                        <span class="n">dilation_rate</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
                        <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
                        <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rbr_identity</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">out_channels</span> <span class="o">==</span> <span class="n">in_channels</span> <span class="ow">and</span> <span class="n">strides</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rbr_dense</span> <span class="o">=</span> <span class="n">conv_bn</span><span class="p">(</span>
                <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rbr_1x1</span> <span class="o">=</span> <span class="n">conv_bn</span><span class="p">(</span>
                <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="n">padding_11</span><span class="p">,</span>
                <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RepVGG Block, identity = &quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rbr_identity</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;rbr_reparam&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinearity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rbr_reparam</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rbr_identity</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">id_out</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">id_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rbr_identity</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinearity</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rbr_dense</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">rbr_1x1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="n">id_out</span>
        <span class="p">)</span>

    <span class="c1"># This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.</span>
    <span class="c1"># You can get the equivalent kernel and bias at any time and do whatever you want,</span>
    <span class="c1">#     for example, apply some penalties or constraints during training, just like you do to the other models.</span>
    <span class="c1"># May be useful for quantization or pruning.</span>
    <span class="k">def</span> <span class="nf">get_equivalent_kernel_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">kernel3x3</span><span class="p">,</span> <span class="n">bias3x3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_bn_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rbr_dense</span><span class="p">)</span>
        <span class="n">kernel1x1</span><span class="p">,</span> <span class="n">bias1x1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_bn_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rbr_1x1</span><span class="p">)</span>
        <span class="n">kernelid</span><span class="p">,</span> <span class="n">biasid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fuse_bn_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rbr_identity</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">kernel3x3</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pad_1x1_to_3x3_tensor</span><span class="p">(</span><span class="n">kernel1x1</span><span class="p">)</span> <span class="o">+</span> <span class="n">kernelid</span><span class="p">,</span>
            <span class="n">bias3x3</span> <span class="o">+</span> <span class="n">bias1x1</span> <span class="o">+</span> <span class="n">biasid</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_pad_1x1_to_3x3_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel1x1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">kernel1x1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
                <span class="n">kernel1x1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_fuse_bn_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">branch</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">branch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">branch</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="n">branch</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s2">&quot;conv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">running_mean</span> <span class="o">=</span> <span class="n">branch</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s2">&quot;bn&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">moving_mean</span>
            <span class="n">running_var</span> <span class="o">=</span> <span class="n">branch</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s2">&quot;bn&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">moving_variance</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="n">branch</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s2">&quot;bn&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">gamma</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="n">branch</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s2">&quot;bn&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">beta</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="n">branch</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s2">&quot;bn&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">epsilon</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">branch</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;id_tensor&quot;</span><span class="p">):</span>
                <span class="n">input_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span>
                <span class="n">kernel_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span><span class="p">):</span>
                    <span class="n">kernel_value</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">%</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">id_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
                    <span class="n">kernel_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span>
                <span class="p">)</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">id_tensor</span>
            <span class="n">running_mean</span> <span class="o">=</span> <span class="n">branch</span><span class="o">.</span><span class="n">moving_mean</span>
            <span class="n">running_var</span> <span class="o">=</span> <span class="n">branch</span><span class="o">.</span><span class="n">moving_variance</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="n">branch</span><span class="o">.</span><span class="n">gamma</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="n">branch</span><span class="o">.</span><span class="n">beta</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="n">branch</span><span class="o">.</span><span class="n">epsilon</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">running_var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">/</span> <span class="n">std</span>
        <span class="k">return</span> <span class="n">kernel</span> <span class="o">*</span> <span class="n">t</span><span class="p">,</span> <span class="n">beta</span> <span class="o">-</span> <span class="n">running_mean</span> <span class="o">*</span> <span class="n">gamma</span> <span class="o">/</span> <span class="n">std</span>

    <span class="k">def</span> <span class="nf">repvgg_convert</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">kernel</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_equivalent_kernel_bias</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">bias</span>
</pre></div>
</div>
</div>
</div>
<p>This code defines a RepVGGBlock layer in TensorFlow, which is a convolutional block used in the RepVGG model. The RepVGG model is a neural network architecture that achieves high accuracy while having a simple structure. The RepVGGBlock layer is designed to be more efficient and easier to train compared to other convolutional layers.</p>
<p>The RepVGGBlock layer has several parameters such as <code class="docutils literal notranslate"><span class="pre">in_channels</span></code>, <code class="docutils literal notranslate"><span class="pre">out_channels</span></code>, <code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="docutils literal notranslate"><span class="pre">strides</span></code>, <code class="docutils literal notranslate"><span class="pre">padding</span></code>, <code class="docutils literal notranslate"><span class="pre">dilation</span></code>, and <code class="docutils literal notranslate"><span class="pre">groups</span></code>. <code class="docutils literal notranslate"><span class="pre">in_channels</span></code> and <code class="docutils literal notranslate"><span class="pre">out_channels</span></code> determine the number of input and output channels, respectively.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">kernel_size</span></code> specifies the size of the convolution kernel.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">strides</span></code> determines the step size of the convolution operation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding</span></code> controls the amount of padding to be added to the input image.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dilation</span></code> specifies the dilation rate of the convolution operation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">groups</span></code> determines the number of groups to be used in the convolution operation.</p></li>
</ul>
<p>The layer contains several convolutional operations, including a 3x3 convolution, a 1x1 convolution, and a residual identity. These convolutional operations are fused with batch normalization to improve training efficiency. The layer also includes a rectified linear unit (ReLU) activation function.</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">call()</span></code> function of the RepVGGBlock layer applies the convolutional operations and the ReLU activation function to the input tensor.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">get_equivalent_kernel_bias()</span></code> function derives the equivalent kernel and bias of the layer in a differentiable way, which can be useful for applying penalties or constraints during training, such as in quantization or pruning.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">repvgg_convert()</span></code> function converts the RepVGGBlock layer to a standard convolutional layer by fusing batch normalization with convolutional operations.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="k">class</span> <span class="nc">RepVGG</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">width_multiplier</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">override_groups_map</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">deploy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RepVGG</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">width_multiplier</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">deploy</span> <span class="o">=</span> <span class="n">deploy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">override_groups_map</span> <span class="o">=</span> <span class="n">override_groups_map</span> <span class="ow">or</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">assert</span> <span class="mi">0</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">override_groups_map</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">in_planes</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">64</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">stage0</span> <span class="o">=</span> <span class="n">RepVGGBlock</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">out_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">in_planes</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">deploy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">deploy</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cur_layer_idx</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stage1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_stage</span><span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="mi">64</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">num_blocks</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stage2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_stage</span><span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="mi">128</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">num_blocks</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stage3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_stage</span><span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="n">num_blocks</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stage4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_stage</span><span class="p">(</span>
            <span class="nb">int</span><span class="p">(</span><span class="mi">512</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> <span class="n">num_blocks</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gap</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AdaptiveAveragePooling2D</span><span class="p">(</span><span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_stage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="n">stride</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_blocks</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">blocks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">stride</span> <span class="ow">in</span> <span class="n">strides</span><span class="p">:</span>
            <span class="n">cur_groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">override_groups_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cur_layer_idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">RepVGGBlock</span><span class="p">(</span>
                    <span class="n">in_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">in_planes</span><span class="p">,</span>
                    <span class="n">out_channels</span><span class="o">=</span><span class="n">planes</span><span class="p">,</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                    <span class="n">strides</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">groups</span><span class="o">=</span><span class="n">cur_groups</span><span class="p">,</span>
                    <span class="n">deploy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">deploy</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">in_planes</span> <span class="o">=</span> <span class="n">planes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cur_layer_idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">blocks</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage4</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gap</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<p>This is a TensorFlow implementation of the RepVGG model, a type of convolutional neural network designed for efficient inference on mobile and embedded devices.</p>
<ul class="simple">
<li><p>The RepVGG model uses a series of RepVGG blocks to transform the input image into a feature representation that is then fed into a fully connected layer to make the final prediction.</p></li>
<li><p>The RepVGG blocks are based on the VGG-style architecture, but instead of using traditional convolutional layers, they use a combination of 1x1 and 3x3 depthwise separable convolutions to reduce the number of parameters while maintaining performance.</p></li>
<li><p>The width of the network can be adjusted by specifying a width multiplier for each stage of the network.</p></li>
<li><p>The model also includes an adaptive average pooling layer to reduce the spatial dimensions of the feature map before the fully connected layer.</p></li>
</ul>
</section>
</section>
<section id="resnet">
<h3><span class="section-number">29.4.2. </span>Resnet<a class="headerlink" href="#resnet" title="Permalink to this headline">#</a></h3>
<p>ResNet (Residual Network) was proposed by Kaiming He and won the 2015 ILSVRC Grand Prix with an error rate of 3.57%. In the previous network, when the model is not deep enough, its network recognition is not strong, but when the network stack (Plain Network) is very deep, the network gradient disappearance and gradient dispersion are obvious, resulting in the model‚Äôs computational effectiveness but not up but down. Therefore, in view of the degradation problem of this deep network, ResNet is designed as an ultra-deep network without the gradient vanishing problem.ResNet has various types depending on the number of layers, from 18 to 1202 layers. As an example, Res Net50 consists of 49 convolutional layers and 1 fully connected layer, as shown in the figure below. This simple addition does not add additional parameters and computation to the network, but can greatly increase the training speed and improve the training effect, and this simple structure can well solve the degradation problem when the model deepens the number of layers. In this way, the network will always be in the optimal state and the performance of the network will not decrease with increasing depth.</p>
<p>The most important part of ResNet should be the residual block, and here is the structure.</p>
<figure class="align-default" id="residual-block">
<a class="bg-white mb-1 reference internal image-reference" href="../_images/03_resblock.png"><img alt="../_images/03_resblock.png" class="bg-white mb-1" src="../_images/03_resblock.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 29.3 </span><span class="caption-text">Structure of residual block <span id="id2">[<a class="reference internal" href="#id80" title="Shaoqing Ren Kaiming He, Xiangyu Zhang and Jian Sun. Residual block structure. URL: https://arxiv.org/pdf/1512.03385.pdf (visited on 2023).">KHSa</a>]</span></span><a class="headerlink" href="#residual-block" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="resnet-structure">
<a class="bg-white mb-1 reference internal image-reference" href="../_images/04_ResNet.png"><img alt="../_images/04_ResNet.png" class="bg-white mb-1" src="../_images/04_ResNet.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 29.4 </span><span class="caption-text">Structure of residual network <span id="id3">[<a class="reference internal" href="#id79" title="Shaoqing Ren Kaiming He, Xiangyu Zhang and Jian Sun. Resnet structure. URL: https://arxiv.org/pdf/1512.03385.pdf (visited on 2023).">KHSb</a>]</span></span><a class="headerlink" href="#resnet-structure" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<section id="id4">
<h4><span class="section-number">29.4.2.1. </span>Code<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">conv_bn_relu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">conv_bn_relu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">conv_bn_relu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">shortcut</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">resnet</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">num_blocks</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">input_shape</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">conv_bn_relu</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">num_filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="c1"># Stacking residual blocks</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">num_blocks</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">):</span>
            <span class="n">strides</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">strides</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">)</span>

    <span class="c1"># Global average pooling and fully-connected layer for classification</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">logits</span>
</pre></div>
</div>
</div>
</div>
<p>This implementation uses the conv_bn_relu function to perform a convolution operation followed by batch normalization and ReLU activation.</p>
<ul class="simple">
<li><p>The residual_block function defines a residual block that consists of two convolutional layers with batch normalization and ReLU activation, followed by an addition of the input to the output of the second convolutional layer.</p></li>
<li><p>The resnet function stacks multiple residual blocks and ends with a global average pooling layer and a fully-connected layer for classification.</p></li>
</ul>
</section>
</section>
<section id="densenet">
<h3><span class="section-number">29.4.3. </span>DenseNet<a class="headerlink" href="#densenet" title="Permalink to this headline">#</a></h3>
<p>DenseNet proposes a more radical dense connection mechanism than ResNet: i.e., connecting all layers to each other, specifically each layer accepts all the layers before it as its additional input. resNet short-circuits each layer with some previous layer (usually 2-3 layers), and the connection is made by element-level summation. In DenseNet, each layer is connected (concat) with all the preceding layers in the channel dimension and used as input to the next layer, which is a dense connection. Moreover, DenseNet is directly concat feature maps from different layers, which enables feature reuse and improves efficiency, and this feature is the most important difference between DenseNet and ResNet.</p>
<figure class="align-default" id="dense-block">
<a class="bg-white mb-1 reference internal image-reference" href="../_images/05_denseblock.png"><img alt="../_images/05_denseblock.png" class="bg-white mb-1" src="../_images/05_denseblock.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 29.5 </span><span class="caption-text">Structure of dense block <span id="id5">[<a class="reference internal" href="#id82" title="Laurens van der Maaten Gao Huang, Zhuang Liu and Kilian Q. Weinberger. Dense block structure. URL: https://arxiv.org/pdf/1608.06993.pdf (visited on 2023).">GHWa</a>]</span></span><a class="headerlink" href="#dense-block" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="densenet-structure">
<a class="bg-white mb-1 reference internal image-reference" href="../_images/06_DenseNet.png"><img alt="../_images/06_DenseNet.png" class="bg-white mb-1" src="../_images/06_DenseNet.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 29.6 </span><span class="caption-text">Structure of dense network <span id="id6">[<a class="reference internal" href="#id83" title="Laurens van der Maaten Gao Huang, Zhuang Liu and Kilian Q. Weinberger. Dense net structure. URL: https://arxiv.org/pdf/1608.06993.pdf (visited on 2023).">GHWb</a>]</span></span><a class="headerlink" href="#densenet-structure" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<section id="id7">
<h4><span class="section-number">29.4.3.1. </span>Code<a class="headerlink" href="#id7" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">conv_block</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">dense_block</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">growth_rate</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">conv</span> <span class="o">=</span> <span class="n">conv_block</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">growth_rate</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">conv</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">input</span>

<span class="k">def</span> <span class="nf">transition_block</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">compression</span><span class="p">):</span>
    <span class="n">n_filters</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">n_filters</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_filters</span> <span class="o">*</span> <span class="n">compression</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">average_pooling2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">densenet</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">n_dense_blocks</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_layers_per_block</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">growth_rate</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
    <span class="c1"># Initial convolution layer</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">growth_rate</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">max_pooling2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span>

    <span class="c1"># Dense blocks</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dense_blocks</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">dense_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_layers_per_block</span><span class="p">,</span> <span class="n">growth_rate</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">n_dense_blocks</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">transition_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">compression</span><span class="p">)</span>

    <span class="c1"># Global average pooling and classification layer</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">average_pooling2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">output</span>

</pre></div>
</div>
</div>
</div>
<p>This implementation includes functions for building the building blocks of DenseNet: conv_block, dense_block, and transition_block. These building blocks are then used to construct the densenet function, which takes an input tensor and returns the output logits for a classification task.</p>
<p>The densenet function takes several hyperparameters as inputs, such as the number of dense blocks, the number of layers per block, the growth rate of each block, the compression factor for the transition blocks, and the dropout rate. These hyperparameters can be adjusted to optimize the performance of the model for a specific task.</p>
</section>
</section>
<section id="mobilenet">
<h3><span class="section-number">29.4.4. </span>MobileNet<a class="headerlink" href="#mobilenet" title="Permalink to this headline">#</a></h3>
<p>MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem.</p>
<p>Besides, the standard convolutional filters for normal CNNs are replaced by two layers: depthwise convolution and pointwise convolution to build a depthwise separable filter.</p>
<figure class="align-default" id="mobilenet-convolution-structure">
<a class="bg-white mb-1 reference internal image-reference" href="../_images/07_mobileconv.png"><img alt="../_images/07_mobileconv.png" class="bg-white mb-1" src="../_images/07_mobileconv.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 29.7 </span><span class="caption-text">Replacement of standard convolution filter <span id="id8">[<a class="reference internal" href="#id84" title="Bo Chen Andrew G. Howard, Menglong Zhu, Tobias Weyand Dmitry Kalenichenko, Weijun Wang, Marco Andreetto, and Hartwig Adam. Convolution for mobilenet structure. URL: https://arxiv.org/pdf/1704.04861.pdf%E2%80%8Barxiv.org (visited on 2023).">AGHDKAAb</a>]</span></span><a class="headerlink" href="#mobilenet-convolution-structure" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="mobilenet-body-structure">
<a class="bg-white mb-1 reference internal image-reference" href="../_images/08_MobileNet.png"><img alt="../_images/08_MobileNet.png" class="bg-white mb-1" src="../_images/08_MobileNet.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 29.8 </span><span class="caption-text">Body structure of MobileNet <span id="id9">[<a class="reference internal" href="#id85" title="Bo Chen Andrew G. Howard, Menglong Zhu, Tobias Weyand Dmitry Kalenichenko, Weijun Wang, Marco Andreetto, and Hartwig Adam. Mobilenet body structure. URL: https://arxiv.org/pdf/1704.04861.pdf%E2%80%8Barxiv.org (visited on 2023).">AGHDKAAa</a>]</span></span><a class="headerlink" href="#mobilenet-body-structure" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<section id="id10">
<h4><span class="section-number">29.4.4.1. </span>Code<a class="headerlink" href="#id10" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">depthwise_separable_conv</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">num_filters</span><span class="p">,</span> <span class="n">width_multiplier</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Depthwise Separable Convolution&quot;&quot;&quot;</span>
    <span class="c1"># Depthwise Convolution</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">DepthwiseConv2D</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span> <span class="k">if</span> <span class="n">downsample</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">downsample</span> <span class="k">else</span> <span class="mi">1</span><span class="p">),</span>
                                          <span class="n">depth_multiplier</span><span class="o">=</span><span class="n">width_multiplier</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()(</span><span class="n">net</span><span class="p">)</span>

    <span class="c1"># Pointwise Convolution</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">num_filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()(</span><span class="n">net</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">net</span>

<span class="k">def</span> <span class="nf">mobilenet</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">width_multiplier</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>

    <span class="c1"># Initial Convolution</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mi">32</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">),</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()(</span><span class="n">net</span><span class="p">)</span>

    <span class="c1"># Depthwise Separable Convolution x 13</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">depthwise_separable_conv</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">64</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">),</span> <span class="n">width_multiplier</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">depthwise_separable_conv</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">),</span> <span class="n">width_multiplier</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">depthwise_separable_conv</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">128</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">),</span> <span class="n">width_multiplier</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">depthwise_separable_conv</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">),</span> <span class="n">width_multiplier</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">depthwise_separable_conv</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">),</span> <span class="n">width_multiplier</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">depthwise_separable_conv</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">512</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">),</span> <span class="n">width_multiplier</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">depthwise_separable_conv</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">512</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">),</span> <span class="n">width_multiplier</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">depthwise_separable_conv</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">),</span> <span class="n">width_multiplier</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">depthwise_separable_conv</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="n">width_multiplier</span><span class="p">),</span> <span class="n">width_multiplier</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">net</span><span class="p">)</span>

    <span class="c1"># Output</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">net</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This implementation defines two functions: depthwise_separable_conv and mobilenet. The former implements the depthwise separable convolution operation used by the MobileNet architecture, while the latter constructs the entire MobileNet model.</p>
<p>The mobilenet function takes three arguments: input_shape (a tuple specifying the input shape of the model), num_classes (the number of output classes), and width_multiplier (a scaling factor for the number of filters in each layer of the model, defaulting to 1).</p>
</section>
</section>
<section id="vit">
<h3><span class="section-number">29.4.5. </span>ViT<a class="headerlink" href="#vit" title="Permalink to this headline">#</a></h3>
<p>Different from the previous models, ViT (Vision Transformer) uses the concept of Transformer. Inspired by the Transformer scaling successes in NLP, they experiment with applying a standard Transformer directly to images, with the fewest possible modifications. To do so, they split an image into patches and provide the sequence of linear embeddings of these patches as an input to a Transformer. Image patches are treated the same way as tokens (words) in an NLP application. They train the model on image classification in supervised fashion.</p>
<section id="id11">
<h4><span class="section-number">29.4.5.1. </span>Code<a class="headerlink" href="#id11" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LayerNormalization</span><span class="p">,</span> <span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Input</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers.experimental.preprocessing</span> <span class="kn">import</span> <span class="n">Resizing</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>


<span class="k">class</span> <span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">att</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">key_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
            <span class="n">Dense</span><span class="p">(</span><span class="n">ff_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
            <span class="n">Dense</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">),</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="p">):</span>
        <span class="n">attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
        <span class="n">attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">attn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span><span class="p">(</span><span class="n">inputs</span> <span class="o">+</span> <span class="n">attn_output</span><span class="p">)</span>
        <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">out1</span><span class="p">)</span>
        <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span><span class="p">(</span><span class="n">out1</span> <span class="o">+</span> <span class="n">ffn_output</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">VisionTransformer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">patch_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">ff_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VisionTransformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">num_patches</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_size</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_dim</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">patch_size</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">Resizing</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patchify</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">Patching</span><span class="p">(</span><span class="n">num_patches</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_projection</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">patch_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="s1">&#39;position_embedding&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_dim</span><span class="p">),</span>
                                                   <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">RandomNormal</span><span class="p">(),</span>
                                                   <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_blocks</span> <span class="o">=</span> <span class="p">[</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">embed_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">patch_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">ff_dim</span><span class="o">=</span><span class="n">ff_dim</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">rate</span><span class="p">)</span>
                                   <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layernorm</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patchify</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_projection</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_dim</span><span class="p">)),</span> <span class="n">x</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">transformer_block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_blocks</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">transformer_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The above code defines a Vision Transformer (ViT) model in TensorFlow, which is a state-of-the-art architecture for image classification tasks that combines the transformer architecture with a patch-based approach for image processing.</p>
<p>The TransformerBlock class defines a single transformer block with multi-head attention and a feedforward neural network. The constructor takes in the following arguments:</p>
<ul class="simple">
<li><p>embed_dim: the dimensionality of the embedding layer</p></li>
<li><p>num_heads: the number of attention heads</p></li>
<li><p>ff_dim: the dimensionality of the feedforward layer</p></li>
<li><p>rate: the dropout rate</p></li>
</ul>
<p>The call method of the TransformerBlock class takes in the input tensor and a boolean flag training indicating whether the layer should behave in training or inference mode. The input tensor is passed through the multi-head attention layer, followed by a dropout layer, and then added to the input tensor using residual connections. The resulting tensor is passed through a feedforward neural network, followed by another dropout layer, and then added to the residual tensor using another residual connection.</p>
<p>The VisionTransformer class defines the ViT model, which consists of multiple transformer blocks and a final dense layer for classification. The constructor takes in the following arguments:</p>
<ul class="simple">
<li><p>image_size: the size of the input image</p></li>
<li><p>patch_size: the size of the patches to be extracted from the image</p></li>
<li><p>num_layers: the number of transformer blocks in the model</p></li>
<li><p>num_heads: the number of attention heads in each transformer block</p></li>
<li><p>ff_dim: the dimensionality of the feedforward layer in each transformer block</p></li>
<li><p>num_classes: the number of output classes</p></li>
<li><p>rate: the dropout rate</p></li>
</ul>
<p>The call method of the VisionTransformer class takes in the input tensor and a boolean flag training indicating whether the layer should behave in training or inference mode. The input tensor is first resized to the specified image_size and then passed through a patch extraction layer that divides the image into patches of size patch_size. Each patch is projected to a patch_dim-dimensional embedding space using a dense layer. A learnable position embedding is added to the patches and the resulting tensor is passed through a dropout layer. The resulting tensor is then passed through a stack of num_layers transformer blocks, each followed by a dropout layer. The output of the final transformer block is passed through a layer normalization layer and the first element of the resulting tensor is passed through a dense layer with num_classes output units and a softmax activation function.</p>
</section>
</section>
</section>
<section id="classic-datasets">
<h2><span class="section-number">29.5. </span>Classic datasets<a class="headerlink" href="#classic-datasets" title="Permalink to this headline">#</a></h2>
<p>As we said before, image classification task is mainly trained by datasets, so the importance of dataset is obvious. Here, we will introduce some widely-used datasets.</p>
<section id="cifar-10-100">
<h3><span class="section-number">29.5.1. </span>CIFAR-10/100<a class="headerlink" href="#cifar-10-100" title="Permalink to this headline">#</a></h3>
<p>The <a class="reference external" href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 dataset</a> consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.</p>
<p>The CIFAR-100 dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a ‚Äúfine‚Äù label (the class to which it belongs) and a ‚Äúcoarse‚Äù label (the superclass to which it belongs).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Download for Linux
wget <a class="reference external" href="http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz">http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz</a>
wget <a class="reference external" href="http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz">http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz</a></p>
<p>Download for Win/Mac
Download from the offical website</p>
</div>
</section>
<section id="imagenet-1000">
<h3><span class="section-number">29.5.2. </span>ImageNet-1000<a class="headerlink" href="#imagenet-1000" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://image-net.org/">ImageNet</a> is an image dataset organized according to the WordNet hierarchy. Each meaningful concept in WordNet, possibly described by multiple words or word phrases, is called a ‚Äúsynonym set‚Äù or ‚Äúsynset‚Äù. There are more than 100,000 synsets in WordNet; the majority of them are nouns (80,000+). In ImageNet, we aim to provide on average 1000 images to illustrate each synset. Images of each concept are quality-controlled and human-annotated. In its completion, we hope ImageNet will offer tens of millions of cleanly labeled and sorted images for most of the concepts in the WordNet hierarchy.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you want to download this dataset, please visit <a class="reference external" href="https://www.kaggle.com/c/imagenet-object-localization-challenge/overview/description">kaggle</a> for more information.</p>
</div>
</section>
</section>
<section id="standards">
<h2><span class="section-number">29.6. </span>Standards<a class="headerlink" href="#standards" title="Permalink to this headline">#</a></h2>
<section id="top-1-accuracy">
<h3><span class="section-number">29.6.1. </span>Top-1 accuracy<a class="headerlink" href="#top-1-accuracy" title="Permalink to this headline">#</a></h3>
<p>If your predicted label takes the largest one inside the final probability vector as the prediction result, and if the one with the highest probability in your prediction result is correctly classified, then the prediction is correct. Otherwise, the prediction is wrong.</p>
</section>
<section id="top-5-accuracy">
<h3><span class="section-number">29.6.2. </span>Top-5 accuracy<a class="headerlink" href="#top-5-accuracy" title="Permalink to this headline">#</a></h3>
<p>Among the 50 classification probabilities of the test image, take the first 5 maximum classification probabilities, whether the correct label (classification) is in it or not, that is, whether it is one of these first 5, if it is, it is a successful classification.</p>
</section>
</section>
<section id="your-turn">
<h2><span class="section-number">29.7. </span>Your turn! üöÄ<a class="headerlink" href="#your-turn" title="Permalink to this headline">#</a></h2>
<p>TBD.</p>
</section>
<section id="acknowledgments">
<h2><span class="section-number">29.8. </span>Acknowledgments<a class="headerlink" href="#acknowledgments" title="Permalink to this headline">#</a></h2>
<p>Thanks to <a class="reference external" href="https://www.stanford.edu">Stanford</a> for creating the open-source course <a class="reference external" href="https://cs231n.github.io/classification/">CS231n: Deep Learning for Computer Vision</a>, <a class="reference external" href="https://github.com/hoangthang1607">Duc Thang HOANG</a> for creating the open-source project <a class="reference external" href="https://github.com/hoangthang1607/RepVGG-Tensorflow-2">RepVGG-Tensorflow-2</a>, <a class="reference external" href="https://github.com/taki0112">Junho Kim</a> for creating the open-source project <a class="reference external" href="https://github.com/taki0112/ResNet-Tensorflow">ResNet-Tensorflow</a>, <a class="reference external" href="https://github.com/taki0112/Densenet-Tensorflow">Densenet-Tensorflow</a> and <a class="reference external" href="https://github.com/taki0112/vit-tensorflow">vit-tensorflow</a> and <a class="reference external" href="https://github.com/ohadlights">ohadlights</a> for creating the open-source project <a class="reference external" href="https://github.com/ohadlights/mobilenetv2">mobilenetv2</a>. They inspire the majority of the content in this chapter.</p>
<hr class="docutils" />
<div class="docutils container" id="id12">
<dl class="citation">
<dt class="label" id="id85"><span class="brackets"><a class="fn-backref" href="#id9">AGHDKAAa</a></span></dt>
<dd><p>Bo¬†Chen Andrew G.¬†Howard, Menglong¬†Zhu, Tobias¬†Weyand Dmitry¬†Kalenichenko, Weijun¬†Wang, Marco Andreetto, and Hartwig Adam. Mobilenet body structure. URL: <a class="reference external" href="https://arxiv.org/pdf/1704.04861.pdf%E2%80%8Barxiv.org">https://arxiv.org/pdf/1704.04861.pdf%E2%80%8Barxiv.org</a> (visited on 2023).</p>
</dd>
<dt class="label" id="id84"><span class="brackets"><a class="fn-backref" href="#id8">AGHDKAAb</a></span></dt>
<dd><p>Bo¬†Chen Andrew G.¬†Howard, Menglong¬†Zhu, Tobias¬†Weyand Dmitry¬†Kalenichenko, Weijun¬†Wang, Marco Andreetto, and Hartwig Adam. Convolution for mobilenet structure. URL: <a class="reference external" href="https://arxiv.org/pdf/1704.04861.pdf%E2%80%8Barxiv.org">https://arxiv.org/pdf/1704.04861.pdf%E2%80%8Barxiv.org</a> (visited on 2023).</p>
</dd>
<dt class="label" id="id82"><span class="brackets"><a class="fn-backref" href="#id5">GHWa</a></span></dt>
<dd><p>Laurens van der¬†Maaten Gao¬†Huang, Zhuang¬†Liu and Kilian¬†Q. Weinberger. Dense block structure. URL: <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">https://arxiv.org/pdf/1608.06993.pdf</a> (visited on 2023).</p>
</dd>
<dt class="label" id="id83"><span class="brackets"><a class="fn-backref" href="#id6">GHWb</a></span></dt>
<dd><p>Laurens van der¬†Maaten Gao¬†Huang, Zhuang¬†Liu and Kilian¬†Q. Weinberger. Dense net structure. URL: <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">https://arxiv.org/pdf/1608.06993.pdf</a> (visited on 2023).</p>
</dd>
<dt class="label" id="id80"><span class="brackets"><a class="fn-backref" href="#id2">KHSa</a></span></dt>
<dd><p>Shaoqing¬†Ren Kaiming¬†He, Xiangyu¬†Zhang and Jian Sun. Residual block structure. URL: <a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">https://arxiv.org/pdf/1512.03385.pdf</a> (visited on 2023).</p>
</dd>
<dt class="label" id="id79"><span class="brackets"><a class="fn-backref" href="#id3">KHSb</a></span></dt>
<dd><p>Shaoqing¬†Ren Kaiming¬†He, Xiangyu¬†Zhang and Jian Sun. Resnet structure. URL: <a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">https://arxiv.org/pdf/1512.03385.pdf</a> (visited on 2023).</p>
</dd>
<dt class="label" id="id81"><span class="brackets"><a class="fn-backref" href="#id1">KS</a></span></dt>
<dd><p>Andrew¬†Zisserman Karen¬†Simonyan. Vggnet structure. URL: <a class="reference external" href="https://arxiv.org/pdf/1409.1556.pdf">https://arxiv.org/pdf/1409.1556.pdf</a> (visited on 2023).</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ocademy-ai/machine-learning",
            ref: "release",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./deep-learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="dl-summary.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">28. </span>Summary of deep learning (TBD)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="image-segmentation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">30. </span>Image segmentation</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ocademy<br/>
  
      &copy; Copyright 2022-2023.<br/>
    <div class="extra_footer">
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> Text content of this work is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>