
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>40.49. Linear Regression Implementation from Scratch &#8212; Ocademy Open Machine Learning Book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/drawio.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/youtube.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "ocademy-ai/machine-learning-utterances");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "💬 comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"></script>
    <script>quizdown.init({"quizdown_js": "https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"});</script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="40.50. ML logistic regression - assignment 1" href="../ml-logistic-regression-1.html" />
    <link rel="prev" title="40.48. Gradient descent" href="gradient-descent.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint">Learn AI together, for free! At <a color='lightblue' href='https://ocademy.cc'><u style='color:lightblue;'>Ocademy</u></a>.</div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo-long.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Ocademy Open Machine Learning Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PREREQUISITES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-introduction.html">
   1. Python programming introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-basics.html">
   2. Python programming basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-advanced.html">
   3. Python programming advanced
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATA SCIENCE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/introduction/introduction.html">
   4. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/defining-data-science.html">
     4.1. Defining data science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/data-science-ethics.html">
     4.2. Data Science ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/defining-data.html">
     4.3. Defining data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/introduction-to-statistics-and-probability.html">
     4.4. Introduction to statistics and probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/working-with-data/working-with-data.html">
   5. Working with data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/relational-databases.html">
     5.1. Relational databases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/non-relational-data.html">
     5.2. Non-relational data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/numpy.html">
     5.3. NumPy
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../data-science/working-with-data/pandas/pandas.html">
     5.4. Pandas
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../data-science/working-with-data/pandas/introduction-and-data-structures.html">
       5.4.1. Introduction and Data Structures
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../data-science/working-with-data/pandas/data-selection.html">
       5.4.2. Data Selection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../data-science/working-with-data/pandas/advanced-pandas-techniques.html">
       5.4.3. Advanced Pandas Techniques
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/data-preparation.html">
     5.5. Data preparation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-visualization/data-visualization.html">
   6. Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-distributions.html">
     6.1. Visualizing distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-proportions.html">
     6.2. Visualizing proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-relationships.html">
     6.3. Visualizing relationships: all about honey 🍯
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/meaningful-visualizations.html">
     6.4. Making meaningful visualizations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-science-lifecycle/data-science-lifecycle.html">
   7. Data Science lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/introduction.html">
     7.1. Introduction to the Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/analyzing.html">
     7.2. Analyzing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/communication.html">
     7.3. Communication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/data-science-in-the-cloud.html">
   8. Data Science in the cloud
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/introduction.html">
     8.1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/the-low-code-no-code-way.html">
     8.2. The “low code/no code” way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/the-azure-ml-sdk-way.html">
     8.3. Data Science in the cloud: The “Azure ML SDK” way
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../data-science/data-science-in-the-wild.html">
   9. Data Science in the real world
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING BASICS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-fundamentals/ml-overview.html">
   10. Machine Learning overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/regression/regression-models-for-machine-learning.html">
   11. Regression models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/tools-of-the-trade.html">
     11.1. Tools of the trade
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/managing-data.html">
     11.2. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/linear-and-polynomial-regression.html">
     11.3. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/logistic-regression.html">
     11.4. Logistic regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/classification/getting-started-with-classification.html">
   12. Getting started with classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/introduction-to-classification.html">
     12.1. Introduction to classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/more-classifiers.html">
     12.2. More classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/yet-other-classifiers.html">
     12.3. Yet other classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/build-a-web-app-to-use-a-machine-learning-model.html">
     12.4. Build a web app to use a Machine Learning model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/parameter-optimization/parameter-optimization.html">
   13. Parameter Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/parameter-optimization/loss-function.html">
     13.1. Loss function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/parameter-optimization/gradient-descent.html">
     13.2. Gradient descent
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ADVANCED MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/clustering/clustering-models-for-machine-learning.html">
   14. Clustering models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/clustering/introduction-to-clustering.html">
     14.1. Introduction to clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/clustering/k-means-clustering.html">
     14.2. K-Means clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/ensemble-learning/getting-started-with-ensemble-learning.html">
   15. Getting started with ensemble learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/bagging.html">
     15.1. Bagging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/random-forest.html">
     15.2. Random forest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/feature-importance.html">
     15.3. Feature importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/gradient-boosting/introduction-to-gradient-boosting.html">
   16. Introduction to Gradient Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/gradient-boosting.html">
     16.1. Gradient Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/gradient-boosting-example.html">
     16.2. Gradient boosting example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/xgboost.html">
     16.3. XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/xgboost-k-fold-cv-feature-importance.html">
     16.4. XGBoost + k-fold CV + Feature Importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/unsupervised-learning.html">
   17. Unsupervised learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/kernel-method.html">
   18. Kernel method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/unsupervised-learning-pca-and-clustering.html">
   19. Unsupervised learning: PCA and clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/model-selection.html">
   20. Model selection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dl-overview.html">
   21. Intro to Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/nn.html">
   22. Neural Networks
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../deep-learning/cnn/cnn.html">
   23. Convolutional Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/cnn/cnn-vgg.html">
     23.3.1.1. Stylenet / Neural-Style
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/cnn/cnn-deepdream.html">
     23.3.1.2. Deepdream in TensorFlow
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/gan.html">
   24. Generative adversarial networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/rnn.html">
   25. Recurrent Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/nlp.html">
   26. Natural Language Processing Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/autoencoder.html">
   27. Autoencoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/lstm.html">
   28. Long-short term memory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/time-series.html">
   29. Time series
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dqn.html">
   30. Deep Q-learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/image-classification.html">
   31. Image classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/image-segmentation.html">
   32. Image segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/difussion-model.html">
   33. Diffusion Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/object-detection.html">
   34. Object detection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING OPERATIONS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/overview.html">
   35. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/problem-framing.html">
   36. Problem framing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/data-engineering.html">
   37. Data engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/model-training-and-evaluation.html">
   38. Model training &amp; evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/model-deployment.html">
   39. Model deployment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OTHERS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../README.html">
   40. Self-paced assignments
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../../set-up-env/first-assignment.html">
     40.3. First assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../set-up-env/second-assignment.html">
     40.4. Second assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../project-plan-template.html">
     40.5. Project Plan​ Template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-introduction.html">
     40.6. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-basics.html">
     40.7. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-advanced.html">
     40.8. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-text-about-data-science.html">
     40.9. Analyzing text about Data Science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-scenarios.html">
     40.10. Data Science scenarios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/write-a-data-ethics-case-study.html">
     40.11. Write a data ethics case study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/lines-scatters-and-bars.html">
     40.12. Lines, scatters and bars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/apply-your-skills.html">
     40.13. Apply your skills
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/try-it-in-excel.html">
     40.14. Try it in Excel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/dive-into-the-beehive.html">
     40.15. Dive into the beehive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/build-your-own-custom-vis.html">
     40.16. Build your own custom vis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/classifying-datasets.html">
     40.17. Classifying datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/small-diabetes-study.html">
     40.18. Small diabetes study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction-to-statistics-and-probability.html">
     40.19. Introduction to probability and statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/displaying-airport-data.html">
     40.20. Displaying airport data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/soda-profits.html">
     40.21. Soda profits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-COVID-19-papers.html">
     40.22. Analyzing COVID-19 papers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/estimation-of-COVID-19-pandemic.html">
     40.23. Estimation of COVID-19 pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-processing-in-python.html">
     40.24. Data processing in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/evaluating-data-from-a-form.html">
     40.25. Evaluating data from a form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-preparation.html">
     40.26. Data preparation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-data.html">
     40.27. Analyzing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/nyc-taxi-data-in-winter-and-summer.html">
     40.28. NYC taxi data in winter and summer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/matplotlib-applied.html">
     40.29. Matplotlib applied
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/tell-a-story.html">
     40.35. Tell a story
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/explore-a-planetary-computer-dataset.html">
     40.36. Explore a planetary computer dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/exploring-for-anwser.html">
     40.37. Exploring for answers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/market-research.html">
     40.38. Market research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/low-code-no-code-data-science-project-on-azure-ml.html">
     40.39. Low code/no code Data Science project on Azure ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-project-using-azure-ml-sdk.html">
     40.40. Data Science project using Azure ML SDK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-in-the-cloud-the-azure-ml-sdk-way.html">
     40.41. Data Science in the cloud: The “Azure ML SDK” way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-overview-iris.html">
     40.42. Machine Learning overview - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-overview-mnist-digits.html">
     40.43. Machine Learning overview - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression-with-scikit-learn.html">
     40.44. Regression with Scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="california_housing.html">
     40.45. Linear regression - California Housing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linear-regression-metrics.html">
     40.46. Linear Regression Metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="loss-function.html">
     40.47. Loss Function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="gradient-descent.html">
     40.48. Gradient descent
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     40.49. Linear Regression Implementation from Scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-logistic-regression-1.html">
     40.50. ML logistic regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-logistic-regression-2.html">
     40.51. ML logistic regression - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-neural-network-1.html">
     40.52. ML neural network - Assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../build-ml-web-app-1.html">
     40.53. Build ML web app - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../build-ml-web-app-2.html">
     40.54. Build ML web app - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression-tools.html">
     40.55. Regression tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../managing-data.html">
     40.56. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exploring-visualizations.html">
     40.57. Exploring visualizations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../try-a-different-model.html">
     40.58. Try a different model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../create-a-regression-model.html">
     40.59. Create a regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../linear-and-polynomial-regression.html">
     40.60. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../retrying-some-regression.html">
     40.61. Retrying some regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pumpkin-varieties-and-color.html">
     40.62. Pumpkin varieties and color
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../delicious-asian-and-indian-cuisines.html">
     40.63. Delicious asian and indian cuisines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../explore-classification-methods.html">
     40.64. Explore classification methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/kernel-method-assignment-1.html">
     40.65. Kernel method assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/support_vector_machines_for_regression.html">
     40.66. Support Vector Machines (SVM) - Intro and SVM for Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/support_vector_machines_for_classification.html">
     40.67. Support Vector Machines (SVM) - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/decision_trees_for_regression.html">
     40.68. Decision Trees - Intro and Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/decision_trees_for_classification.html">
     40.69. Decision Trees - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/model-selection-assignment-1.html">
     40.70. Model selection assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/learning-curve-to-identify-overfit-underfit.html">
     40.71. Learning Curve To Identify Overfit &amp; Underfit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/dropout-and-batch-normalization.html">
     40.72. Dropout and Batch Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/lasso-and-ridge-regression.html">
     40.73. Lasso and Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/regularized-linear-models.html">
     40.74. Regularized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/unsupervised-learning/customer-segmentation-clustering.html">
     40.75. Customer segmentation: clustering - assignment 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/random-forests-intro-and-regression.html">
     40.76. Random forests intro and regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/random-forests-for-classification.html">
     40.77. Random forests for classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.html">
     40.78. Beyond random forests: more ensemble models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/decision-trees.html">
     40.79. Decision trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/hyperparameter-tuning-gradient-boosting.html">
     40.80. Hyperparameter tuning gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/gradient-boosting-assignment.html">
     40.81. Gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/boosting-with-tuning.html">
     40.82. Boosting with tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/random-forest-classifier-feature-importance.html">
     40.83. Random Forest Classifier with Feature Importance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/data-engineering.html">
     40.85. Data engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/counterintuitive-challenges-in-ml-debugging.html">
     40.86. Counterintuitive Challenges in ML Debugging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/debugging-in-classification.html">
     40.87. Case Study: Debugging in Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/debugging-in-regression.html">
     40.88. Case Study: Debugging in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/random-forest-classifier.html">
     40.89. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../study-the-solvers.html">
     40.90. Study the solvers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../build-classification-models.html">
     40.91. Build classification models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../build-classification-model.html">
     40.92. Build Classification Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../parameter-play.html">
     40.93. Parameter play
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/how-to-choose-cnn-architecture-mnist.html">
     40.94. How to choose cnn architecture mnist
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/sign-language-digits-classification-with-cnn.html">
     40.96. Sign Language Digits Classification with CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/object-recognition-in-images-using-cnn.html">
     40.98. Object Recognition in Images using CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/image-classification.html">
     40.99. Image classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/tensorflow/intro_to_tensorflow_for_deeplearning.html">
     40.100. Intro to TensorFlow for Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/lstm/bitcoin-lstm-model-with-tweet-volume-and-sentiment.html">
     40.102. Bitcoin LSTM Model with Tweet Volume and Sentiment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/rnn/google-stock-price-prediction-rnn.html">
     40.104. Google Stock Price Prediction RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/autoencoder.html">
     40.106. Intro to Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/base-denoising-autoencoder-dimension-reduction.html">
     40.107. Base/Denoising Autoencoder &amp; Dimension Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/variational-autoencoder-and-faces-generation.html">
     40.108. Fun with Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/time-series-forecasting-assignment.html">
     40.109. Time Series Forecasting Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nn-for-classification-assignment.html">
     40.111. Neural Networks for Classification with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nn-classify-15-fruits-assignment.html">
     40.112. NN Classify 15 Fruits Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/dqn/dqn-on-foreign-exchange-market.html">
     40.117. DQN On Foreign Exchange Market
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/gan/art-by-gan.html">
     40.118. Art by gan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/gan/gan-introduction.html">
     40.120. Generative Adversarial Networks (GANs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/image-segmentation/comparing-edge-based-and-region-based-segmentation.html">
     40.121. Comparing edge-based and region-based segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/difussion-model/denoising-difussion-model.html">
     40.122. Summary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/object-detection/car-object-detection.html">
     40.123. Car Object Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/overview/basic-classification-classify-images-of-clothing.html">
     40.125. Basic classification: Classify images of clothing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nlp/getting-start-nlp-with-classification-task.html">
     40.126. Getting Start NLP with classification task
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../slides/introduction.html">
   41. Slides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-introduction.html">
     41.1. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-basics.html">
     41.2. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-advanced.html">
     41.3. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-introduction.html">
     41.4. Data Science introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/relational-vs-non-relational-database.html">
     41.5. Relational vs. non-relational database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/numpy-and-pandas.html">
     41.6. NumPy and Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-visualization.html">
     41.7. Data visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-lifecycle.html">
     41.8. Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-in-the-cloud.html">
     41.9. Data Science in the cloud
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-in-real-world.html">
     41.10. Data Science in real world
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/ml-overview.html">
     41.11. Machine Learning overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/linear-regression.html">
     41.12. Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/logistic-regression.html">
     41.13. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/logistic-regression-condensed.html">
     41.14. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/neural-network.html">
     41.15. Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/build-an-ml-web-app.html">
     41.16. Build an machine learning web application
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/unsupervised-learning.html">
     41.17. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/kernel-method.html">
     41.18. Kernel method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/model-selection.html">
     41.19. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/deep-learning/cnn.html">
     41.20. Convolutional Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/deep-learning/gan.html">
     41.21. Generative Adversarial Network
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ocademy-ai/machine-learning/release?urlpath=lab/tree/open-machine-learning-jupyter-book/assignments/ml-fundamentals/linear-regression/linear-regression-from-scratch.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ocademy-ai/machine-learning/blob/release/open-machine-learning-jupyter-book/assignments/ml-fundamentals/linear-regression/linear-regression-from-scratch.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning//issues/new?title=Issue%20on%20page%20%2Fassignments/ml-fundamentals/linear-regression/linear-regression-from-scratch.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/edit/release/open-machine-learning-jupyter-book/assignments/ml-fundamentals/linear-regression/linear-regression-from-scratch.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/assignments/ml-fundamentals/linear-regression/linear-regression-from-scratch.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   40.49.1. Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preparation">
   40.49.2. Data Preparation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-development">
   40.49.3. Model Development
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-loss-function">
     40.49.3.1. Define loss function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#use-gradient-descent-to-train-the-model">
     40.49.3.2. Use gradient descent to train the model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-evaluation">
   40.49.4. Model Evaluation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   40.49.5. Conclusion
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Linear Regression Implementation from Scratch</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   40.49.1. Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preparation">
   40.49.2. Data Preparation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-development">
   40.49.3. Model Development
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-loss-function">
     40.49.3.1. Define loss function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#use-gradient-descent-to-train-the-model">
     40.49.3.2. Use gradient descent to train the model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-evaluation">
   40.49.4. Model Evaluation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   40.49.5. Conclusion
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="linear-regression-implementation-from-scratch">
<h1><span class="section-number">40.49. </span>Linear Regression Implementation from Scratch<a class="headerlink" href="#linear-regression-implementation-from-scratch" title="Permalink to this headline">#</a></h1>
<section id="introduction">
<h2><span class="section-number">40.49.1. </span>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">#</a></h2>
<p>In previous sections, we have gained some understanding of linear regression, gradient descent, evaluation metrics, and the role of the loss function in this regression technique. In summary, linear regression utilizes gradient descent to optimize the model’s parameters by minimizing the loss function. This enables it to establish a linear relationship between the input features and the target variable, making it a powerful algorithm for predicting continuous values.</p>
<p>Linear regression is a widely used method in data analysis to describe the relationship between independent variables and a dependent variable using a linear equation. It aims to minimize the error between predicted and actual values by finding the best-fit line or surface. Linear regression can be used for predicting trends, exploring relationships, and identifying patterns in the data.</p>
<p>This chapter will apply the previously learnt knowledge to implement a linear regression model from scratch. The chapter includes steps for data preparation, model development, and model evaluation, and ultimately summarises the process of developing and evaluating linear regression models.</p>
<p>In Python, we can use libraries like NumPy and Pandas for data handling and analysis. We will also use the Matplotlib library for visualizing data and model performance. Here’s a simple Python code snippet to demonstrate how a linear regression model works:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Generate some random data</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create a DataFrame from the data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">])</span>

<span class="c1"># Create the &#39;Temp&#39; directory if it doesn&#39;t exist</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;./tmp&#39;</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s1">&#39;./tmp&#39;</span><span class="p">)</span>

<span class="c1"># Save the data to a CSV file in the &#39;Temp&#39; directory</span>
<span class="n">data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;./tmp/data.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Plot the data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/linear-regression-from-scratch_6_0.png" src="../../../_images/linear-regression-from-scratch_6_0.png" />
</div>
</div>
</section>
<section id="data-preparation">
<h2><span class="section-number">40.49.2. </span>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">#</a></h2>
<p>Before we can start developing the linear regression model, it is important to prepare the data appropriately. This involves importing the necessary libraries, loading the dataset, performing exploratory data analysis, and cleaning and preprocessing the data.</p>
<p>Let’s take a look at the code snippet below to understand how we can perform these steps:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the necessary libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Load the dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./Temp/data.csv&#39;</span><span class="p">)</span>

<span class="c1"># Perform exploratory data analysis</span>
<span class="c1"># Display the first few rows of the data</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="c1"># Split the dataset into training and testing sets</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;X&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Visualize the relationship between features and target variable</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Set&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testing Set&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Print the sizes of training and testing sets</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set size:&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing set size:&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>          X         y
0  0.749080  6.334288
1  1.901429  9.405278
2  1.463988  8.483724
3  1.197317  5.604382
4  0.312037  4.716440
</pre></div>
</div>
<img alt="../../../_images/linear-regression-from-scratch_8_1.png" src="../../../_images/linear-regression-from-scratch_8_1.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set size: (80, 1) (80,)
Testing set size: (20, 1) (20,)
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-development">
<h2><span class="section-number">40.49.3. </span>Model Development<a class="headerlink" href="#model-development" title="Permalink to this headline">#</a></h2>
<p>Once we have prepared the data, we can proceed with developing the linear regression model. This involves deriving the mathematical formula for linear regression, implementing the formula in code, defining a cost function, and implementing the gradient descent algorithm to train the model.</p>
<p>Let’s take a look at the code snippet below to understand how we can develop the linear regression model:</p>
<section id="define-loss-function">
<h3><span class="section-number">40.49.3.1. </span>Define loss function<a class="headerlink" href="#define-loss-function" title="Permalink to this headline">#</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Calculate the loss between the true target variable and the predicted target variable.

Parameters:
- y_true: The true target variable (numpy array or pandas Series)
- y_pred: The predicted target variable (numpy array or pandas Series)

Returns:
- loss: The calculated loss (float)
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the loss function</span>
<span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="c1"># Calculate the mean squared error</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mse</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="use-gradient-descent-to-train-the-model">
<h3><span class="section-number">40.49.3.2. </span>Use gradient descent to train the model<a class="headerlink" href="#use-gradient-descent-to-train-the-model" title="Permalink to this headline">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">gradient_descent</span></code> function is responsible for performing gradient descent to optimize the coefficients of the linear regression model. Here is a breakdown of the steps involved:</p>
<ol class="simple">
<li><p>Scale the data: The input features (<code class="docutils literal notranslate"><span class="pre">X_train</span></code> and <code class="docutils literal notranslate"><span class="pre">X_test</span></code>) are scaled using the <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> from scikit-learn. This ensures that all features have a similar scale, which can improve the performance of the gradient descent algorithm.</p></li>
<li><p>Add a bias term: A column of ones is added to the input features (<code class="docutils literal notranslate"><span class="pre">X_train</span></code>) to account for the bias term in the linear regression model.</p></li>
<li><p>Initialize coefficients: The coefficients are initialized with zeros. The number of coefficients is equal to the number of features plus one (including the bias term).</p></li>
<li><p>Perform gradient descent: The function iterates over a specified number of iterations. In each iteration, the following steps are performed:</p>
<ul class="simple">
<li><p>Compute the predictions (<code class="docutils literal notranslate"><span class="pre">y_pred</span></code>) by multiplying the input features (<code class="docutils literal notranslate"><span class="pre">X_train_with_bias</span></code>) with the coefficients.</p></li>
<li><p>Compute the gradients by taking the dot product of the transposed input features (<code class="docutils literal notranslate"><span class="pre">X_train_with_bias.T</span></code>) and the difference between the predictions and the true target variable (<code class="docutils literal notranslate"><span class="pre">y_train</span></code>).</p></li>
<li><p>Update the coefficients by subtracting the learning rate multiplied by the gradients.</p></li>
<li><p>Compute the loss by calculating the mean squared error between the true target variable (<code class="docutils literal notranslate"><span class="pre">y_train</span></code>) and the predictions (<code class="docutils literal notranslate"><span class="pre">y_pred</span></code>).</p></li>
</ul>
</li>
<li><p>Make predictions on the test set: The function applies the same preprocessing steps to the test set (<code class="docutils literal notranslate"><span class="pre">X_test</span></code>) and computes the predictions (<code class="docutils literal notranslate"><span class="pre">y_pred_test</span></code>) using the updated coefficients.</p></li>
</ol>
<p>This function is a key component in training the linear regression model from scratch. It allows us to iteratively update the coefficients based on the gradients, gradually improving the model’s performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the gradient descent function</span>
<span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">):</span>
    <span class="c1"># Scale the data</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
    <span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Add a column of ones to X for the bias term</span>
    <span class="n">X_train_with_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X_train_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X_train_scaled</span><span class="p">]</span>

    <span class="c1"># Initialize the coefficients with zeros</span>
    <span class="n">coefficients</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X_train_with_bias</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Perform gradient descent</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
        <span class="c1"># Compute the predictions</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">X_train_with_bias</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">coefficients</span><span class="p">)</span>

        <span class="c1"># Compute the gradients</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">X_train_with_bias</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> 

        <span class="c1"># Update the coefficients</span>
        <span class="n">coefficients</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients</span>

        <span class="c1"># Compute the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration:&quot;</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Loss:&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

    <span class="c1"># Make predictions on the test set</span>
    <span class="n">X_test_with_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X_test_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X_test_scaled</span><span class="p">]</span>
    <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">X_test_with_bias</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">coefficients</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">y_pred_test</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we train the linear regression model and make predictions on the test set.</p>
<p>First, we import the required library and set the learning rate and number of iterations for gradient descent. We then call the gradient descent function and pass in the training and test data, the learning rate, and the number of iterations. The function returns the optimised coefficients and predictions for the test set. Finally, we store the returned results in the variables coefficients and ypred test.</p>
<p>By running this code, we can train a linear regression model using gradient descent and get the prediction results on the test set to further analyse and evaluate the performance of the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="c1"># Perform gradient descent to train the model</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">coefficients</span><span class="p">,</span> <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration: 1 Loss: 49.252973836909085
Iteration: 2 Loss: 18.27358504939668
Iteration: 3 Loss: 7.121005085892223
Iteration: 4 Loss: 3.1060762990306165
Iteration: 5 Loss: 1.6607019357604422
Iteration: 6 Loss: 1.1403671649831801
Iteration: 7 Loss: 0.9530466475033655
Iteration: 8 Loss: 0.8856112612106326
Iteration: 9 Loss: 0.8613345221452491
Iteration: 10 Loss: 0.8525948960817107
Iteration: 11 Loss: 0.8494486306988371
Iteration: 12 Loss: 0.8483159751610024
Iteration: 13 Loss: 0.8479082191673818
Iteration: 14 Loss: 0.8477614270096787
Iteration: 15 Loss: 0.8477085818329055
Iteration: 16 Loss: 0.8476895575692671
Iteration: 17 Loss: 0.8476827088343573
Iteration: 18 Loss: 0.8476802432897899
Iteration: 19 Loss: 0.8476793556937455
Iteration: 20 Loss: 0.8476790361591695
Iteration: 21 Loss: 0.847678921126722
Iteration: 22 Loss: 0.8476788797150412
Iteration: 23 Loss: 0.8476788648068361
Iteration: 24 Loss: 0.8476788594398821
Iteration: 25 Loss: 0.8476788575077785
Iteration: 26 Loss: 0.8476788568122215
Iteration: 27 Loss: 0.847678856561821
Iteration: 28 Loss: 0.8476788564716766
Iteration: 29 Loss: 0.8476788564392248
Iteration: 30 Loss: 0.847678856427542
Iteration: 31 Loss: 0.8476788564233363
Iteration: 32 Loss: 0.8476788564218222
Iteration: 33 Loss: 0.8476788564212772
Iteration: 34 Loss: 0.8476788564210811
Iteration: 35 Loss: 0.8476788564210102
Iteration: 36 Loss: 0.8476788564209847
Iteration: 37 Loss: 0.8476788564209757
Iteration: 38 Loss: 0.8476788564209723
Iteration: 39 Loss: 0.8476788564209713
Iteration: 40 Loss: 0.8476788564209707
Iteration: 41 Loss: 0.8476788564209705
Iteration: 42 Loss: 0.8476788564209705
Iteration: 43 Loss: 0.8476788564209705
Iteration: 44 Loss: 0.8476788564209704
Iteration: 45 Loss: 0.8476788564209707
Iteration: 46 Loss: 0.8476788564209705
Iteration: 47 Loss: 0.8476788564209705
Iteration: 48 Loss: 0.8476788564209705
Iteration: 49 Loss: 0.8476788564209705
Iteration: 50 Loss: 0.8476788564209705
Iteration: 51 Loss: 0.8476788564209705
Iteration: 52 Loss: 0.8476788564209705
Iteration: 53 Loss: 0.8476788564209705
Iteration: 54 Loss: 0.8476788564209705
Iteration: 55 Loss: 0.8476788564209704
Iteration: 56 Loss: 0.8476788564209705
Iteration: 57 Loss: 0.8476788564209705
Iteration: 58 Loss: 0.8476788564209705
Iteration: 59 Loss: 0.8476788564209705
Iteration: 60 Loss: 0.8476788564209705
Iteration: 61 Loss: 0.8476788564209704
Iteration: 62 Loss: 0.8476788564209705
Iteration: 63 Loss: 0.8476788564209705
Iteration: 64 Loss: 0.8476788564209705
Iteration: 65 Loss: 0.8476788564209705
Iteration: 66 Loss: 0.8476788564209705
Iteration: 67 Loss: 0.8476788564209705
Iteration: 68 Loss: 0.8476788564209704
Iteration: 69 Loss: 0.8476788564209705
Iteration: 70 Loss: 0.8476788564209705
Iteration: 71 Loss: 0.8476788564209705
Iteration: 72 Loss: 0.8476788564209707
Iteration: 73 Loss: 0.8476788564209705
Iteration: 74 Loss: 0.8476788564209705
Iteration: 75 Loss: 0.8476788564209705
Iteration: 76 Loss: 0.8476788564209705
Iteration: 77 Loss: 0.8476788564209705
Iteration: 78 Loss: 0.8476788564209705
Iteration: 79 Loss: 0.8476788564209705
Iteration: 80 Loss: 0.8476788564209705
Iteration: 81 Loss: 0.8476788564209705
Iteration: 82 Loss: 0.8476788564209705
Iteration: 83 Loss: 0.8476788564209705
Iteration: 84 Loss: 0.8476788564209705
Iteration: 85 Loss: 0.8476788564209705
Iteration: 86 Loss: 0.8476788564209705
Iteration: 87 Loss: 0.8476788564209705
Iteration: 88 Loss: 0.8476788564209705
Iteration: 89 Loss: 0.8476788564209705
Iteration: 90 Loss: 0.8476788564209705
Iteration: 91 Loss: 0.8476788564209705
Iteration: 92 Loss: 0.8476788564209705
Iteration: 93 Loss: 0.8476788564209705
Iteration: 94 Loss: 0.8476788564209705
Iteration: 95 Loss: 0.8476788564209705
Iteration: 96 Loss: 0.8476788564209705
Iteration: 97 Loss: 0.8476788564209705
Iteration: 98 Loss: 0.8476788564209705
Iteration: 99 Loss: 0.8476788564209705
Iteration: 100 Loss: 0.8476788564209705
Iteration: 101 Loss: 0.8476788564209705
Iteration: 102 Loss: 0.8476788564209705
Iteration: 103 Loss: 0.8476788564209705
Iteration: 104 Loss: 0.8476788564209705
Iteration: 105 Loss: 0.8476788564209705
Iteration: 106 Loss: 0.8476788564209705
Iteration: 107 Loss: 0.8476788564209705
Iteration: 108 Loss: 0.8476788564209705
Iteration: 109 Loss: 0.8476788564209705
Iteration: 110 Loss: 0.8476788564209705
Iteration: 111 Loss: 0.8476788564209705
Iteration: 112 Loss: 0.8476788564209705
Iteration: 113 Loss: 0.8476788564209705
Iteration: 114 Loss: 0.8476788564209705
Iteration: 115 Loss: 0.8476788564209705
Iteration: 116 Loss: 0.8476788564209705
Iteration: 117 Loss: 0.8476788564209705
Iteration: 118 Loss: 0.8476788564209705
Iteration: 119 Loss: 0.8476788564209705
Iteration: 120 Loss: 0.8476788564209705
Iteration: 121 Loss: 0.8476788564209705
Iteration: 122 Loss: 0.8476788564209705
Iteration: 123 Loss: 0.8476788564209705
Iteration: 124 Loss: 0.8476788564209705
Iteration: 125 Loss: 0.8476788564209705
Iteration: 126 Loss: 0.8476788564209705
Iteration: 127 Loss: 0.8476788564209705
Iteration: 128 Loss: 0.8476788564209705
Iteration: 129 Loss: 0.8476788564209705
Iteration: 130 Loss: 0.8476788564209705
Iteration: 131 Loss: 0.8476788564209705
Iteration: 132 Loss: 0.8476788564209705
Iteration: 133 Loss: 0.8476788564209705
Iteration: 134 Loss: 0.8476788564209705
Iteration: 135 Loss: 0.8476788564209705
Iteration: 136 Loss: 0.8476788564209705
Iteration: 137 Loss: 0.8476788564209705
Iteration: 138 Loss: 0.8476788564209705
Iteration: 139 Loss: 0.8476788564209705
Iteration: 140 Loss: 0.8476788564209705
Iteration: 141 Loss: 0.8476788564209705
Iteration: 142 Loss: 0.8476788564209705
Iteration: 143 Loss: 0.8476788564209705
Iteration: 144 Loss: 0.8476788564209705
Iteration: 145 Loss: 0.8476788564209705
Iteration: 146 Loss: 0.8476788564209705
Iteration: 147 Loss: 0.8476788564209705
Iteration: 148 Loss: 0.8476788564209705
Iteration: 149 Loss: 0.8476788564209705
Iteration: 150 Loss: 0.8476788564209705
Iteration: 151 Loss: 0.8476788564209705
Iteration: 152 Loss: 0.8476788564209705
Iteration: 153 Loss: 0.8476788564209705
Iteration: 154 Loss: 0.8476788564209705
Iteration: 155 Loss: 0.8476788564209705
Iteration: 156 Loss: 0.8476788564209705
Iteration: 157 Loss: 0.8476788564209705
Iteration: 158 Loss: 0.8476788564209705
Iteration: 159 Loss: 0.8476788564209705
Iteration: 160 Loss: 0.8476788564209705
Iteration: 161 Loss: 0.8476788564209705
Iteration: 162 Loss: 0.8476788564209705
Iteration: 163 Loss: 0.8476788564209705
Iteration: 164 Loss: 0.8476788564209705
Iteration: 165 Loss: 0.8476788564209705
Iteration: 166 Loss: 0.8476788564209705
Iteration: 167 Loss: 0.8476788564209705
Iteration: 168 Loss: 0.8476788564209705
Iteration: 169 Loss: 0.8476788564209705
Iteration: 170 Loss: 0.8476788564209705
Iteration: 171 Loss: 0.8476788564209705
Iteration: 172 Loss: 0.8476788564209705
Iteration: 173 Loss: 0.8476788564209705
Iteration: 174 Loss: 0.8476788564209705
Iteration: 175 Loss: 0.8476788564209705
Iteration: 176 Loss: 0.8476788564209705
Iteration: 177 Loss: 0.8476788564209705
Iteration: 178 Loss: 0.8476788564209705
Iteration: 179 Loss: 0.8476788564209705
Iteration: 180 Loss: 0.8476788564209705
Iteration: 181 Loss: 0.8476788564209705
Iteration: 182 Loss: 0.8476788564209705
Iteration: 183 Loss: 0.8476788564209705
Iteration: 184 Loss: 0.8476788564209705
Iteration: 185 Loss: 0.8476788564209705
Iteration: 186 Loss: 0.8476788564209705
Iteration: 187 Loss: 0.8476788564209705
Iteration: 188 Loss: 0.8476788564209705
Iteration: 189 Loss: 0.8476788564209705
Iteration: 190 Loss: 0.8476788564209705
Iteration: 191 Loss: 0.8476788564209705
Iteration: 192 Loss: 0.8476788564209705
Iteration: 193 Loss: 0.8476788564209705
Iteration: 194 Loss: 0.8476788564209705
Iteration: 195 Loss: 0.8476788564209705
Iteration: 196 Loss: 0.8476788564209705
Iteration: 197 Loss: 0.8476788564209705
Iteration: 198 Loss: 0.8476788564209705
Iteration: 199 Loss: 0.8476788564209705
Iteration: 200 Loss: 0.8476788564209705
Iteration: 201 Loss: 0.8476788564209705
Iteration: 202 Loss: 0.8476788564209705
Iteration: 203 Loss: 0.8476788564209705
Iteration: 204 Loss: 0.8476788564209705
Iteration: 205 Loss: 0.8476788564209705
Iteration: 206 Loss: 0.8476788564209705
Iteration: 207 Loss: 0.8476788564209705
Iteration: 208 Loss: 0.8476788564209705
Iteration: 209 Loss: 0.8476788564209705
Iteration: 210 Loss: 0.8476788564209705
Iteration: 211 Loss: 0.8476788564209705
Iteration: 212 Loss: 0.8476788564209705
Iteration: 213 Loss: 0.8476788564209705
Iteration: 214 Loss: 0.8476788564209705
Iteration: 215 Loss: 0.8476788564209705
Iteration: 216 Loss: 0.8476788564209705
Iteration: 217 Loss: 0.8476788564209705
Iteration: 218 Loss: 0.8476788564209705
Iteration: 219 Loss: 0.8476788564209705
Iteration: 220 Loss: 0.8476788564209705
Iteration: 221 Loss: 0.8476788564209705
Iteration: 222 Loss: 0.8476788564209705
Iteration: 223 Loss: 0.8476788564209705
Iteration: 224 Loss: 0.8476788564209705
Iteration: 225 Loss: 0.8476788564209705
Iteration: 226 Loss: 0.8476788564209705
Iteration: 227 Loss: 0.8476788564209705
Iteration: 228 Loss: 0.8476788564209705
Iteration: 229 Loss: 0.8476788564209705
Iteration: 230 Loss: 0.8476788564209705
Iteration: 231 Loss: 0.8476788564209705
Iteration: 232 Loss: 0.8476788564209705
Iteration: 233 Loss: 0.8476788564209705
Iteration: 234 Loss: 0.8476788564209705
Iteration: 235 Loss: 0.8476788564209705
Iteration: 236 Loss: 0.8476788564209705
Iteration: 237 Loss: 0.8476788564209705
Iteration: 238 Loss: 0.8476788564209705
Iteration: 239 Loss: 0.8476788564209705
Iteration: 240 Loss: 0.8476788564209705
Iteration: 241 Loss: 0.8476788564209705
Iteration: 242 Loss: 0.8476788564209705
Iteration: 243 Loss: 0.8476788564209705
Iteration: 244 Loss: 0.8476788564209705
Iteration: 245 Loss: 0.8476788564209705
Iteration: 246 Loss: 0.8476788564209705
Iteration: 247 Loss: 0.8476788564209705
Iteration: 248 Loss: 0.8476788564209705
Iteration: 249 Loss: 0.8476788564209705
Iteration: 250 Loss: 0.8476788564209705
Iteration: 251 Loss: 0.8476788564209705
Iteration: 252 Loss: 0.8476788564209705
Iteration: 253 Loss: 0.8476788564209705
Iteration: 254 Loss: 0.8476788564209705
Iteration: 255 Loss: 0.8476788564209705
Iteration: 256 Loss: 0.8476788564209705
Iteration: 257 Loss: 0.8476788564209705
Iteration: 258 Loss: 0.8476788564209705
Iteration: 259 Loss: 0.8476788564209705
Iteration: 260 Loss: 0.8476788564209705
Iteration: 261 Loss: 0.8476788564209705
Iteration: 262 Loss: 0.8476788564209705
Iteration: 263 Loss: 0.8476788564209705
Iteration: 264 Loss: 0.8476788564209705
Iteration: 265 Loss: 0.8476788564209705
Iteration: 266 Loss: 0.8476788564209705
Iteration: 267 Loss: 0.8476788564209705
Iteration: 268 Loss: 0.8476788564209705
Iteration: 269 Loss: 0.8476788564209705
Iteration: 270 Loss: 0.8476788564209705
Iteration: 271 Loss: 0.8476788564209705
Iteration: 272 Loss: 0.8476788564209705
Iteration: 273 Loss: 0.8476788564209705
Iteration: 274 Loss: 0.8476788564209705
Iteration: 275 Loss: 0.8476788564209705
Iteration: 276 Loss: 0.8476788564209705
Iteration: 277 Loss: 0.8476788564209705
Iteration: 278 Loss: 0.8476788564209705
Iteration: 279 Loss: 0.8476788564209705
Iteration: 280 Loss: 0.8476788564209705
Iteration: 281 Loss: 0.8476788564209705
Iteration: 282 Loss: 0.8476788564209705
Iteration: 283 Loss: 0.8476788564209705
Iteration: 284 Loss: 0.8476788564209705
Iteration: 285 Loss: 0.8476788564209705
Iteration: 286 Loss: 0.8476788564209705
Iteration: 287 Loss: 0.8476788564209705
Iteration: 288 Loss: 0.8476788564209705
Iteration: 289 Loss: 0.8476788564209705
Iteration: 290 Loss: 0.8476788564209705
Iteration: 291 Loss: 0.8476788564209705
Iteration: 292 Loss: 0.8476788564209705
Iteration: 293 Loss: 0.8476788564209705
Iteration: 294 Loss: 0.8476788564209705
Iteration: 295 Loss: 0.8476788564209705
Iteration: 296 Loss: 0.8476788564209705
Iteration: 297 Loss: 0.8476788564209705
Iteration: 298 Loss: 0.8476788564209705
Iteration: 299 Loss: 0.8476788564209705
Iteration: 300 Loss: 0.8476788564209705
Iteration: 301 Loss: 0.8476788564209705
Iteration: 302 Loss: 0.8476788564209705
Iteration: 303 Loss: 0.8476788564209705
Iteration: 304 Loss: 0.8476788564209705
Iteration: 305 Loss: 0.8476788564209705
Iteration: 306 Loss: 0.8476788564209705
Iteration: 307 Loss: 0.8476788564209705
Iteration: 308 Loss: 0.8476788564209705
Iteration: 309 Loss: 0.8476788564209705
Iteration: 310 Loss: 0.8476788564209705
Iteration: 311 Loss: 0.8476788564209705
Iteration: 312 Loss: 0.8476788564209705
Iteration: 313 Loss: 0.8476788564209705
Iteration: 314 Loss: 0.8476788564209705
Iteration: 315 Loss: 0.8476788564209705
Iteration: 316 Loss: 0.8476788564209705
Iteration: 317 Loss: 0.8476788564209705
Iteration: 318 Loss: 0.8476788564209705
Iteration: 319 Loss: 0.8476788564209705
Iteration: 320 Loss: 0.8476788564209705
Iteration: 321 Loss: 0.8476788564209705
Iteration: 322 Loss: 0.8476788564209705
Iteration: 323 Loss: 0.8476788564209705
Iteration: 324 Loss: 0.8476788564209705
Iteration: 325 Loss: 0.8476788564209705
Iteration: 326 Loss: 0.8476788564209705
Iteration: 327 Loss: 0.8476788564209705
Iteration: 328 Loss: 0.8476788564209705
Iteration: 329 Loss: 0.8476788564209705
Iteration: 330 Loss: 0.8476788564209705
Iteration: 331 Loss: 0.8476788564209705
Iteration: 332 Loss: 0.8476788564209705
Iteration: 333 Loss: 0.8476788564209705
Iteration: 334 Loss: 0.8476788564209705
Iteration: 335 Loss: 0.8476788564209705
Iteration: 336 Loss: 0.8476788564209705
Iteration: 337 Loss: 0.8476788564209705
Iteration: 338 Loss: 0.8476788564209705
Iteration: 339 Loss: 0.8476788564209705
Iteration: 340 Loss: 0.8476788564209705
Iteration: 341 Loss: 0.8476788564209705
Iteration: 342 Loss: 0.8476788564209705
Iteration: 343 Loss: 0.8476788564209705
Iteration: 344 Loss: 0.8476788564209705
Iteration: 345 Loss: 0.8476788564209705
Iteration: 346 Loss: 0.8476788564209705
Iteration: 347 Loss: 0.8476788564209705
Iteration: 348 Loss: 0.8476788564209705
Iteration: 349 Loss: 0.8476788564209705
Iteration: 350 Loss: 0.8476788564209705
Iteration: 351 Loss: 0.8476788564209705
Iteration: 352 Loss: 0.8476788564209705
Iteration: 353 Loss: 0.8476788564209705
Iteration: 354 Loss: 0.8476788564209705
Iteration: 355 Loss: 0.8476788564209705
Iteration: 356 Loss: 0.8476788564209705
Iteration: 357 Loss: 0.8476788564209705
Iteration: 358 Loss: 0.8476788564209705
Iteration: 359 Loss: 0.8476788564209705
Iteration: 360 Loss: 0.8476788564209705
Iteration: 361 Loss: 0.8476788564209705
Iteration: 362 Loss: 0.8476788564209705
Iteration: 363 Loss: 0.8476788564209705
Iteration: 364 Loss: 0.8476788564209705
Iteration: 365 Loss: 0.8476788564209705
Iteration: 366 Loss: 0.8476788564209705
Iteration: 367 Loss: 0.8476788564209705
Iteration: 368 Loss: 0.8476788564209705
Iteration: 369 Loss: 0.8476788564209705
Iteration: 370 Loss: 0.8476788564209705
Iteration: 371 Loss: 0.8476788564209705
Iteration: 372 Loss: 0.8476788564209705
Iteration: 373 Loss: 0.8476788564209705
Iteration: 374 Loss: 0.8476788564209705
Iteration: 375 Loss: 0.8476788564209705
Iteration: 376 Loss: 0.8476788564209705
Iteration: 377 Loss: 0.8476788564209705
Iteration: 378 Loss: 0.8476788564209705
Iteration: 379 Loss: 0.8476788564209705
Iteration: 380 Loss: 0.8476788564209705
Iteration: 381 Loss: 0.8476788564209705
Iteration: 382 Loss: 0.8476788564209705
Iteration: 383 Loss: 0.8476788564209705
Iteration: 384 Loss: 0.8476788564209705
Iteration: 385 Loss: 0.8476788564209705
Iteration: 386 Loss: 0.8476788564209705
Iteration: 387 Loss: 0.8476788564209705
Iteration: 388 Loss: 0.8476788564209705
Iteration: 389 Loss: 0.8476788564209705
Iteration: 390 Loss: 0.8476788564209705
Iteration: 391 Loss: 0.8476788564209705
Iteration: 392 Loss: 0.8476788564209705
Iteration: 393 Loss: 0.8476788564209705
Iteration: 394 Loss: 0.8476788564209705
Iteration: 395 Loss: 0.8476788564209705
Iteration: 396 Loss: 0.8476788564209705
Iteration: 397 Loss: 0.8476788564209705
Iteration: 398 Loss: 0.8476788564209705
Iteration: 399 Loss: 0.8476788564209705
Iteration: 400 Loss: 0.8476788564209705
Iteration: 401 Loss: 0.8476788564209705
Iteration: 402 Loss: 0.8476788564209705
Iteration: 403 Loss: 0.8476788564209705
Iteration: 404 Loss: 0.8476788564209705
Iteration: 405 Loss: 0.8476788564209705
Iteration: 406 Loss: 0.8476788564209705
Iteration: 407 Loss: 0.8476788564209705
Iteration: 408 Loss: 0.8476788564209705
Iteration: 409 Loss: 0.8476788564209705
Iteration: 410 Loss: 0.8476788564209705
Iteration: 411 Loss: 0.8476788564209705
Iteration: 412 Loss: 0.8476788564209705
Iteration: 413 Loss: 0.8476788564209705
Iteration: 414 Loss: 0.8476788564209705
Iteration: 415 Loss: 0.8476788564209705
Iteration: 416 Loss: 0.8476788564209705
Iteration: 417 Loss: 0.8476788564209705
Iteration: 418 Loss: 0.8476788564209705
Iteration: 419 Loss: 0.8476788564209705
Iteration: 420 Loss: 0.8476788564209705
Iteration: 421 Loss: 0.8476788564209705
Iteration: 422 Loss: 0.8476788564209705
Iteration: 423 Loss: 0.8476788564209705
Iteration: 424 Loss: 0.8476788564209705
Iteration: 425 Loss: 0.8476788564209705
Iteration: 426 Loss: 0.8476788564209705
Iteration: 427 Loss: 0.8476788564209705
Iteration: 428 Loss: 0.8476788564209705
Iteration: 429 Loss: 0.8476788564209705
Iteration: 430 Loss: 0.8476788564209705
Iteration: 431 Loss: 0.8476788564209705
Iteration: 432 Loss: 0.8476788564209705
Iteration: 433 Loss: 0.8476788564209705
Iteration: 434 Loss: 0.8476788564209705
Iteration: 435 Loss: 0.8476788564209705
Iteration: 436 Loss: 0.8476788564209705
Iteration: 437 Loss: 0.8476788564209705
Iteration: 438 Loss: 0.8476788564209705
Iteration: 439 Loss: 0.8476788564209705
Iteration: 440 Loss: 0.8476788564209705
Iteration: 441 Loss: 0.8476788564209705
Iteration: 442 Loss: 0.8476788564209705
Iteration: 443 Loss: 0.8476788564209705
Iteration: 444 Loss: 0.8476788564209705
Iteration: 445 Loss: 0.8476788564209705
Iteration: 446 Loss: 0.8476788564209705
Iteration: 447 Loss: 0.8476788564209705
Iteration: 448 Loss: 0.8476788564209705
Iteration: 449 Loss: 0.8476788564209705
Iteration: 450 Loss: 0.8476788564209705
Iteration: 451 Loss: 0.8476788564209705
Iteration: 452 Loss: 0.8476788564209705
Iteration: 453 Loss: 0.8476788564209705
Iteration: 454 Loss: 0.8476788564209705
Iteration: 455 Loss: 0.8476788564209705
Iteration: 456 Loss: 0.8476788564209705
Iteration: 457 Loss: 0.8476788564209705
Iteration: 458 Loss: 0.8476788564209705
Iteration: 459 Loss: 0.8476788564209705
Iteration: 460 Loss: 0.8476788564209705
Iteration: 461 Loss: 0.8476788564209705
Iteration: 462 Loss: 0.8476788564209705
Iteration: 463 Loss: 0.8476788564209705
Iteration: 464 Loss: 0.8476788564209705
Iteration: 465 Loss: 0.8476788564209705
Iteration: 466 Loss: 0.8476788564209705
Iteration: 467 Loss: 0.8476788564209705
Iteration: 468 Loss: 0.8476788564209705
Iteration: 469 Loss: 0.8476788564209705
Iteration: 470 Loss: 0.8476788564209705
Iteration: 471 Loss: 0.8476788564209705
Iteration: 472 Loss: 0.8476788564209705
Iteration: 473 Loss: 0.8476788564209705
Iteration: 474 Loss: 0.8476788564209705
Iteration: 475 Loss: 0.8476788564209705
Iteration: 476 Loss: 0.8476788564209705
Iteration: 477 Loss: 0.8476788564209705
Iteration: 478 Loss: 0.8476788564209705
Iteration: 479 Loss: 0.8476788564209705
Iteration: 480 Loss: 0.8476788564209705
Iteration: 481 Loss: 0.8476788564209705
Iteration: 482 Loss: 0.8476788564209705
Iteration: 483 Loss: 0.8476788564209705
Iteration: 484 Loss: 0.8476788564209705
Iteration: 485 Loss: 0.8476788564209705
Iteration: 486 Loss: 0.8476788564209705
Iteration: 487 Loss: 0.8476788564209705
Iteration: 488 Loss: 0.8476788564209705
Iteration: 489 Loss: 0.8476788564209705
Iteration: 490 Loss: 0.8476788564209705
Iteration: 491 Loss: 0.8476788564209705
Iteration: 492 Loss: 0.8476788564209705
Iteration: 493 Loss: 0.8476788564209705
Iteration: 494 Loss: 0.8476788564209705
Iteration: 495 Loss: 0.8476788564209705
Iteration: 496 Loss: 0.8476788564209705
Iteration: 497 Loss: 0.8476788564209705
Iteration: 498 Loss: 0.8476788564209705
Iteration: 499 Loss: 0.8476788564209705
Iteration: 500 Loss: 0.8476788564209705
Iteration: 501 Loss: 0.8476788564209705
Iteration: 502 Loss: 0.8476788564209705
Iteration: 503 Loss: 0.8476788564209705
Iteration: 504 Loss: 0.8476788564209705
Iteration: 505 Loss: 0.8476788564209705
Iteration: 506 Loss: 0.8476788564209705
Iteration: 507 Loss: 0.8476788564209705
Iteration: 508 Loss: 0.8476788564209705
Iteration: 509 Loss: 0.8476788564209705
Iteration: 510 Loss: 0.8476788564209705
Iteration: 511 Loss: 0.8476788564209705
Iteration: 512 Loss: 0.8476788564209705
Iteration: 513 Loss: 0.8476788564209705
Iteration: 514 Loss: 0.8476788564209705
Iteration: 515 Loss: 0.8476788564209705
Iteration: 516 Loss: 0.8476788564209705
Iteration: 517 Loss: 0.8476788564209705
Iteration: 518 Loss: 0.8476788564209705
Iteration: 519 Loss: 0.8476788564209705
Iteration: 520 Loss: 0.8476788564209705
Iteration: 521 Loss: 0.8476788564209705
Iteration: 522 Loss: 0.8476788564209705
Iteration: 523 Loss: 0.8476788564209705
Iteration: 524 Loss: 0.8476788564209705
Iteration: 525 Loss: 0.8476788564209705
Iteration: 526 Loss: 0.8476788564209705
Iteration: 527 Loss: 0.8476788564209705
Iteration: 528 Loss: 0.8476788564209705
Iteration: 529 Loss: 0.8476788564209705
Iteration: 530 Loss: 0.8476788564209705
Iteration: 531 Loss: 0.8476788564209705
Iteration: 532 Loss: 0.8476788564209705
Iteration: 533 Loss: 0.8476788564209705
Iteration: 534 Loss: 0.8476788564209705
Iteration: 535 Loss: 0.8476788564209705
Iteration: 536 Loss: 0.8476788564209705
Iteration: 537 Loss: 0.8476788564209705
Iteration: 538 Loss: 0.8476788564209705
Iteration: 539 Loss: 0.8476788564209705
Iteration: 540 Loss: 0.8476788564209705
Iteration: 541 Loss: 0.8476788564209705
Iteration: 542 Loss: 0.8476788564209705
Iteration: 543 Loss: 0.8476788564209705
Iteration: 544 Loss: 0.8476788564209705
Iteration: 545 Loss: 0.8476788564209705
Iteration: 546 Loss: 0.8476788564209705
Iteration: 547 Loss: 0.8476788564209705
Iteration: 548 Loss: 0.8476788564209705
Iteration: 549 Loss: 0.8476788564209705
Iteration: 550 Loss: 0.8476788564209705
Iteration: 551 Loss: 0.8476788564209705
Iteration: 552 Loss: 0.8476788564209705
Iteration: 553 Loss: 0.8476788564209705
Iteration: 554 Loss: 0.8476788564209705
Iteration: 555 Loss: 0.8476788564209705
Iteration: 556 Loss: 0.8476788564209705
Iteration: 557 Loss: 0.8476788564209705
Iteration: 558 Loss: 0.8476788564209705
Iteration: 559 Loss: 0.8476788564209705
Iteration: 560 Loss: 0.8476788564209705
Iteration: 561 Loss: 0.8476788564209705
Iteration: 562 Loss: 0.8476788564209705
Iteration: 563 Loss: 0.8476788564209705
Iteration: 564 Loss: 0.8476788564209705
Iteration: 565 Loss: 0.8476788564209705
Iteration: 566 Loss: 0.8476788564209705
Iteration: 567 Loss: 0.8476788564209705
Iteration: 568 Loss: 0.8476788564209705
Iteration: 569 Loss: 0.8476788564209705
Iteration: 570 Loss: 0.8476788564209705
Iteration: 571 Loss: 0.8476788564209705
Iteration: 572 Loss: 0.8476788564209705
Iteration: 573 Loss: 0.8476788564209705
Iteration: 574 Loss: 0.8476788564209705
Iteration: 575 Loss: 0.8476788564209705
Iteration: 576 Loss: 0.8476788564209705
Iteration: 577 Loss: 0.8476788564209705
Iteration: 578 Loss: 0.8476788564209705
Iteration: 579 Loss: 0.8476788564209705
Iteration: 580 Loss: 0.8476788564209705
Iteration: 581 Loss: 0.8476788564209705
Iteration: 582 Loss: 0.8476788564209705
Iteration: 583 Loss: 0.8476788564209705
Iteration: 584 Loss: 0.8476788564209705
Iteration: 585 Loss: 0.8476788564209705
Iteration: 586 Loss: 0.8476788564209705
Iteration: 587 Loss: 0.8476788564209705
Iteration: 588 Loss: 0.8476788564209705
Iteration: 589 Loss: 0.8476788564209705
Iteration: 590 Loss: 0.8476788564209705
Iteration: 591 Loss: 0.8476788564209705
Iteration: 592 Loss: 0.8476788564209705
Iteration: 593 Loss: 0.8476788564209705
Iteration: 594 Loss: 0.8476788564209705
Iteration: 595 Loss: 0.8476788564209705
Iteration: 596 Loss: 0.8476788564209705
Iteration: 597 Loss: 0.8476788564209705
Iteration: 598 Loss: 0.8476788564209705
Iteration: 599 Loss: 0.8476788564209705
Iteration: 600 Loss: 0.8476788564209705
Iteration: 601 Loss: 0.8476788564209705
Iteration: 602 Loss: 0.8476788564209705
Iteration: 603 Loss: 0.8476788564209705
Iteration: 604 Loss: 0.8476788564209705
Iteration: 605 Loss: 0.8476788564209705
Iteration: 606 Loss: 0.8476788564209705
Iteration: 607 Loss: 0.8476788564209705
Iteration: 608 Loss: 0.8476788564209705
Iteration: 609 Loss: 0.8476788564209705
Iteration: 610 Loss: 0.8476788564209705
Iteration: 611 Loss: 0.8476788564209705
Iteration: 612 Loss: 0.8476788564209705
Iteration: 613 Loss: 0.8476788564209705
Iteration: 614 Loss: 0.8476788564209705
Iteration: 615 Loss: 0.8476788564209705
Iteration: 616 Loss: 0.8476788564209705
Iteration: 617 Loss: 0.8476788564209705
Iteration: 618 Loss: 0.8476788564209705
Iteration: 619 Loss: 0.8476788564209705
Iteration: 620 Loss: 0.8476788564209705
Iteration: 621 Loss: 0.8476788564209705
Iteration: 622 Loss: 0.8476788564209705
Iteration: 623 Loss: 0.8476788564209705
Iteration: 624 Loss: 0.8476788564209705
Iteration: 625 Loss: 0.8476788564209705
Iteration: 626 Loss: 0.8476788564209705
Iteration: 627 Loss: 0.8476788564209705
Iteration: 628 Loss: 0.8476788564209705
Iteration: 629 Loss: 0.8476788564209705
Iteration: 630 Loss: 0.8476788564209705
Iteration: 631 Loss: 0.8476788564209705
Iteration: 632 Loss: 0.8476788564209705
Iteration: 633 Loss: 0.8476788564209705
Iteration: 634 Loss: 0.8476788564209705
Iteration: 635 Loss: 0.8476788564209705
Iteration: 636 Loss: 0.8476788564209705
Iteration: 637 Loss: 0.8476788564209705
Iteration: 638 Loss: 0.8476788564209705
Iteration: 639 Loss: 0.8476788564209705
Iteration: 640 Loss: 0.8476788564209705
Iteration: 641 Loss: 0.8476788564209705
Iteration: 642 Loss: 0.8476788564209705
Iteration: 643 Loss: 0.8476788564209705
Iteration: 644 Loss: 0.8476788564209705
Iteration: 645 Loss: 0.8476788564209705
Iteration: 646 Loss: 0.8476788564209705
Iteration: 647 Loss: 0.8476788564209705
Iteration: 648 Loss: 0.8476788564209705
Iteration: 649 Loss: 0.8476788564209705
Iteration: 650 Loss: 0.8476788564209705
Iteration: 651 Loss: 0.8476788564209705
Iteration: 652 Loss: 0.8476788564209705
Iteration: 653 Loss: 0.8476788564209705
Iteration: 654 Loss: 0.8476788564209705
Iteration: 655 Loss: 0.8476788564209705
Iteration: 656 Loss: 0.8476788564209705
Iteration: 657 Loss: 0.8476788564209705
Iteration: 658 Loss: 0.8476788564209705
Iteration: 659 Loss: 0.8476788564209705
Iteration: 660 Loss: 0.8476788564209705
Iteration: 661 Loss: 0.8476788564209705
Iteration: 662 Loss: 0.8476788564209705
Iteration: 663 Loss: 0.8476788564209705
Iteration: 664 Loss: 0.8476788564209705
Iteration: 665 Loss: 0.8476788564209705
Iteration: 666 Loss: 0.8476788564209705
Iteration: 667 Loss: 0.8476788564209705
Iteration: 668 Loss: 0.8476788564209705
Iteration: 669 Loss: 0.8476788564209705
Iteration: 670 Loss: 0.8476788564209705
Iteration: 671 Loss: 0.8476788564209705
Iteration: 672 Loss: 0.8476788564209705
Iteration: 673 Loss: 0.8476788564209705
Iteration: 674 Loss: 0.8476788564209705
Iteration: 675 Loss: 0.8476788564209705
Iteration: 676 Loss: 0.8476788564209705
Iteration: 677 Loss: 0.8476788564209705
Iteration: 678 Loss: 0.8476788564209705
Iteration: 679 Loss: 0.8476788564209705
Iteration: 680 Loss: 0.8476788564209705
Iteration: 681 Loss: 0.8476788564209705
Iteration: 682 Loss: 0.8476788564209705
Iteration: 683 Loss: 0.8476788564209705
Iteration: 684 Loss: 0.8476788564209705
Iteration: 685 Loss: 0.8476788564209705
Iteration: 686 Loss: 0.8476788564209705
Iteration: 687 Loss: 0.8476788564209705
Iteration: 688 Loss: 0.8476788564209705
Iteration: 689 Loss: 0.8476788564209705
Iteration: 690 Loss: 0.8476788564209705
Iteration: 691 Loss: 0.8476788564209705
Iteration: 692 Loss: 0.8476788564209705
Iteration: 693 Loss: 0.8476788564209705
Iteration: 694 Loss: 0.8476788564209705
Iteration: 695 Loss: 0.8476788564209705
Iteration: 696 Loss: 0.8476788564209705
Iteration: 697 Loss: 0.8476788564209705
Iteration: 698 Loss: 0.8476788564209705
Iteration: 699 Loss: 0.8476788564209705
Iteration: 700 Loss: 0.8476788564209705
Iteration: 701 Loss: 0.8476788564209705
Iteration: 702 Loss: 0.8476788564209705
Iteration: 703 Loss: 0.8476788564209705
Iteration: 704 Loss: 0.8476788564209705
Iteration: 705 Loss: 0.8476788564209705
Iteration: 706 Loss: 0.8476788564209705
Iteration: 707 Loss: 0.8476788564209705
Iteration: 708 Loss: 0.8476788564209705
Iteration: 709 Loss: 0.8476788564209705
Iteration: 710 Loss: 0.8476788564209705
Iteration: 711 Loss: 0.8476788564209705
Iteration: 712 Loss: 0.8476788564209705
Iteration: 713 Loss: 0.8476788564209705
Iteration: 714 Loss: 0.8476788564209705
Iteration: 715 Loss: 0.8476788564209705
Iteration: 716 Loss: 0.8476788564209705
Iteration: 717 Loss: 0.8476788564209705
Iteration: 718 Loss: 0.8476788564209705
Iteration: 719 Loss: 0.8476788564209705
Iteration: 720 Loss: 0.8476788564209705
Iteration: 721 Loss: 0.8476788564209705
Iteration: 722 Loss: 0.8476788564209705
Iteration: 723 Loss: 0.8476788564209705
Iteration: 724 Loss: 0.8476788564209705
Iteration: 725 Loss: 0.8476788564209705
Iteration: 726 Loss: 0.8476788564209705
Iteration: 727 Loss: 0.8476788564209705
Iteration: 728 Loss: 0.8476788564209705
Iteration: 729 Loss: 0.8476788564209705
Iteration: 730 Loss: 0.8476788564209705
Iteration: 731 Loss: 0.8476788564209705
Iteration: 732 Loss: 0.8476788564209705
Iteration: 733 Loss: 0.8476788564209705
Iteration: 734 Loss: 0.8476788564209705
Iteration: 735 Loss: 0.8476788564209705
Iteration: 736 Loss: 0.8476788564209705
Iteration: 737 Loss: 0.8476788564209705
Iteration: 738 Loss: 0.8476788564209705
Iteration: 739 Loss: 0.8476788564209705
Iteration: 740 Loss: 0.8476788564209705
Iteration: 741 Loss: 0.8476788564209705
Iteration: 742 Loss: 0.8476788564209705
Iteration: 743 Loss: 0.8476788564209705
Iteration: 744 Loss: 0.8476788564209705
Iteration: 745 Loss: 0.8476788564209705
Iteration: 746 Loss: 0.8476788564209705
Iteration: 747 Loss: 0.8476788564209705
Iteration: 748 Loss: 0.8476788564209705
Iteration: 749 Loss: 0.8476788564209705
Iteration: 750 Loss: 0.8476788564209705
Iteration: 751 Loss: 0.8476788564209705
Iteration: 752 Loss: 0.8476788564209705
Iteration: 753 Loss: 0.8476788564209705
Iteration: 754 Loss: 0.8476788564209705
Iteration: 755 Loss: 0.8476788564209705
Iteration: 756 Loss: 0.8476788564209705
Iteration: 757 Loss: 0.8476788564209705
Iteration: 758 Loss: 0.8476788564209705
Iteration: 759 Loss: 0.8476788564209705
Iteration: 760 Loss: 0.8476788564209705
Iteration: 761 Loss: 0.8476788564209705
Iteration: 762 Loss: 0.8476788564209705
Iteration: 763 Loss: 0.8476788564209705
Iteration: 764 Loss: 0.8476788564209705
Iteration: 765 Loss: 0.8476788564209705
Iteration: 766 Loss: 0.8476788564209705
Iteration: 767 Loss: 0.8476788564209705
Iteration: 768 Loss: 0.8476788564209705
Iteration: 769 Loss: 0.8476788564209705
Iteration: 770 Loss: 0.8476788564209705
Iteration: 771 Loss: 0.8476788564209705
Iteration: 772 Loss: 0.8476788564209705
Iteration: 773 Loss: 0.8476788564209705
Iteration: 774 Loss: 0.8476788564209705
Iteration: 775 Loss: 0.8476788564209705
Iteration: 776 Loss: 0.8476788564209705
Iteration: 777 Loss: 0.8476788564209705
Iteration: 778 Loss: 0.8476788564209705
Iteration: 779 Loss: 0.8476788564209705
Iteration: 780 Loss: 0.8476788564209705
Iteration: 781 Loss: 0.8476788564209705
Iteration: 782 Loss: 0.8476788564209705
Iteration: 783 Loss: 0.8476788564209705
Iteration: 784 Loss: 0.8476788564209705
Iteration: 785 Loss: 0.8476788564209705
Iteration: 786 Loss: 0.8476788564209705
Iteration: 787 Loss: 0.8476788564209705
Iteration: 788 Loss: 0.8476788564209705
Iteration: 789 Loss: 0.8476788564209705
Iteration: 790 Loss: 0.8476788564209705
Iteration: 791 Loss: 0.8476788564209705
Iteration: 792 Loss: 0.8476788564209705
Iteration: 793 Loss: 0.8476788564209705
Iteration: 794 Loss: 0.8476788564209705
Iteration: 795 Loss: 0.8476788564209705
Iteration: 796 Loss: 0.8476788564209705
Iteration: 797 Loss: 0.8476788564209705
Iteration: 798 Loss: 0.8476788564209705
Iteration: 799 Loss: 0.8476788564209705
Iteration: 800 Loss: 0.8476788564209705
Iteration: 801 Loss: 0.8476788564209705
Iteration: 802 Loss: 0.8476788564209705
Iteration: 803 Loss: 0.8476788564209705
Iteration: 804 Loss: 0.8476788564209705
Iteration: 805 Loss: 0.8476788564209705
Iteration: 806 Loss: 0.8476788564209705
Iteration: 807 Loss: 0.8476788564209705
Iteration: 808 Loss: 0.8476788564209705
Iteration: 809 Loss: 0.8476788564209705
Iteration: 810 Loss: 0.8476788564209705
Iteration: 811 Loss: 0.8476788564209705
Iteration: 812 Loss: 0.8476788564209705
Iteration: 813 Loss: 0.8476788564209705
Iteration: 814 Loss: 0.8476788564209705
Iteration: 815 Loss: 0.8476788564209705
Iteration: 816 Loss: 0.8476788564209705
Iteration: 817 Loss: 0.8476788564209705
Iteration: 818 Loss: 0.8476788564209705
Iteration: 819 Loss: 0.8476788564209705
Iteration: 820 Loss: 0.8476788564209705
Iteration: 821 Loss: 0.8476788564209705
Iteration: 822 Loss: 0.8476788564209705
Iteration: 823 Loss: 0.8476788564209705
Iteration: 824 Loss: 0.8476788564209705
Iteration: 825 Loss: 0.8476788564209705
Iteration: 826 Loss: 0.8476788564209705
Iteration: 827 Loss: 0.8476788564209705
Iteration: 828 Loss: 0.8476788564209705
Iteration: 829 Loss: 0.8476788564209705
Iteration: 830 Loss: 0.8476788564209705
Iteration: 831 Loss: 0.8476788564209705
Iteration: 832 Loss: 0.8476788564209705
Iteration: 833 Loss: 0.8476788564209705
Iteration: 834 Loss: 0.8476788564209705
Iteration: 835 Loss: 0.8476788564209705
Iteration: 836 Loss: 0.8476788564209705
Iteration: 837 Loss: 0.8476788564209705
Iteration: 838 Loss: 0.8476788564209705
Iteration: 839 Loss: 0.8476788564209705
Iteration: 840 Loss: 0.8476788564209705
Iteration: 841 Loss: 0.8476788564209705
Iteration: 842 Loss: 0.8476788564209705
Iteration: 843 Loss: 0.8476788564209705
Iteration: 844 Loss: 0.8476788564209705
Iteration: 845 Loss: 0.8476788564209705
Iteration: 846 Loss: 0.8476788564209705
Iteration: 847 Loss: 0.8476788564209705
Iteration: 848 Loss: 0.8476788564209705
Iteration: 849 Loss: 0.8476788564209705
Iteration: 850 Loss: 0.8476788564209705
Iteration: 851 Loss: 0.8476788564209705
Iteration: 852 Loss: 0.8476788564209705
Iteration: 853 Loss: 0.8476788564209705
Iteration: 854 Loss: 0.8476788564209705
Iteration: 855 Loss: 0.8476788564209705
Iteration: 856 Loss: 0.8476788564209705
Iteration: 857 Loss: 0.8476788564209705
Iteration: 858 Loss: 0.8476788564209705
Iteration: 859 Loss: 0.8476788564209705
Iteration: 860 Loss: 0.8476788564209705
Iteration: 861 Loss: 0.8476788564209705
Iteration: 862 Loss: 0.8476788564209705
Iteration: 863 Loss: 0.8476788564209705
Iteration: 864 Loss: 0.8476788564209705
Iteration: 865 Loss: 0.8476788564209705
Iteration: 866 Loss: 0.8476788564209705
Iteration: 867 Loss: 0.8476788564209705
Iteration: 868 Loss: 0.8476788564209705
Iteration: 869 Loss: 0.8476788564209705
Iteration: 870 Loss: 0.8476788564209705
Iteration: 871 Loss: 0.8476788564209705
Iteration: 872 Loss: 0.8476788564209705
Iteration: 873 Loss: 0.8476788564209705
Iteration: 874 Loss: 0.8476788564209705
Iteration: 875 Loss: 0.8476788564209705
Iteration: 876 Loss: 0.8476788564209705
Iteration: 877 Loss: 0.8476788564209705
Iteration: 878 Loss: 0.8476788564209705
Iteration: 879 Loss: 0.8476788564209705
Iteration: 880 Loss: 0.8476788564209705
Iteration: 881 Loss: 0.8476788564209705
Iteration: 882 Loss: 0.8476788564209705
Iteration: 883 Loss: 0.8476788564209705
Iteration: 884 Loss: 0.8476788564209705
Iteration: 885 Loss: 0.8476788564209705
Iteration: 886 Loss: 0.8476788564209705
Iteration: 887 Loss: 0.8476788564209705
Iteration: 888 Loss: 0.8476788564209705
Iteration: 889 Loss: 0.8476788564209705
Iteration: 890 Loss: 0.8476788564209705
Iteration: 891 Loss: 0.8476788564209705
Iteration: 892 Loss: 0.8476788564209705
Iteration: 893 Loss: 0.8476788564209705
Iteration: 894 Loss: 0.8476788564209705
Iteration: 895 Loss: 0.8476788564209705
Iteration: 896 Loss: 0.8476788564209705
Iteration: 897 Loss: 0.8476788564209705
Iteration: 898 Loss: 0.8476788564209705
Iteration: 899 Loss: 0.8476788564209705
Iteration: 900 Loss: 0.8476788564209705
Iteration: 901 Loss: 0.8476788564209705
Iteration: 902 Loss: 0.8476788564209705
Iteration: 903 Loss: 0.8476788564209705
Iteration: 904 Loss: 0.8476788564209705
Iteration: 905 Loss: 0.8476788564209705
Iteration: 906 Loss: 0.8476788564209705
Iteration: 907 Loss: 0.8476788564209705
Iteration: 908 Loss: 0.8476788564209705
Iteration: 909 Loss: 0.8476788564209705
Iteration: 910 Loss: 0.8476788564209705
Iteration: 911 Loss: 0.8476788564209705
Iteration: 912 Loss: 0.8476788564209705
Iteration: 913 Loss: 0.8476788564209705
Iteration: 914 Loss: 0.8476788564209705
Iteration: 915 Loss: 0.8476788564209705
Iteration: 916 Loss: 0.8476788564209705
Iteration: 917 Loss: 0.8476788564209705
Iteration: 918 Loss: 0.8476788564209705
Iteration: 919 Loss: 0.8476788564209705
Iteration: 920 Loss: 0.8476788564209705
Iteration: 921 Loss: 0.8476788564209705
Iteration: 922 Loss: 0.8476788564209705
Iteration: 923 Loss: 0.8476788564209705
Iteration: 924 Loss: 0.8476788564209705
Iteration: 925 Loss: 0.8476788564209705
Iteration: 926 Loss: 0.8476788564209705
Iteration: 927 Loss: 0.8476788564209705
Iteration: 928 Loss: 0.8476788564209705
Iteration: 929 Loss: 0.8476788564209705
Iteration: 930 Loss: 0.8476788564209705
Iteration: 931 Loss: 0.8476788564209705
Iteration: 932 Loss: 0.8476788564209705
Iteration: 933 Loss: 0.8476788564209705
Iteration: 934 Loss: 0.8476788564209705
Iteration: 935 Loss: 0.8476788564209705
Iteration: 936 Loss: 0.8476788564209705
Iteration: 937 Loss: 0.8476788564209705
Iteration: 938 Loss: 0.8476788564209705
Iteration: 939 Loss: 0.8476788564209705
Iteration: 940 Loss: 0.8476788564209705
Iteration: 941 Loss: 0.8476788564209705
Iteration: 942 Loss: 0.8476788564209705
Iteration: 943 Loss: 0.8476788564209705
Iteration: 944 Loss: 0.8476788564209705
Iteration: 945 Loss: 0.8476788564209705
Iteration: 946 Loss: 0.8476788564209705
Iteration: 947 Loss: 0.8476788564209705
Iteration: 948 Loss: 0.8476788564209705
Iteration: 949 Loss: 0.8476788564209705
Iteration: 950 Loss: 0.8476788564209705
Iteration: 951 Loss: 0.8476788564209705
Iteration: 952 Loss: 0.8476788564209705
Iteration: 953 Loss: 0.8476788564209705
Iteration: 954 Loss: 0.8476788564209705
Iteration: 955 Loss: 0.8476788564209705
Iteration: 956 Loss: 0.8476788564209705
Iteration: 957 Loss: 0.8476788564209705
Iteration: 958 Loss: 0.8476788564209705
Iteration: 959 Loss: 0.8476788564209705
Iteration: 960 Loss: 0.8476788564209705
Iteration: 961 Loss: 0.8476788564209705
Iteration: 962 Loss: 0.8476788564209705
Iteration: 963 Loss: 0.8476788564209705
Iteration: 964 Loss: 0.8476788564209705
Iteration: 965 Loss: 0.8476788564209705
Iteration: 966 Loss: 0.8476788564209705
Iteration: 967 Loss: 0.8476788564209705
Iteration: 968 Loss: 0.8476788564209705
Iteration: 969 Loss: 0.8476788564209705
Iteration: 970 Loss: 0.8476788564209705
Iteration: 971 Loss: 0.8476788564209705
Iteration: 972 Loss: 0.8476788564209705
Iteration: 973 Loss: 0.8476788564209705
Iteration: 974 Loss: 0.8476788564209705
Iteration: 975 Loss: 0.8476788564209705
Iteration: 976 Loss: 0.8476788564209705
Iteration: 977 Loss: 0.8476788564209705
Iteration: 978 Loss: 0.8476788564209705
Iteration: 979 Loss: 0.8476788564209705
Iteration: 980 Loss: 0.8476788564209705
Iteration: 981 Loss: 0.8476788564209705
Iteration: 982 Loss: 0.8476788564209705
Iteration: 983 Loss: 0.8476788564209705
Iteration: 984 Loss: 0.8476788564209705
Iteration: 985 Loss: 0.8476788564209705
Iteration: 986 Loss: 0.8476788564209705
Iteration: 987 Loss: 0.8476788564209705
Iteration: 988 Loss: 0.8476788564209705
Iteration: 989 Loss: 0.8476788564209705
Iteration: 990 Loss: 0.8476788564209705
Iteration: 991 Loss: 0.8476788564209705
Iteration: 992 Loss: 0.8476788564209705
Iteration: 993 Loss: 0.8476788564209705
Iteration: 994 Loss: 0.8476788564209705
Iteration: 995 Loss: 0.8476788564209705
Iteration: 996 Loss: 0.8476788564209705
Iteration: 997 Loss: 0.8476788564209705
Iteration: 998 Loss: 0.8476788564209705
Iteration: 999 Loss: 0.8476788564209705
Iteration: 1000 Loss: 0.8476788564209705
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="model-evaluation">
<h2><span class="section-number">40.49.4. </span>Model Evaluation<a class="headerlink" href="#model-evaluation" title="Permalink to this headline">#</a></h2>
<p>After training the linear regression model, it is important to evaluate its performance to assess how well it is able to make predictions. In this section, we will discuss some commonly used evaluation metrics for regression models.</p>
<p>When evaluating a machine learning model, we often use certain metrics to measure its performance. Here are some commonly used metrics and plotting methods:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span>

<span class="c1"># Make predictions on the test set</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Compute the evaluation metrics</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Squared Error:&quot;</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Absolute Error:&quot;</span><span class="p">,</span> <span class="n">mae</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R-squared:&quot;</span><span class="p">,</span> <span class="n">r2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean Squared Error: 0.6536995137169997
Mean Absolute Error: 0.5913425779189757
R-squared: 0.8072059636181399
</pre></div>
</div>
</div>
</div>
<p>The scatter plot shows the relationship between the features (X) and the actual values (blue dots), along with the predicted values (red line). This visualization helps us understand how well the model captures the underlying patterns in the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Plot the scatter plot of the training set</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Set&#39;</span><span class="p">)</span>

<span class="c1"># Plot the scatter plot of the testing set</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testing Set&#39;</span><span class="p">)</span>

<span class="c1"># Plot the line representing the predicted results</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predictions&#39;</span><span class="p">)</span>

<span class="c1"># Set the title and labels for the chart</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Linear Regression&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

<span class="c1"># Add a legend</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Display the chart</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/linear-regression-from-scratch_19_0.png" src="../../../_images/linear-regression-from-scratch_19_0.png" />
</div>
</div>
</section>
<section id="conclusion">
<h2><span class="section-number">40.49.5. </span>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">#</a></h2>
<p>In this assignment, we implemented a simple linear regression model and trained and predicted using the from-scratch method. Through this implementation process, we gained a deeper understanding of the linear regression model and learned how to use gradient descent algorithm to minimize the loss function.</p>
<p>We evaluated the performance of the model and used several common evaluation metrics to measure the accuracy of the model’s predictions. Based on our results, the linear regression model performed well. The values of mean absolute error and root mean squared error were relatively small, indicating that the errors between the model’s predictions and actual results were small. And the value of R-squared was close to 1, indicating that the model was able to explain the variability in the data well.</p>
<p>Although our model performed well on this task, we also need to be aware of its limitations. Linear regression models assume a linear relationship between input features and target variables. If the data has a nonlinear relationship, the model may not fit the data well. In addition, it may also be affected by problems such as outliers and multicollinearity.</p>
<p>To further improve the performance of the model, we can try the following directions for future work:</p>
<ul class="simple">
<li><p>Consider using other types of regression models, such as polynomial regression or ridge regression, to explore more complex feature relationships.</p></li>
<li><p>Do more feature engineering, such as adding interaction features or introducing nonlinear transformations, to capture more complex patterns in the data.</p></li>
<li><p>Use regularization techniques to address problems such as overfitting and multicollinearity.</p></li>
<li><p>Collect more data or use data augmentation techniques to increase the size of the dataset and improve the generalization ability of the model.</p></li>
</ul>
<p>In conclusion, implementing a linear regression model from scratch is a great way to gain a deeper understanding of how machine learning algorithms work. We hope that this assignment has helped you to better understand the concepts and techniques involved in building and training machine learning models.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ocademy-ai/machine-learning",
            ref: "release",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./assignments/ml-fundamentals/linear-regression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="gradient-descent.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">40.48. </span>Gradient descent</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../ml-logistic-regression-1.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">40.50. </span>ML logistic regression - assignment 1</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ocademy<br/>
  
      &copy; Copyright 2022-2023.<br/>
    <div class="extra_footer">
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> Text content of this work is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>