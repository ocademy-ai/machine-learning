
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>42.48. Gradient descent &#8212; Ocademy Open Machine Learning Book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/drawio.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/youtube.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "ocademy-ai/machine-learning-utterances");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "üí¨ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"></script>
    <script>quizdown.init({"quizdown_js": "https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"});</script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="42.49. Linear Regression Implementation from Scratch" href="linear-regression-from-scratch.html" />
    <link rel="prev" title="42.47. Loss Function" href="loss-function.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint">Learn AI together, for free! At <a color='lightblue' href='https://ocademy.cc'><u style='color:lightblue;'>Ocademy</u></a>.</div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo-long.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Ocademy Open Machine Learning Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PREREQUISITES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-introduction.html">
   1. Python programming introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-basics.html">
   2. Python programming basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-advanced.html">
   3. Python programming advanced
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATA SCIENCE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/introduction/introduction.html">
   4. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/defining-data-science.html">
     4.1. Defining data science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/data-science-ethics.html">
     4.2. Data Science ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/defining-data.html">
     4.3. Defining data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/introduction-to-statistics-and-probability.html">
     4.4. Introduction to statistics and probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/working-with-data/working-with-data.html">
   5. Working with data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/relational-databases.html">
     5.1. Relational databases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/non-relational-data.html">
     5.2. Non-relational data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/numpy.html">
     5.3. NumPy
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../data-science/working-with-data/pandas/pandas.html">
     5.4. Pandas
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../data-science/working-with-data/pandas/introduction-and-data-structures.html">
       5.4.1. Introduction and Data Structures
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../data-science/working-with-data/pandas/data-selection.html">
       5.4.2. Data Selection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../data-science/working-with-data/pandas/advanced-pandas-techniques.html">
       5.4.3. Advanced Pandas Techniques
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/data-preparation.html">
     5.5. Data preparation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-visualization/data-visualization.html">
   6. Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-distributions.html">
     6.1. Visualizing distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-proportions.html">
     6.2. Visualizing proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-relationships.html">
     6.3. Visualizing relationships: all about honey üçØ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/meaningful-visualizations.html">
     6.4. Making meaningful visualizations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-science-lifecycle/data-science-lifecycle.html">
   7. Data Science lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/introduction.html">
     7.1. Introduction to the Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/analyzing.html">
     7.2. Analyzing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/communication.html">
     7.3. Communication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/data-science-in-the-cloud.html">
   8. Data Science in the cloud
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/introduction.html">
     8.1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/the-low-code-no-code-way.html">
     8.2. The ‚Äúlow code/no code‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/the-azure-ml-sdk-way.html">
     8.3. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../data-science/data-science-in-the-wild.html">
   9. Data Science in the real world
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING BASICS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-fundamentals/ml-overview.html">
   10. Machine Learning overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/regression/regression-models-for-machine-learning.html">
   11. Regression models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/tools-of-the-trade.html">
     11.1. Tools of the trade
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/managing-data.html">
     11.2. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/linear-and-polynomial-regression.html">
     11.3. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/logistic-regression.html">
     11.4. Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/Univariate-linear-regression.html">
     11.5. Univariate linear regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/classification/getting-started-with-classification.html">
   12. Getting started with classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/introduction-to-classification.html">
     12.1. Introduction to classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/more-classifiers.html">
     12.2. More classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/yet-other-classifiers.html">
     12.3. Yet other classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/build-a-web-app-to-use-a-machine-learning-model.html">
     12.4. Build a web app to use a Machine Learning model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/parameter-optimization/parameter-optimization.html">
   13. Parameter Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/parameter-optimization/loss-function.html">
     13.1. Loss function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/parameter-optimization/gradient-descent.html">
     13.2. Gradient descent
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ADVANCED MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/clustering/clustering-models-for-machine-learning.html">
   14. Clustering models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/clustering/introduction-to-clustering.html">
     14.1. Introduction to clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/clustering/k-means-clustering.html">
     14.2. K-Means clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/ensemble-learning/getting-started-with-ensemble-learning.html">
   15. Getting started with ensemble learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/bagging.html">
     15.2. Bagging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/random-forest.html">
     15.3. Random forest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/feature-importance.html">
     15.4. Feature importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/gradient-boosting/introduction-to-gradient-boosting.html">
   16. Introduction to Gradient Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/gradient-boosting.html">
     16.1. Gradient Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/gradient-boosting-example.html">
     16.2. Gradient boosting example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/xgboost.html">
     16.3. XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/xgboost-k-fold-cv-feature-importance.html">
     16.4. XGBoost + k-fold CV + Feature Importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/unsupervised-learning.html">
   17. Unsupervised learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/kernel-method.html">
   18. Kernel method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/unsupervised-learning-pca-and-clustering.html">
   19. Unsupervised learning: PCA and clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/model-selection.html">
   20. Model selection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dl-overview.html">
   21. Intro to Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/nn.html">
   22. Neural Networks
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../deep-learning/cnn/cnn.html">
   23. Convolutional Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/cnn/cnn-vgg.html">
     23.9. Stylenet / Neural-Style
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/cnn/cnn-deepdream.html">
     23.10. Deepdream in TensorFlow
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../deep-learning/rnn/rnn.html">
   24. Recurrent Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/rnn/lstm.html">
     24.1.1. Long-short term memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/rnn/bi-rnn.html">
     24.1.2. Bidirectional RNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/time-series.html">
   25. Time series
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/autoencoder.html">
   26. Autoencoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/object-detection.html">
   27. Object detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/image-classification.html">
   28. Image classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/image-segmentation.html">
   29. Image segmentation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../deep-learning/nlp/nlp.html">
   30. Natural Language Processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/nlp/text-preprocessing.html">
     30.7.1. Text Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/nlp/text-representation.html">
     30.7.2. Word embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/gan.html">
   31. Generative adversarial networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/difussion-model.html">
   32. Diffusion Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dqn.html">
   33. Deep Q-learning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING OPERATIONS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/overview.html">
   34. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/problem-framing.html">
   35. Problem framing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/data-engineering.html">
   36. Data engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/model-training-and-evaluation.html">
   37. Model training &amp; evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/model-deployment.html">
   38. Model deployment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Large Language Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../llm/introduction.html">
   39. Introduction
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../llm/basic/basic.html">
   40. Large Language Models Basic
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../llm/basic/attention.html">
     40.1. Coding Attention Mechanisms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../llm/basic/transformer.html">
     40.2. Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../llm/basic/language-modelling.html">
     40.3. Transformers for Language Modelling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../llm/pretrained-model/implementing-a-GPT-model.html">
   41. Implementing a GPT model from Scratch To Generate Text
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../llm/pretrained-model/pretraining-on-unlabeled-data.html">
     41.10. Pretraining on Unlabeled Data
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OTHERS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../README.html">
   42. Self-paced assignments
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../../set-up-env/first-assignment.html">
     42.3. First assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../set-up-env/second-assignment.html">
     42.4. Second assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../project-plan-template.html">
     42.5. Project Plan‚Äã Template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-introduction.html">
     42.6. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-basics.html">
     42.7. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-advanced.html">
     42.8. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-text-about-data-science.html">
     42.9. Analyzing text about Data Science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-scenarios.html">
     42.10. Data Science scenarios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/write-a-data-ethics-case-study.html">
     42.11. Write a data ethics case study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/lines-scatters-and-bars.html">
     42.12. Lines, scatters and bars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/apply-your-skills.html">
     42.13. Apply your skills
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/try-it-in-excel.html">
     42.14. Try it in Excel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/dive-into-the-beehive.html">
     42.15. Dive into the beehive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/build-your-own-custom-vis.html">
     42.16. Build your own custom vis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/classifying-datasets.html">
     42.17. Classifying datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/small-diabetes-study.html">
     42.18. Small diabetes study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction-to-statistics-and-probability.html">
     42.19. Introduction to probability and statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/displaying-airport-data.html">
     42.20. Displaying airport data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/soda-profits.html">
     42.21. Soda profits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-COVID-19-papers.html">
     42.22. Analyzing COVID-19 papers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/estimation-of-COVID-19-pandemic.html">
     42.23. Estimation of COVID-19 pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-processing-in-python.html">
     42.24. Data processing in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/evaluating-data-from-a-form.html">
     42.25. Evaluating data from a form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-preparation.html">
     42.26. Data preparation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-data.html">
     42.27. Analyzing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/nyc-taxi-data-in-winter-and-summer.html">
     42.28. NYC taxi data in winter and summer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/matplotlib-applied.html">
     42.29. Matplotlib applied
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/tell-a-story.html">
     42.35. Tell a story
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/explore-a-planetary-computer-dataset.html">
     42.36. Explore a planetary computer dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/exploring-for-anwser.html">
     42.37. Exploring for answers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/market-research.html">
     42.38. Market research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/low-code-no-code-data-science-project-on-azure-ml.html">
     42.39. Low code/no code Data Science project on Azure ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-project-using-azure-ml-sdk.html">
     42.40. Data Science project using Azure ML SDK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-in-the-cloud-the-azure-ml-sdk-way.html">
     42.41. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-overview-iris.html">
     42.42. Machine Learning overview - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-overview-mnist-digits.html">
     42.43. Machine Learning overview - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression-with-scikit-learn.html">
     42.44. Regression with Scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="california_housing.html">
     42.45. Linear regression - California Housing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linear-regression-metrics.html">
     42.46. Linear Regression Metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="loss-function.html">
     42.47. Loss Function
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     42.48. Gradient descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linear-regression-from-scratch.html">
     42.49. Linear Regression Implementation from Scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-logistic-regression-1.html">
     42.50. ML logistic regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-logistic-regression-2.html">
     42.51. ML logistic regression - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-neural-network-1.html">
     42.52. ML neural network - Assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../build-ml-web-app-1.html">
     42.53. Build ML web app - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../build-ml-web-app-2.html">
     42.54. Build ML web app - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../regression-tools.html">
     42.55. Regression tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../managing-data.html">
     42.56. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../exploring-visualizations.html">
     42.57. Exploring visualizations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../try-a-different-model.html">
     42.58. Try a different model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../create-a-regression-model.html">
     42.59. Create a regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../linear-and-polynomial-regression.html">
     42.60. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../retrying-some-regression.html">
     42.61. Retrying some regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pumpkin-varieties-and-color.html">
     42.62. Pumpkin varieties and color
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../delicious-asian-and-indian-cuisines.html">
     42.63. Delicious asian and indian cuisines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../explore-classification-methods.html">
     42.64. Explore classification methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/kernel-method-assignment-1.html">
     42.65. Kernel method assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/support_vector_machines_for_regression.html">
     42.66. Support Vector Machines (SVM) - Intro and SVM for Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/support_vector_machines_for_classification.html">
     42.67. Support Vector Machines (SVM) - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/decision_trees_for_regression.html">
     42.68. Decision Trees - Intro and Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/decision_trees_for_classification.html">
     42.69. Decision Trees - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/model-selection-assignment-1.html">
     42.70. Model selection assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/learning-curve-to-identify-overfit-underfit.html">
     42.71. Learning Curve To Identify Overfit &amp; Underfit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/dropout-and-batch-normalization.html">
     42.72. Dropout and Batch Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/lasso-and-ridge-regression.html">
     42.73. Lasso and Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/regularized-linear-models.html">
     42.74. Regularized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/unsupervised-learning/customer-segmentation-clustering.html">
     42.75. Customer segmentation: clustering - assignment 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/random-forests-intro-and-regression.html">
     42.76. Random forests intro and regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/random-forests-for-classification.html">
     42.77. Random forests for classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.html">
     42.78. Beyond random forests: more ensemble models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/decision-trees.html">
     42.79. Decision trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/hyperparameter-tuning-gradient-boosting.html">
     42.80. Hyperparameter tuning gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/gradient-boosting-assignment.html">
     42.81. Gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/boosting-with-tuning.html">
     42.82. Boosting with tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/random-forest-classifier-feature-importance.html">
     42.83. Random Forest Classifier with Feature Importance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/data-engineering.html">
     42.85. Data engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/counterintuitive-challenges-in-ml-debugging.html">
     42.86. Counterintuitive Challenges in ML Debugging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/debugging-in-classification.html">
     42.87. Case Study: Debugging in Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/debugging-in-regression.html">
     42.88. Case Study: Debugging in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/random-forest-classifier.html">
     42.89. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../study-the-solvers.html">
     42.90. Study the solvers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../build-classification-models.html">
     42.91. Build classification models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../build-classification-model.html">
     42.92. Build Classification Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../parameter-play.html">
     42.93. Parameter play
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/how-to-choose-cnn-architecture-mnist.html">
     42.94. How to choose cnn architecture mnist
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/sign-language-digits-classification-with-cnn.html">
     42.96. Sign Language Digits Classification with CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/object-recognition-in-images-using-cnn.html">
     42.98. Object Recognition in Images using CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/image-classification.html">
     42.99. Image classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/tensorflow/intro_to_tensorflow_for_deeplearning.html">
     42.100. Intro to TensorFlow for Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/lstm/bitcoin-lstm-model-with-tweet-volume-and-sentiment.html">
     42.102. Bitcoin LSTM Model with Tweet Volume and Sentiment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/rnn/google-stock-price-prediction-rnn.html">
     42.104. Google Stock Price Prediction RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/autoencoder.html">
     42.106. Intro to Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/base-denoising-autoencoder-dimension-reduction.html">
     42.107. Base/Denoising Autoencoder &amp; Dimension Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/variational-autoencoder-and-faces-generation.html">
     42.108. Fun with Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/time-series-forecasting-assignment.html">
     42.109. Time Series Forecasting Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nn-for-classification-assignment.html">
     42.111. Neural Networks for Classification with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nn-classify-15-fruits-assignment.html">
     42.112. NN Classify 15 Fruits Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/dqn/dqn-on-foreign-exchange-market.html">
     42.117. DQN On Foreign Exchange Market
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/gan/art-by-gan.html">
     42.118. Art by gan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/gan/gan-introduction.html">
     42.120. Generative Adversarial Networks (GANs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/image-segmentation/comparing-edge-based-and-region-based-segmentation.html">
     42.121. Comparing edge-based and region-based segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/difussion-model/denoising-difussion-model.html">
     42.122. Summary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/object-detection/car-object-detection.html">
     42.123. Car Object Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/overview/basic-classification-classify-images-of-clothing.html">
     42.125. Basic classification: Classify images of clothing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nlp/getting-start-nlp-with-classification-task.html">
     42.126. Getting Start NLP with classification task
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nlp/beginner-guide-to-text-preprocessing.html">
     42.128. Beginner‚Äôs Guide to Text Pre-Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nlp/news-topic-classification-tasks.html">
     42.129. News topic classification tasks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../llm/basic/transformer-architecture.html">
     42.130. Complete the transformer architecture
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../slides/introduction.html">
   43. Slides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-introduction.html">
     43.1. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-basics.html">
     43.2. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-advanced.html">
     43.3. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-introduction.html">
     43.4. Data Science introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/relational-vs-non-relational-database.html">
     43.5. Relational vs. non-relational database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/numpy-and-pandas.html">
     43.6. NumPy and Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-visualization.html">
     43.7. Data visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-lifecycle.html">
     43.8. Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-in-the-cloud.html">
     43.9. Data Science in the cloud
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-in-real-world.html">
     43.10. Data Science in real world
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/ml-overview.html">
     43.11. Machine Learning overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/linear-regression.html">
     43.12. Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/logistic-regression.html">
     43.13. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/logistic-regression-condensed.html">
     43.14. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/neural-network.html">
     43.15. Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/build-an-ml-web-app.html">
     43.16. Build an machine learning web application
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/unsupervised-learning.html">
     43.17. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/kernel-method.html">
     43.18. Kernel method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/model-selection.html">
     43.19. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/deep-learning/cnn.html">
     43.20. Convolutional Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/deep-learning/gan.html">
     43.21. Generative Adversarial Network
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ocademy-ai/machine-learning/release?urlpath=lab/tree/open-machine-learning-jupyter-book/assignments/ml-fundamentals/linear-regression/gradient-descent.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ocademy-ai/machine-learning/blob/release/open-machine-learning-jupyter-book/assignments/ml-fundamentals/linear-regression/gradient-descent.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning//issues/new?title=Issue%20on%20page%20%2Fassignments/ml-fundamentals/linear-regression/gradient-descent.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/edit/release/open-machine-learning-jupyter-book/assignments/ml-fundamentals/linear-regression/gradient-descent.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/assignments/ml-fundamentals/linear-regression/gradient-descent.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#session-objective">
   42.48.1. Session Objective
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lets-explore-and-gain-intuition">
   42.48.2. Let‚Äôs Explore and Gain Intuition
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#math-feel-free-to-skip-if-you-find-it-difficult">
     42.48.2.1. Math (feel free to skip if you find it difficult)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#partial-derivatives">
     42.48.2.2. Partial Derivatives
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#partial-derivative-with-respect-to-m">
     42.48.2.3. Partial Derivative with Respect to
     <span class="math notranslate nohighlight">
      \(m\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#partial-derivative-with-respect-to-b">
     42.48.2.4. Partial Derivative with Respect to
     <span class="math notranslate nohighlight">
      \(b\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-final-function">
     42.48.2.5. The Final Function
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#time-to-code">
   42.48.3. Time to code!
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#one-dimensional-gradient-descent">
   42.48.4. 1. One-dimensional gradient descent
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lets-try">
     42.48.4.1. Let‚Äôs try!
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#two-dimensional-gradient-descent">
   42.48.5. 2. Two-dimensional gradient descent
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     42.48.5.1. Let‚Äôs try!
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Gradient descent</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#session-objective">
   42.48.1. Session Objective
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lets-explore-and-gain-intuition">
   42.48.2. Let‚Äôs Explore and Gain Intuition
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#math-feel-free-to-skip-if-you-find-it-difficult">
     42.48.2.1. Math (feel free to skip if you find it difficult)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#partial-derivatives">
     42.48.2.2. Partial Derivatives
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#partial-derivative-with-respect-to-m">
     42.48.2.3. Partial Derivative with Respect to
     <span class="math notranslate nohighlight">
      \(m\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#partial-derivative-with-respect-to-b">
     42.48.2.4. Partial Derivative with Respect to
     <span class="math notranslate nohighlight">
      \(b\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-final-function">
     42.48.2.5. The Final Function
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#time-to-code">
   42.48.3. Time to code!
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#one-dimensional-gradient-descent">
   42.48.4. 1. One-dimensional gradient descent
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lets-try">
     42.48.4.1. Let‚Äôs try!
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#two-dimensional-gradient-descent">
   42.48.5. 2. Two-dimensional gradient descent
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     42.48.5.1. Let‚Äôs try!
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="gradient-descent">
<h1><span class="section-number">42.48. </span>Gradient descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">#</a></h1>
<section id="session-objective">
<h2><span class="section-number">42.48.1. </span>Session Objective<a class="headerlink" href="#session-objective" title="Permalink to this headline">#</a></h2>
<p>In previous sessions, we‚Äôve delved into the application of Linear Regression and Logistic Regression models. You may find the code relatively straightforward and intuitive at this point. However, you might be pondering questions like:</p>
<ul class="simple">
<li><p>What exactly occurs when we invoke the <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> function?</p></li>
<li><p>Why does the execution of the <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> function sometimes take a significant amount of time?</p></li>
</ul>
<p>This session is designed to provide insight into the functionality of the <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> method, which is responsible for training machine learning models and fine-tuning model parameters. The underlying technique at play here is known as ‚ÄúGradient Descent.‚Äù</p>
</section>
<section id="lets-explore-and-gain-intuition">
<h2><span class="section-number">42.48.2. </span>Let‚Äôs Explore and Gain Intuition<a class="headerlink" href="#lets-explore-and-gain-intuition" title="Permalink to this headline">#</a></h2>
<p>To further enhance your understanding and gain a playful insight into Gradient Descent, you can explore the following resources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/lilipads/gradient_descent_viz">Gradient Descent Visualization</a>: This GitHub repository offers a visualization of the Gradient Descent algorithm, which can be a valuable resource for understanding the optimization process.</p></li>
<li><p><a class="reference external" href="https://bl.ocks.org/EmilienDupont/aaf429be5705b219aaaf8d691e27ca87">Optimization Algorithms Visualization</a>: Explore this visualization to see how different optimization algorithms, including Gradient Descent, work and how they converge to find optimal solutions.</p></li>
</ul>
<p>These resources will help you build an intuitive grasp of Gradient Descent and its role in training machine learning models. Enjoy your exploration!</p>
<section id="math-feel-free-to-skip-if-you-find-it-difficult">
<h3><span class="section-number">42.48.2.1. </span>Math (feel free to skip if you find it difficult)<a class="headerlink" href="#math-feel-free-to-skip-if-you-find-it-difficult" title="Permalink to this headline">#</a></h3>
<p>The fundamental concept behind gradient descent is rather straightforward: it involves the gradual adjustment of parameters, such as the slope (<span class="math notranslate nohighlight">\(m\)</span>) and the intercept (<span class="math notranslate nohighlight">\(b\)</span>) in our regression equation $y = mx + b, with the aim of minimizing a cost function. This cost function is typically a metric that quantifies the disparity between our model‚Äôs predicted results and the actual values. In regression scenarios, the widely employed cost function is the <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">squared</span> <span class="pre">error</span></code> (MSE). When dealing with classification problems, a different set of parameters must be fine-tuned.</p>
<p>The MSE (Mean Squared Error) is mathematically expressed as:</p>
<div class="math notranslate nohighlight">
\[
MSE = \frac{1}{n}\sum_{i=1}^{n} (y_i - \hat{y_i})^2
\]</div>
<p>Here, <span class="math notranslate nohighlight">\(y_i\)</span> represents the actual data points, <span class="math notranslate nohighlight">\(\hat{y_i}\)</span> signifies the predictions made by our model (<span class="math notranslate nohighlight">\(mx_i + b\)</span>), and <span class="math notranslate nohighlight">\(n\)</span> denotes the total number of data points.</p>
<p>Our primary challenge is to determine the optimal adjustments to parameters <span class="math notranslate nohighlight">\(m\)</span> and $b‚Äù to minimize the MSE effectively.</p>
</section>
<section id="partial-derivatives">
<h3><span class="section-number">42.48.2.2. </span>Partial Derivatives<a class="headerlink" href="#partial-derivatives" title="Permalink to this headline">#</a></h3>
<p>In our pursuit of minimizing the Mean Squared Error (MSE), we turn to partial derivatives to understand how each individual parameter influences the MSE. The term ‚Äúpartial‚Äù signifies that we are taking derivatives with respect to individual parameters, in this case, <span class="math notranslate nohighlight">\(m\)</span> and $b, separately.</p>
<p>Consider the following formula, which closely resembles the MSE, but now we‚Äôve introduced the function <span class="math notranslate nohighlight">\(f(m, b)\)</span> into it. The addition of this function doesn‚Äôt significantly alter the essence of the calculation, but it allows us to input specific values for <span class="math notranslate nohighlight">\(m\)</span> and <span class="math notranslate nohighlight">\(b\)</span> to compute the result.</p>
<div class="math notranslate nohighlight">
\[f(m, b) = \frac{1}{n}\sum_{i=1}^{n}(y_i - (mx_i+b))^2\]</div>
<p>For the purposes of calculating partial derivatives, we can temporarily disregard the summation and the terms preceding it, focusing solely on the expression <span class="math notranslate nohighlight">\(y - (mx + b)^2\)</span>. This expression serves as a better starting point for the subsequent partial derivative calculations.</p>
</section>
<section id="partial-derivative-with-respect-to-m">
<h3><span class="section-number">42.48.2.3. </span>Partial Derivative with Respect to <span class="math notranslate nohighlight">\(m\)</span><a class="headerlink" href="#partial-derivative-with-respect-to-m" title="Permalink to this headline">#</a></h3>
<p>When we calculate the partial derivative with respect to the parameter <span class="math notranslate nohighlight">\(m,&quot; we isolate the parameter \)</span>m‚Äù and treat <span class="math notranslate nohighlight">\(b\)</span> as a constant (effectively setting it to 0 for differentiation purposes). To compute this derivative, we utilize the chain rule, which is a fundamental concept in calculus.</p>
<p>The chain rule is expressed as follows:</p>
<div class="math notranslate nohighlight">
\[ [f(g(x))]' = f'(g(x)) * g(x)' \quad - \textrm{chain rule} \]</div>
<p>The chain rule is applicable when one function is nested inside another. In this context, the square operation, <span class="math notranslate nohighlight">\(()^2\)</span>, is the outer function, while <span class="math notranslate nohighlight">\(y - (mx + b)\)</span> is the inner function. Following the chain rule, we differentiate the outer function, maintain the inner function as it is, and then multiply it by the derivative of the inner function. Let‚Äôs break down the steps:</p>
<div class="math notranslate nohighlight">
\[ (y - (mx + b))^2 \]</div>
<ol class="simple">
<li><p>The derivative of <span class="math notranslate nohighlight">\(()^2\)</span> is <span class="math notranslate nohighlight">\(2()\)</span>, just like <span class="math notranslate nohighlight">\(x^2\)</span> becomes <span class="math notranslate nohighlight">\(2x\)</span>.</p></li>
<li><p>We leave the inner function, <span class="math notranslate nohighlight">\(y - (mx + b)\)</span>, unaltered.</p></li>
<li><p>The derivative of <span class="math notranslate nohighlight">\(y - (mx + b)\)</span> with respect to <strong><em>m</em></strong> is <span class="math notranslate nohighlight">\((0 - x)\)</span>, which simplifies to <span class="math notranslate nohighlight">\(-x\)</span>. This is because both <strong><em>y</em></strong> and <strong><em>b</em></strong> are treated as constants (their derivatives are zero), and the derivative of <strong><em>mx</em></strong> is simply <strong><em>x</em></strong>.</p></li>
</ol>
<p>Now, let‚Äôs combine these components:</p>
<div class="math notranslate nohighlight">
\[ 2 \cdot (y - (mx+b)) \cdot (-x) \]</div>
<p>For clarity, we can rearrange this expression by moving the factor of <span class="math notranslate nohighlight">\(-x\)</span> to the left:</p>
<div class="math notranslate nohighlight">
\[ -2x \cdot (y-(mx+b)) \]</div>
<p>This is the final version of our derivative with respect to <span class="math notranslate nohighlight">\(m\)</span>:</p>
<div class="math notranslate nohighlight">
\[ \frac{\partial f}{\partial m} = \frac{1}{n}\sum_{i=1}^{n} -2x_i(y_i - (mx_i+b)) \]</div>
<p>Here, <span class="math notranslate nohighlight">\(\frac{df}{dm}\)</span> signifies the partial derivative of function <span class="math notranslate nohighlight">\(f\)</span> (as previously defined) with respect to the parameter <span class="math notranslate nohighlight">\(m\)</span>. We can now insert this derivative into our summation to complete the calculation.</p>
</section>
<section id="partial-derivative-with-respect-to-b">
<h3><span class="section-number">42.48.2.4. </span>Partial Derivative with Respect to <span class="math notranslate nohighlight">\(b\)</span><a class="headerlink" href="#partial-derivative-with-respect-to-b" title="Permalink to this headline">#</a></h3>
<p>The process for computing the partial derivative with respect to the parameter <span class="math notranslate nohighlight">\(b&quot; is analogous to our previous derivation with respect to \)</span>m. We still apply the same rules and utilize the chain rule:</p>
<ol class="simple">
<li><p>The derivative of <span class="math notranslate nohighlight">\(()^2\)</span> is <span class="math notranslate nohighlight">\(2()\)</span>, which corresponds to how <span class="math notranslate nohighlight">\(x^2\)</span> becomes <span class="math notranslate nohighlight">\(2x\)</span>.</p></li>
<li><p>We leave the inner function, <span class="math notranslate nohighlight">\(y - (mx + b)\)</span>, unaltered.</p></li>
<li><p>For the derivative of <span class="math notranslate nohighlight">\(y - (mx + b)\)</span> with respect to <strong><em>b</em></strong>, it becomes <span class="math notranslate nohighlight">\((0 - 1)\)</span> or simply $-1.‚Äù This is because both <strong><em>y</em></strong> and <strong><em>mx</em></strong> are treated as constants (their derivatives are zero), and the derivative of <strong><em>b</em></strong> is 1.</p></li>
</ol>
<p>Now, let‚Äôs consolidate these components:</p>
<div class="math notranslate nohighlight">
\[ 2 \cdot (y - (mx+b)) \cdot (-1) \]</div>
<p>Simplifying this expression:</p>
<div class="math notranslate nohighlight">
\[ -2 \cdot (y-(mx+b)) \]</div>
<p>This is the final version of our derivative with respect to <span class="math notranslate nohighlight">\(b\)</span>:</p>
<div class="math notranslate nohighlight">
\[ \frac{\partial f}{\partial b} = \frac{1}{n}\sum_{i=1}^{n} -2(y_i - (mx_i+b)) \]</div>
<p>Similarly to the previous case, <span class="math notranslate nohighlight">\(\frac{df}{db}\)</span> represents the partial derivative of function <span class="math notranslate nohighlight">\(f\)</span> with respect to the parameter $b‚Äù. Inserting this derivative into our summation concludes the computation.</p>
</section>
<section id="the-final-function">
<h3><span class="section-number">42.48.2.5. </span>The Final Function<a class="headerlink" href="#the-final-function" title="Permalink to this headline">#</a></h3>
<p>Before delving into the code, there are a few essential details to address:</p>
<ol class="simple">
<li><p>Gradient descent is an iterative process, and with each iteration (referred to as an ‚Äúepoch‚Äù), we incrementally reduce the Mean Squared Error (MSE). At each iteration, we apply our derived functions to update the values of parameters <span class="math notranslate nohighlight">\(m\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.</p></li>
<li><p>Because gradient descent is iterative, we must determine how many iterations to perform, or devise a mechanism to stop the algorithm when it approaches the minimum of the MSE. In essence, we continue iterations until the algorithm no longer improves the MSE, signifying that it has reached a minimum.</p></li>
<li><p>An important parameter in gradient descent is the learning rate (<span class="math notranslate nohighlight">\(lr\)</span>). The learning rate governs the pace at which the algorithm moves toward the minimum of the MSE. A smaller learning rate results in slower but more precise convergence, while a larger learning rate may lead to faster convergence but may overshoot the minimum.</p></li>
</ol>
<p>In summary, gradient descent primarily involves the process of taking derivatives and applying them iteratively to minimize a function. These derivatives guide us toward optimizing the parameters <span class="math notranslate nohighlight">\(m\)</span> and $b‚Äù in order to minimize the Mean Squared Error.</p>
</section>
</section>
<section id="time-to-code">
<h2><span class="section-number">42.48.3. </span>Time to code!<a class="headerlink" href="#time-to-code" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="one-dimensional-gradient-descent">
<h2><span class="section-number">42.48.4. </span>1. One-dimensional gradient descent<a class="headerlink" href="#one-dimensional-gradient-descent" title="Permalink to this headline">#</a></h2>
<p>One-dimensional gradient descent is a simple optimization algorithm used to find the minimum (or maximum) of a univariate function.</p>
<p>Here are the main steps:</p>
<blockquote>
<div><p>step 1: Choose an initial point on the function curve. For example, we choose an initial x value.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>step 2: Compute the derivative of the function at the current point. In this case, the derivative of the function is computed as follows:</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">5</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>step 3: Update the position along the function curve using the gradient and the learning rate. The learning rate determines the size of the step.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">x</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">df</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>step 4: Repeat the process for a specified number of iterations.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="n">df</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>step 5: Output the result, which is the minimum value of x that corresponds to the minimum of the function.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x_min:&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="lets-try">
<h3><span class="section-number">42.48.4.1. </span>Let‚Äôs try!<a class="headerlink" href="#lets-try" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the target function</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">10</span>

<span class="c1"># Define the guidance of the target function</span>
<span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">5</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;f(x)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define gradient descent function</span>
<span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">x_init</span><span class="p">):</span>
    <span class="c1"># step 1:start with an initial value for the input variable, denoted as x_int.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x_init</span>
    <span class="n">x_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="c1"># step 2:compute the derivative of the function at the current point.</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="n">df</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient</span>
        <span class="c1"># step 3:update the position along the function curve.</span>
        <span class="n">x_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># step 4:repeat the process.</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_history</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the learning rate and initial value</span>
        <span class="c1"># learning rate: the size of the step for gradient descent.</span>
        <span class="c1"># max_iter: number of gradient descent iterations.</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">x_init</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Run gradient descent function</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">x_history</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">x_init</span><span class="p">)</span>

<span class="c1"># Draw the target function and the process of gradient descent</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y_history</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_history</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;f(x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_history</span><span class="p">,</span> <span class="n">y_history</span><span class="p">,</span> <span class="s1">&#39;ro-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gradient Descent&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;f(x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;One-Dimensional Gradient Descent&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x_min:&#39;</span><span class="p">,</span> <span class="n">x_min</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>you can change <code class="docutils literal notranslate"><span class="pre">learning</span> <span class="pre">rate</span></code> and  <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> to see different images.</p>
</section>
</section>
<section id="two-dimensional-gradient-descent">
<h2><span class="section-number">42.48.5. </span>2. Two-dimensional gradient descent<a class="headerlink" href="#two-dimensional-gradient-descent" title="Permalink to this headline">#</a></h2>
<p>Two-dimensional gradient descent is an optimization algorithm used to find the minimum (or maximum) of a function with two input variables.</p>
<p>Here are the main steps:</p>
<blockquote>
<div><p>step 1: Choose an initial point on the function surface by specifying initial values for both x and y.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_init</span> <span class="o">=</span> <span class="o">-</span><span class="mi">5</span>
<span class="n">y_init</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>step 2: Compute the partial derivatives of the function at the current point. These partial derivatives represent the rate of change of the function with respect to x and y.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">dfx</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">5</span>

<span class="k">def</span> <span class="nf">dfy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y</span> <span class="o">+</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>step 3: Update the positions along the function surface for both x and y using their respective partial derivatives and the learning rate.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">x</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dfx</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dfy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>step 4: Repeat the process for a specified number of iterations.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
    <span class="n">gradient_x</span> <span class="o">=</span> <span class="n">dfx</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">gradient_y</span> <span class="o">=</span> <span class="n">dfy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient_x</span>
    <span class="n">y</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient_y</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>step 5: Output the results, which are the minimum values of x and y that correspond to the minimum of the function.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x_min:&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y_min:&#39;</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="id1">
<h3><span class="section-number">42.48.5.1. </span>Let‚Äôs try!<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the target function</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">y</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y</span> <span class="o">+</span> <span class="mi">10</span>

<span class="c1"># Take the partial derivative of the objective function with respect to x</span>
<span class="k">def</span> <span class="nf">dfx</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">5</span>

<span class="c1"># Take the partial derivative of the objective function with respect to y</span>
<span class="k">def</span> <span class="nf">dfy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y</span> <span class="o">+</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the two-dimensional gradient descent function</span>
<span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">x_init</span><span class="p">,</span> <span class="n">y_init</span><span class="p">):</span>
    <span class="c1"># step 1:start with an initial value for the two input variables, denoted as (x_init, y_init).</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x_init</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y_init</span>
    <span class="n">x_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
    <span class="n">y_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="c1"># step 2:compute the partial derivatives of the function at the current point.</span>
        <span class="n">gradient_x</span> <span class="o">=</span> <span class="n">dfx</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">gradient_y</span> <span class="o">=</span> <span class="n">dfy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient_x</span>
        <span class="n">y</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient_y</span>
        <span class="c1"># step 3:update the positions along the function surface.</span>
        <span class="n">x_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="c1"># step 4:repeat the process.</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_history</span><span class="p">,</span> <span class="n">y_history</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the learning rate and initial value</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">x_init</span> <span class="o">=</span> <span class="o">-</span><span class="mi">5</span>
<span class="n">y_init</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Run two-dimensional gradient descent function</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_history</span><span class="p">,</span> <span class="n">y_history</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">x_init</span><span class="p">,</span> <span class="n">y_init</span><span class="p">)</span>

<span class="c1"># Draw the target function and the process of gradient descent</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_history</span><span class="p">,</span> <span class="n">y_history</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_history</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_history</span><span class="p">)),</span> <span class="s1">&#39;ro-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gradient Descent&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;f(x, y)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Two-Dimensional Gradient Descent&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x_min:&#39;</span><span class="p">,</span> <span class="n">x_min</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y_min:&#39;</span><span class="p">,</span> <span class="n">y_min</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ocademy-ai/machine-learning",
            ref: "release",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./assignments/ml-fundamentals/linear-regression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="loss-function.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">42.47. </span>Loss Function</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="linear-regression-from-scratch.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">42.49. </span>Linear Regression Implementation from Scratch</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ocademy<br/>
  
      &copy; Copyright 2022-2023.<br/>
    <div class="extra_footer">
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> Text content of this work is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>