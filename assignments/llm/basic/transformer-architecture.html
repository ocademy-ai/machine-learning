
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>42.130. Complete the transformer architecture &#8212; Ocademy Open Machine Learning Book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/drawio.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/youtube.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "ocademy-ai/machine-learning-utterances");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "💬 comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"></script>
    <script>quizdown.init({"quizdown_js": "https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"});</script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="43. Slides" href="../../../slides/introduction.html" />
    <link rel="prev" title="42.129. News topic classification tasks" href="../../deep-learning/nlp/news-topic-classification-tasks.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint">Learn AI together, for free! At <a color='lightblue' href='https://ocademy.cc'><u style='color:lightblue;'>Ocademy</u></a>.</div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo-long.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Ocademy Open Machine Learning Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PREREQUISITES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-introduction.html">
   1. Python programming introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-basics.html">
   2. Python programming basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-advanced.html">
   3. Python programming advanced
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATA SCIENCE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/introduction/introduction.html">
   4. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/defining-data-science.html">
     4.1. Defining data science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/data-science-ethics.html">
     4.2. Data Science ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/defining-data.html">
     4.3. Defining data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/introduction-to-statistics-and-probability.html">
     4.4. Introduction to statistics and probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/working-with-data/working-with-data.html">
   5. Working with data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/relational-databases.html">
     5.1. Relational databases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/non-relational-data.html">
     5.2. Non-relational data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/numpy.html">
     5.3. NumPy
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../data-science/working-with-data/pandas/pandas.html">
     5.4. Pandas
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../data-science/working-with-data/pandas/introduction-and-data-structures.html">
       5.4.1. Introduction and Data Structures
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../data-science/working-with-data/pandas/data-selection.html">
       5.4.2. Data Selection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../data-science/working-with-data/pandas/advanced-pandas-techniques.html">
       5.4.3. Advanced Pandas Techniques
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/data-preparation.html">
     5.5. Data preparation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-visualization/data-visualization.html">
   6. Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-distributions.html">
     6.1. Visualizing distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-proportions.html">
     6.2. Visualizing proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-relationships.html">
     6.3. Visualizing relationships: all about honey 🍯
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/meaningful-visualizations.html">
     6.4. Making meaningful visualizations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-science-lifecycle/data-science-lifecycle.html">
   7. Data Science lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/introduction.html">
     7.1. Introduction to the Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/analyzing.html">
     7.2. Analyzing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/communication.html">
     7.3. Communication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/data-science-in-the-cloud.html">
   8. Data Science in the cloud
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/introduction.html">
     8.1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/the-low-code-no-code-way.html">
     8.2. The “low code/no code” way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/the-azure-ml-sdk-way.html">
     8.3. Data Science in the cloud: The “Azure ML SDK” way
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../data-science/data-science-in-the-wild.html">
   9. Data Science in the real world
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING BASICS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-fundamentals/ml-overview.html">
   10. Machine Learning overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/regression/regression-models-for-machine-learning.html">
   11. Regression models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/tools-of-the-trade.html">
     11.1. Tools of the trade
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/managing-data.html">
     11.2. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/linear-and-polynomial-regression.html">
     11.3. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/logistic-regression.html">
     11.4. Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/Univariate-linear-regression.html">
     11.5. Univariate linear regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/classification/getting-started-with-classification.html">
   12. Getting started with classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/introduction-to-classification.html">
     12.1. Introduction to classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/more-classifiers.html">
     12.2. More classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/yet-other-classifiers.html">
     12.3. Yet other classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/build-a-web-app-to-use-a-machine-learning-model.html">
     12.4. Build a web app to use a Machine Learning model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/parameter-optimization/parameter-optimization.html">
   13. Parameter Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/parameter-optimization/loss-function.html">
     13.1. Loss function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/parameter-optimization/gradient-descent.html">
     13.2. Gradient descent
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ADVANCED MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/clustering/clustering-models-for-machine-learning.html">
   14. Clustering models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/clustering/introduction-to-clustering.html">
     14.1. Introduction to clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/clustering/k-means-clustering.html">
     14.2. K-Means clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/ensemble-learning/getting-started-with-ensemble-learning.html">
   15. Getting started with ensemble learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/bagging.html">
     15.2. Bagging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/random-forest.html">
     15.3. Random forest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/feature-importance.html">
     15.4. Feature importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/gradient-boosting/introduction-to-gradient-boosting.html">
   16. Introduction to Gradient Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/gradient-boosting.html">
     16.1. Gradient Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/gradient-boosting-example.html">
     16.2. Gradient boosting example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/xgboost.html">
     16.3. XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/xgboost-k-fold-cv-feature-importance.html">
     16.4. XGBoost + k-fold CV + Feature Importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/unsupervised-learning.html">
   17. Unsupervised learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/kernel-method.html">
   18. Kernel method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/unsupervised-learning-pca-and-clustering.html">
   19. Unsupervised learning: PCA and clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/model-selection.html">
   20. Model selection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dl-overview.html">
   21. Intro to Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/nn.html">
   22. Neural Networks
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../deep-learning/cnn/cnn.html">
   23. Convolutional Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/cnn/cnn-vgg.html">
     23.9. Stylenet / Neural-Style
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/cnn/cnn-deepdream.html">
     23.10. Deepdream in TensorFlow
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../deep-learning/rnn/rnn.html">
   24. Recurrent Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/rnn/lstm.html">
     24.1.1. Long-short term memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/rnn/bi-rnn.html">
     24.1.2. Bidirectional RNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/time-series.html">
   25. Time series
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/autoencoder.html">
   26. Autoencoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/object-detection.html">
   27. Object detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/image-classification.html">
   28. Image classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/image-segmentation.html">
   29. Image segmentation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../deep-learning/nlp/nlp.html">
   30. Natural Language Processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/nlp/text-preprocessing.html">
     30.7.1. Text Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../deep-learning/nlp/text-representation.html">
     30.7.2. Word embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/gan.html">
   31. Generative adversarial networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/difussion-model.html">
   32. Diffusion Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dqn.html">
   33. Deep Q-learning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING OPERATIONS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/overview.html">
   34. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/problem-framing.html">
   35. Problem framing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/data-engineering.html">
   36. Data engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/model-training-and-evaluation.html">
   37. Model training &amp; evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/model-deployment.html">
   38. Model deployment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Large Language Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../llm/introduction.html">
   39. Introduction
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../llm/basic/basic.html">
   40. Large Language Models Basic
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../llm/basic/attention.html">
     40.1. Coding Attention Mechanisms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../llm/basic/transformer.html">
     40.2. Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../llm/basic/language-modelling.html">
     40.3. Transformers for Language Modelling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../llm/pretrained-model/implementing-a-GPT-model.html">
   41. Implementing a GPT model from Scratch To Generate Text
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../llm/pretrained-model/pretraining-on-unlabeled-data.html">
     41.10. Pretraining on Unlabeled Data
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OTHERS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../README.html">
   42. Self-paced assignments
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../../set-up-env/first-assignment.html">
     42.3. First assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../set-up-env/second-assignment.html">
     42.4. Second assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../project-plan-template.html">
     42.5. Project Plan​ Template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-introduction.html">
     42.6. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-basics.html">
     42.7. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-advanced.html">
     42.8. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-text-about-data-science.html">
     42.9. Analyzing text about Data Science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-scenarios.html">
     42.10. Data Science scenarios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/write-a-data-ethics-case-study.html">
     42.11. Write a data ethics case study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/lines-scatters-and-bars.html">
     42.12. Lines, scatters and bars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/apply-your-skills.html">
     42.13. Apply your skills
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/try-it-in-excel.html">
     42.14. Try it in Excel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/dive-into-the-beehive.html">
     42.15. Dive into the beehive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/build-your-own-custom-vis.html">
     42.16. Build your own custom vis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/classifying-datasets.html">
     42.17. Classifying datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/small-diabetes-study.html">
     42.18. Small diabetes study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction-to-statistics-and-probability.html">
     42.19. Introduction to probability and statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/displaying-airport-data.html">
     42.20. Displaying airport data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/soda-profits.html">
     42.21. Soda profits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-COVID-19-papers.html">
     42.22. Analyzing COVID-19 papers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/estimation-of-COVID-19-pandemic.html">
     42.23. Estimation of COVID-19 pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-processing-in-python.html">
     42.24. Data processing in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/evaluating-data-from-a-form.html">
     42.25. Evaluating data from a form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-preparation.html">
     42.26. Data preparation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-data.html">
     42.27. Analyzing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/nyc-taxi-data-in-winter-and-summer.html">
     42.28. NYC taxi data in winter and summer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/matplotlib-applied.html">
     42.29. Matplotlib applied
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/tell-a-story.html">
     42.35. Tell a story
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/explore-a-planetary-computer-dataset.html">
     42.36. Explore a planetary computer dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/exploring-for-anwser.html">
     42.37. Exploring for answers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/market-research.html">
     42.38. Market research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/low-code-no-code-data-science-project-on-azure-ml.html">
     42.39. Low code/no code Data Science project on Azure ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-project-using-azure-ml-sdk.html">
     42.40. Data Science project using Azure ML SDK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-in-the-cloud-the-azure-ml-sdk-way.html">
     42.41. Data Science in the cloud: The “Azure ML SDK” way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-overview-iris.html">
     42.42. Machine Learning overview - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-overview-mnist-digits.html">
     42.43. Machine Learning overview - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression-with-scikit-learn.html">
     42.44. Regression with Scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/linear-regression/california_housing.html">
     42.45. Linear regression - California Housing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/linear-regression/linear-regression-metrics.html">
     42.46. Linear Regression Metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/linear-regression/loss-function.html">
     42.47. Loss Function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/linear-regression/gradient-descent.html">
     42.48. Gradient descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/linear-regression/linear-regression-from-scratch.html">
     42.49. Linear Regression Implementation from Scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-logistic-regression-1.html">
     42.50. ML logistic regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-logistic-regression-2.html">
     42.51. ML logistic regression - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-neural-network-1.html">
     42.52. ML neural network - Assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/build-ml-web-app-1.html">
     42.53. Build ML web app - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/build-ml-web-app-2.html">
     42.54. Build ML web app - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression-tools.html">
     42.55. Regression tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/managing-data.html">
     42.56. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/exploring-visualizations.html">
     42.57. Exploring visualizations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/try-a-different-model.html">
     42.58. Try a different model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/create-a-regression-model.html">
     42.59. Create a regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/linear-and-polynomial-regression.html">
     42.60. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/retrying-some-regression.html">
     42.61. Retrying some regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/pumpkin-varieties-and-color.html">
     42.62. Pumpkin varieties and color
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/delicious-asian-and-indian-cuisines.html">
     42.63. Delicious asian and indian cuisines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/explore-classification-methods.html">
     42.64. Explore classification methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/kernel-method-assignment-1.html">
     42.65. Kernel method assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/support_vector_machines_for_regression.html">
     42.66. Support Vector Machines (SVM) - Intro and SVM for Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/support_vector_machines_for_classification.html">
     42.67. Support Vector Machines (SVM) - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/decision_trees_for_regression.html">
     42.68. Decision Trees - Intro and Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/kernel-method/decision_trees_for_classification.html">
     42.69. Decision Trees - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/model-selection-assignment-1.html">
     42.70. Model selection assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/learning-curve-to-identify-overfit-underfit.html">
     42.71. Learning Curve To Identify Overfit &amp; Underfit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/dropout-and-batch-normalization.html">
     42.72. Dropout and Batch Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/lasso-and-ridge-regression.html">
     42.73. Lasso and Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/model-selection/regularized-linear-models.html">
     42.74. Regularized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/unsupervised-learning/customer-segmentation-clustering.html">
     42.75. Customer segmentation: clustering - assignment 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/random-forests-intro-and-regression.html">
     42.76. Random forests intro and regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/random-forests-for-classification.html">
     42.77. Random forests for classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.html">
     42.78. Beyond random forests: more ensemble models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/decision-trees.html">
     42.79. Decision trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/hyperparameter-tuning-gradient-boosting.html">
     42.80. Hyperparameter tuning gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/gradient-boosting-assignment.html">
     42.81. Gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/boosting-with-tuning.html">
     42.82. Boosting with tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/random-forest-classifier-feature-importance.html">
     42.83. Random Forest Classifier with Feature Importance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/data-engineering.html">
     42.85. Data engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/counterintuitive-challenges-in-ml-debugging.html">
     42.86. Counterintuitive Challenges in ML Debugging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/debugging-in-classification.html">
     42.87. Case Study: Debugging in Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/debugging-in-regression.html">
     42.88. Case Study: Debugging in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/random-forest-classifier.html">
     42.89. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/study-the-solvers.html">
     42.90. Study the solvers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/build-classification-models.html">
     42.91. Build classification models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/build-classification-model.html">
     42.92. Build Classification Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/parameter-play.html">
     42.93. Parameter play
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/how-to-choose-cnn-architecture-mnist.html">
     42.94. How to choose cnn architecture mnist
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/sign-language-digits-classification-with-cnn.html">
     42.96. Sign Language Digits Classification with CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/object-recognition-in-images-using-cnn.html">
     42.98. Object Recognition in Images using CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/image-classification.html">
     42.99. Image classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/tensorflow/intro_to_tensorflow_for_deeplearning.html">
     42.100. Intro to TensorFlow for Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/lstm/bitcoin-lstm-model-with-tweet-volume-and-sentiment.html">
     42.102. Bitcoin LSTM Model with Tweet Volume and Sentiment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/rnn/google-stock-price-prediction-rnn.html">
     42.104. Google Stock Price Prediction RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/autoencoder.html">
     42.106. Intro to Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/base-denoising-autoencoder-dimension-reduction.html">
     42.107. Base/Denoising Autoencoder &amp; Dimension Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/variational-autoencoder-and-faces-generation.html">
     42.108. Fun with Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/time-series-forecasting-assignment.html">
     42.109. Time Series Forecasting Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nn-for-classification-assignment.html">
     42.111. Neural Networks for Classification with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nn-classify-15-fruits-assignment.html">
     42.112. NN Classify 15 Fruits Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/dqn/dqn-on-foreign-exchange-market.html">
     42.117. DQN On Foreign Exchange Market
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/gan/art-by-gan.html">
     42.118. Art by gan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/gan/gan-introduction.html">
     42.120. Generative Adversarial Networks (GANs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/image-segmentation/comparing-edge-based-and-region-based-segmentation.html">
     42.121. Comparing edge-based and region-based segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/difussion-model/denoising-difussion-model.html">
     42.122. Summary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/object-detection/car-object-detection.html">
     42.123. Car Object Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/overview/basic-classification-classify-images-of-clothing.html">
     42.125. Basic classification: Classify images of clothing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nlp/getting-start-nlp-with-classification-task.html">
     42.126. Getting Start NLP with classification task
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nlp/beginner-guide-to-text-preprocessing.html">
     42.128. Beginner’s Guide to Text Pre-Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nlp/news-topic-classification-tasks.html">
     42.129. News topic classification tasks
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     42.130. Complete the transformer architecture
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../slides/introduction.html">
   43. Slides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-introduction.html">
     43.1. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-basics.html">
     43.2. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-advanced.html">
     43.3. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-introduction.html">
     43.4. Data Science introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/relational-vs-non-relational-database.html">
     43.5. Relational vs. non-relational database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/numpy-and-pandas.html">
     43.6. NumPy and Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-visualization.html">
     43.7. Data visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-lifecycle.html">
     43.8. Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-in-the-cloud.html">
     43.9. Data Science in the cloud
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-in-real-world.html">
     43.10. Data Science in real world
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/ml-overview.html">
     43.11. Machine Learning overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/linear-regression.html">
     43.12. Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/logistic-regression.html">
     43.13. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/logistic-regression-condensed.html">
     43.14. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/neural-network.html">
     43.15. Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/build-an-ml-web-app.html">
     43.16. Build an machine learning web application
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/unsupervised-learning.html">
     43.17. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/kernel-method.html">
     43.18. Kernel method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/model-selection.html">
     43.19. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/deep-learning/cnn.html">
     43.20. Convolutional Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/deep-learning/gan.html">
     43.21. Generative Adversarial Network
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ocademy-ai/machine-learning/release?urlpath=lab/tree/open-machine-learning-jupyter-book/assignments/llm/basic/transformer-architecture.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ocademy-ai/machine-learning/blob/release/open-machine-learning-jupyter-book/assignments/llm/basic/transformer-architecture.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning//issues/new?title=Issue%20on%20page%20%2Fassignments/llm/basic/transformer-architecture.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/edit/release/open-machine-learning-jupyter-book/assignments/llm/basic/transformer-architecture.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/assignments/llm/basic/transformer-architecture.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transformer-model">
   42.130.1. Transformer Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#embedding-layer">
   42.130.2. Embedding Layer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#attention-layer">
   42.130.3. Attention Layer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feedforward-layer">
   42.130.4. Feedforward Layer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#residual-connection-and-layer-normalization">
   42.130.5. Residual Connection and Layer Normalization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encoder-and-decoder-structure">
   42.130.6. Encoder and Decoder Structure
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Complete the transformer architecture</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transformer-model">
   42.130.1. Transformer Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#embedding-layer">
   42.130.2. Embedding Layer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#attention-layer">
   42.130.3. Attention Layer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feedforward-layer">
   42.130.4. Feedforward Layer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#residual-connection-and-layer-normalization">
   42.130.5. Residual Connection and Layer Normalization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encoder-and-decoder-structure">
   42.130.6. Encoder and Decoder Structure
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="complete-the-transformer-architecture">
<h1><span class="section-number">42.130. </span>Complete the transformer architecture<a class="headerlink" href="#complete-the-transformer-architecture" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up the env</span>

<span class="kn">import</span> <span class="nn">pytest</span>
<span class="kn">import</span> <span class="nn">ipytest</span>
<span class="kn">import</span> <span class="nn">unittest</span>

<span class="n">ipytest</span><span class="o">.</span><span class="n">autoconfig</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="transformer-model">
<h2><span class="section-number">42.130.1. </span>Transformer Model<a class="headerlink" href="#transformer-model" title="Permalink to this headline">#</a></h2>
<p>The encoder-decoder architecture based on the Transformer structure is illustrated in figure below. The left and right sides correspond to the encoder and decoder structures, respectively. They consist of several basic Transformer blocks (represented by the gray boxes in the figure), stacked N times. Each component comprises multiple Transformer blocks, which are stacked N times.</p>
<p>Here’s an overview of the key components and processes involved in the semantic abstraction process from input to output:</p>
<p>Encoder:</p>
<p>The encoder takes an input sequence {xi}ti=1, where each xi represents the representation of a word in the text sequence.
It consists of stacked Transformer blocks. Each block includes:
Attention Layer: Utilizes multi-head attention mechanisms to capture dependencies between words in the input sequence, facilitating the modeling of long-range dependencies without traditional recurrent structures.
Position-wise Feedforward Layer: Applies complex transformations to the representations of each word in the input sequence.
Residual Connections: Directly connect the input and output of the attention and feedforward layers, aiding in efficient information flow and model optimization.
Layer Normalization: Normalizes the output representations of the attention and feedforward layers, stabilizing optimization.
Decoder:</p>
<p>The decoder generates an output sequence {yi}ti=1 based on the representations learned by the encoder.
Similar to the encoder, it consists of stacked Transformer blocks, each including the same components as described above.
In addition, the decoder includes an additional attention mechanism that focuses on the encoder’s output to incorporate context information during sequence generation.
Overall, the encoder-decoder architecture based on the Transformer structure allows for effective semantic abstraction by leveraging attention mechanisms, position-wise feedforward layers, residual connections, and layer normalization. This architecture enables the model to capture complex dependencies between words in the input sequence and generate meaningful outputs for various sequence-to-sequence tasks.</p>
<figure class="align-default" id="id1">
<img alt="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/Transformer-python-%281%29.png" src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/Transformer-python-%281%29.png" />
<figcaption>
<p><span class="caption-number">Fig. 42.1 </span><span class="caption-text">Transformer-based encoder and decoder Architecture</span><a class="headerlink" href="#id1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Next, we’ll discuss the specific functionalities and implementation methods of each module in detail.</p>
</section>
<section id="embedding-layer">
<h2><span class="section-number">42.130.2. </span>Embedding Layer<a class="headerlink" href="#embedding-layer" title="Permalink to this headline">#</a></h2>
<p>The Embedding Layer in the Transformer model is responsible for converting discrete token indices into continuous vector representations. Each token index is mapped to a high-dimensional vector, which is learned during the training process. These embeddings capture semantic and syntactic information about the tokens.</p>
<p>Implementation in PyTorch:</p>
<p>We define a PositionalEncoder class that inherits from nn.Module.
The constructor initializes the positional encoding matrix (pe) based on the given d_model (dimension of the model) and max_seq_len (maximum sequence length).
The forward method scales the input embeddings (x) by the square root of the model dimension and adds the positional encoding matrix (pe) to the input embeddings.
Note that we’re using PyTorch’s Variable and autograd to ensure that the positional encoding is compatible with the autograd mechanism for backpropagation.
Finally, the PositionalEncoder class can be used within a larger PyTorch model to incorporate positional information into word embeddings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">PositionalEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">max_seq_len</span><span class="o">=</span><span class="mi">80</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="c1"># Creating a constant PE matrix based on pos and i</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_seq_len</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
                <span class="n">pe</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">pos</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">)))</span>
                <span class="n">pe</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">pos</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">)))</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;pe&#39;</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Scaling word embeddings to make them relatively larger</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
        <span class="c1"># Adding positional constants to word embedding representations</span>
        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">Variable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<h5><font color=blue>Check result by executing below... 📝</font></h5><div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">ipytest</span> -qq

class TestPositionalEncoder(unittest.TestCase):
    def setUp(self):
        self.d_model = 512
        self.max_seq_len = 10  # Maximum sequence length for testing
        self.positional_encoder = PositionalEncoder(self.d_model, self.max_seq_len)

    def test_forward(self):
        # Create a sample input tensor representing word embeddings
        batch_size = 2
        seq_length = 5
        word_embeddings = torch.randn(batch_size, seq_length, self.d_model)

        # Forward pass through the PositionalEncoder module
        output = self.positional_encoder(word_embeddings)

        # Check if the output shape matches the input shape
        assert output.shape == (batch_size, seq_length, self.d_model)

        # Check if positional encoding is correctly applied
        # Example: Verify if the first element of the first embedding vector matches the expected value
        expected_first_element = torch.sin(torch.tensor([0.0])) * math.sqrt(self.d_model)
        assert math.isclose(output[0, 0, 0].item(), expected_first_element.item(), rel_tol=1e-6)
</pre></div>
</div>
</div>
</div>
</section>
<section id="attention-layer">
<h2><span class="section-number">42.130.3. </span>Attention Layer<a class="headerlink" href="#attention-layer" title="Permalink to this headline">#</a></h2>
<p>The Attention Layer in the Transformer model enables the model to focus on different parts of the input sequence when processing each token. It computes attention scores between each pair of tokens in the input sequence and generates a context vector for each token based on the importance of other tokens. This mechanism allows the model to capture long-range dependencies in the input sequence effectively.</p>
<p>Implementation in PyTorch:</p>
<p>The MultiHeadAttention class defines a multi-head self-attention layer.
The forward method performs linear operations to divide inputs into multiple heads, computes attention scores, and aggregates the outputs of multiple heads.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="n">heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">attention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">d_k</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d_k</span><span class="p">)</span>
        <span class="c1"># Masking out those units added for length padding, setting them to zero after softmax computation</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">dropout</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># Linear operations to divide into h heads</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_linear</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_linear</span><span class="p">(</span><span class="n">q</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_linear</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
        <span class="c1"># Matrix transposition</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># Computing attention</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
        <span class="c1"># Concatenating multiple heads and feeding into the final linear layer</span>
        <span class="n">concat</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">concat</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
<h5><font color=blue>Check result by executing below... 📝</font></h5><div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">ipytest</span> -qq

class TestMultiHeadAttention(unittest.TestCase):
    def test_forward(self):
        # Instantiate MultiHeadAttention module
        heads = 4
        d_model = 64
        dropout = 0.1
        multihead_attn = MultiHeadAttention(heads, d_model, dropout)

        # Create sample input tensors
        batch_size = 2
        seq_length = 5
        q = torch.randn(batch_size, seq_length, d_model)
        k = torch.randn(batch_size, seq_length, d_model)
        v = torch.randn(batch_size, seq_length, d_model)
        mask = torch.randint(0, 2, (batch_size, 1, seq_length))  # Example mask tensor

        # Forward pass through the MultiHeadAttention module
        output = multihead_attn(q, k, v, mask)

        # Check output shape
        self.assertEqual(output.shape, (batch_size, seq_length, d_model))
</pre></div>
</div>
</div>
</div>
</section>
<section id="feedforward-layer">
<h2><span class="section-number">42.130.4. </span>Feedforward Layer<a class="headerlink" href="#feedforward-layer" title="Permalink to this headline">#</a></h2>
<p>The Position-wise Feedforward Layer in the Transformer model applies a simple feedforward neural network independently to each position in the sequence. It consists of two linear transformations with a non-linear activation function (commonly ReLU) applied in between. This layer helps capture complex interactions between different dimensions of the input embeddings.</p>
<p>Implementation in PyTorch:</p>
<p>The FeedForward class defines a feedforward layer.
The forward method applies ReLU activation to the output of the first linear transformation, followed by dropout, and then performs the second linear transformation to produce the final output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Setting d_ff default to 2048</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_ff</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<h5><font color=blue>Check result by executing below... 📝</font></h5><div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">ipytest</span> -qq

class TestFeedForward(unittest.TestCase):
    def test_forward(self):
        # Instantiate FeedForward module
        d_model = 512
        d_ff = 2048
        dropout = 0.1
        feed_forward = FeedForward(d_model, d_ff, dropout)

        # Create sample input tensor
        batch_size = 2
        seq_length = 5
        input_tensor = torch.randn(batch_size, seq_length, d_model)

        # Forward pass through the FeedForward module
        output = feed_forward(input_tensor)

        # Check output shape
        self.assertEqual(output.shape, (batch_size, seq_length, d_model))
</pre></div>
</div>
</div>
</div>
</section>
<section id="residual-connection-and-layer-normalization">
<h2><span class="section-number">42.130.5. </span>Residual Connection and Layer Normalization<a class="headerlink" href="#residual-connection-and-layer-normalization" title="Permalink to this headline">#</a></h2>
<p>Residual Connection:
The Residual Connection, also known as skip connection, is a technique used in deep neural networks to mitigate the vanishing gradient problem and facilitate the flow of information through the network. In the context of the Transformer model, residual connections are added around each sub-layer (such as attention and feedforward layers) before applying layer normalization. This allows the model to learn residual representations and thus ease the optimization process.</p>
<p>Layer Normalization:
Layer Normalization is a technique used to stabilize the training of deep neural networks by normalizing the activations of each layer. In the Transformer model, layer normalization is applied after each sub-layer (such as attention and feedforward layers) and before the residual connection. It normalizes the activations along the feature dimension, allowing the model to learn more robust representations and accelerate convergence during training.</p>
<p>Implementation in PyTorch:</p>
<p>The NormLayer class defines a layer normalization layer.
The forward method computes the layer normalization using the given input tensor x.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NormLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="c1"># Layer normalization includes two learnable parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> \
                <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
        <span class="k">return</span> <span class="n">norm</span>
</pre></div>
</div>
</div>
</div>
<h5><font color=blue>Check result by executing below... 📝</font></h5><div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">ipytest</span> -qq

class TestNormLayer(unittest.TestCase):
    def test_forward(self):
        # Instantiate NormLayer module
        d_model = 512
        eps = 1e-6
        norm_layer = NormLayer(d_model, eps)

        # Create sample input tensor
        batch_size = 2
        seq_length = 5
        input_tensor = torch.randn(batch_size, seq_length, d_model)

        # Forward pass through the NormLayer module
        output = norm_layer(input_tensor)

        # Check output shape
        self.assertEqual(output.shape, (batch_size, seq_length, d_model))
</pre></div>
</div>
</div>
</div>
</section>
<section id="encoder-and-decoder-structure">
<h2><span class="section-number">42.130.6. </span>Encoder and Decoder Structure<a class="headerlink" href="#encoder-and-decoder-structure" title="Permalink to this headline">#</a></h2>
<p>Encoder Structure:
The Encoder in the Transformer model consists of multiple stacked Encoder layers. Each Encoder layer typically contains a Multi-Head Attention sub-layer followed by a FeedForward sub-layer, each with Residual Connection and Layer Normalization.</p>
<p>Decoder Structure:
Similarly, the Decoder in the Transformer model also consists of multiple stacked Decoder layers. Each Decoder layer contains three sub-layers:</p>
<p>Masked Multi-Head Attention sub-layer to attend to previous tokens in the output sequence.
Multi-Head Attention sub-layer that attends to the encoder’s output.
FeedForward sub-layer. Again, each sub-layer is followed by Residual Connection and Layer Normalization.</p>
<p>Below are the Python implementations for the Encoder and Decoder structures:</p>
<p>The EncoderLayer and DecoderLayer classes define encoder and decoder layers, respectively.
The Encoder and Decoder classes define encoder and decoder modules, respectively, composed of multiple layers of encoder or decoder layers.
These classes follow the architecture described in the text, including the use of multi-head attention, feedforward layers, residual connections, and layer normalization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Embedder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Embedder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_clones</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)])</span>

<span class="k">class</span> <span class="nc">PositionalEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PositionalEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">))</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;pe&#39;</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">EncoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_1</span> <span class="o">=</span> <span class="n">NormLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_2</span> <span class="o">=</span> <span class="n">NormLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ff</span><span class="p">(</span><span class="n">x2</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">Embedder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pe</span> <span class="o">=</span> <span class="n">PositionalEncoder</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">get_clones</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">),</span> <span class="n">N</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">NormLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DecoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_1</span> <span class="o">=</span> <span class="n">NormLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_2</span> <span class="o">=</span> <span class="n">NormLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_3</span> <span class="o">=</span> <span class="n">NormLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_1</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_2</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">e_outputs</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">trg_mask</span><span class="p">):</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn_1</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">trg_mask</span><span class="p">))</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn_2</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">e_outputs</span><span class="p">,</span> <span class="n">e_outputs</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">))</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ff</span><span class="p">(</span><span class="n">x2</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">Embedder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pe</span> <span class="o">=</span> <span class="n">PositionalEncoder</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">get_clones</span><span class="p">(</span><span class="n">DecoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">),</span> <span class="n">N</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">NormLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">e_outputs</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">trg_mask</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">trg</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">e_outputs</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">trg_mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The overall implementation of the Transformer encoder and decoder structure:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">trg_vocab</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">trg_vocab</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">trg_vocab</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">trg_mask</span><span class="p">):</span>
        <span class="n">e_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">)</span>
        <span class="n">d_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">trg</span><span class="p">,</span> <span class="n">e_outputs</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">trg_mask</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">d_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
<p>The training process for the Transformer model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sample English and French text data</span>
<span class="n">en_data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;I love coding.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Machine learning is fascinating.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Natural language processing is fun.&quot;</span>
<span class="p">]</span>

<span class="n">fr_data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;J&#39;adore coder.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;L&#39;apprentissage automatique est fascinant.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Le traitement du langage naturel est amusant.&quot;</span>
<span class="p">]</span>

<span class="k">def</span> <span class="nf">tokenize_en</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="c1"># You can implement a more sophisticated tokenizer here if needed</span>
    <span class="k">return</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>  <span class="c1"># Simple tokenizer, converts to lowercase and splits by space</span>

<span class="k">def</span> <span class="nf">tokenize_fr</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="c1"># You can implement a more sophisticated tokenizer here if needed</span>
    <span class="k">return</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>  <span class="c1"># Simple tokenizer, converts to lowercase and splits by space</span>
<span class="c1"># Tokenize English and French text</span>
<span class="n">en_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenize_en</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">en_data</span><span class="p">]</span>
<span class="n">fr_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenize_fr</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">fr_data</span><span class="p">]</span>

<span class="c1"># Create English and French vocabularies</span>
<span class="n">en_vocab</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;&lt;sos&gt;&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>  <span class="c1"># Initialize with special tokens</span>
<span class="n">fr_vocab</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;&lt;sos&gt;&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>  <span class="c1"># Initialize with special tokens</span>

<span class="c1"># Build English vocabulary</span>
<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">en_sentences</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">en_vocab</span><span class="p">:</span>
            <span class="n">en_vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">en_vocab</span><span class="p">)</span>

<span class="c1"># Build French vocabulary</span>
<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">fr_sentences</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">fr_vocab</span><span class="p">:</span>
            <span class="n">fr_vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">fr_vocab</span><span class="p">)</span>

<span class="c1"># Reverse vocabularies to get index-to-token mappings</span>
<span class="n">en_index_to_word</span> <span class="o">=</span> <span class="p">{</span><span class="n">index</span><span class="p">:</span> <span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">en_vocab</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">fr_index_to_word</span> <span class="o">=</span> <span class="p">{</span><span class="n">index</span><span class="p">:</span> <span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">fr_vocab</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="c1"># Model parameters</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">heads</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">src_vocab</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">en_vocab</span><span class="p">)</span>
<span class="n">trg_vocab</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">fr_vocab</span><span class="p">)</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.1</span> 

<span class="c1"># Initialize the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">,</span> <span class="n">trg_vocab</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="c1"># Optimizer</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>


<span class="c1"># Training the model</span>
<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">en_sentences</span><span class="p">,</span> <span class="n">fr_sentences</span><span class="p">,</span> <span class="n">print_every</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">start</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">en_sentences</span><span class="p">)):</span>
            <span class="n">src_sentence</span> <span class="o">=</span> <span class="n">en_sentences</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">trg_sentence</span> <span class="o">=</span> <span class="n">fr_sentences</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            
            <span class="n">src_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">en_vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">src_sentence</span><span class="p">])</span>
            <span class="n">trg_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">fr_vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">trg_sentence</span><span class="p">])</span>
            
            <span class="n">src</span> <span class="o">=</span> <span class="n">src_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Add batch dimension</span>
            <span class="n">trg</span> <span class="o">=</span> <span class="n">trg_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Add batch dimension</span>
            
            <span class="n">trg_input</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="n">src_mask</span><span class="p">,</span> <span class="n">trg_mask</span> <span class="o">=</span> <span class="n">create_masks</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg_input</span><span class="p">)</span>
            
            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">trg_input</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">trg_mask</span><span class="p">)</span>
            
            <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">preds</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">targets</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="n">fr_vocab</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">])</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            
            <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">loss_avg</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">print_every</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;time = </span><span class="si">%d</span><span class="s2">m, epoch </span><span class="si">%d</span><span class="s2">, iter = </span><span class="si">%d</span><span class="s2">, loss = </span><span class="si">%.3f</span><span class="s2">, </span><span class="si">%d</span><span class="s2">s per </span><span class="si">%d</span><span class="s2"> iters&quot;</span> <span class="o">%</span> <span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">//</span> <span class="mi">60</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loss_avg</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">temp</span><span class="p">,</span> <span class="n">print_every</span><span class="p">))</span>
                <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">temp</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                
<span class="n">train_model</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">en_sentences</span><span class="p">,</span> <span class="n">fr_sentences</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Test the trained model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Test the model</span>
<span class="k">def</span> <span class="nf">translate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">src_sentence</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">fr_vocab</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">80</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># Tokenize the source sentence</span>
    <span class="n">src_tokens</span> <span class="o">=</span> <span class="n">tokenize_en</span><span class="p">(</span><span class="n">src_sentence</span><span class="p">)</span>
    
    <span class="c1"># Convert tokens to indices using the English vocabulary</span>
    <span class="n">src_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">en_vocab</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">[</span><span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">src_tokens</span><span class="p">]</span>
    
    <span class="c1"># Convert indices to tensor and add batch dimension</span>
    <span class="n">src_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">src_indices</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Initialize target input with &#39;&lt;sos&gt;&#39; token</span>
    <span class="n">trg_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="n">fr_vocab</span><span class="p">[</span><span class="s1">&#39;&lt;sos&gt;&#39;</span><span class="p">]]])</span>
    
    <span class="c1"># Initialize list to store the generated translation</span>
    <span class="n">translation</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>
            <span class="c1"># Generate mask for source sentence</span>
            <span class="n">src_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">src_tensor</span> <span class="o">!=</span> <span class="n">en_vocab</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c1"># Generate mask for target sentence</span>
            <span class="n">trg_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">src_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
            
            <span class="c1"># Generate predictions for next token</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">src_tensor</span><span class="p">,</span> <span class="n">trg_input</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">trg_mask</span><span class="p">)</span>
            
            <span class="c1"># Get predicted token (index)</span>
            <span class="n">pred_token</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            
            <span class="c1"># Append predicted token to translation list</span>
            <span class="n">translation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_token</span><span class="p">)</span>
            
            <span class="c1"># If predicted token is end-of-sentence token, stop</span>
            <span class="k">if</span> <span class="n">pred_token</span> <span class="o">==</span> <span class="n">fr_vocab</span><span class="p">[</span><span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">]:</span>
                <span class="k">break</span>
            
            <span class="c1"># Append predicted token to target input for next iteration</span>
            <span class="n">trg_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">trg_input</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="n">pred_token</span><span class="p">]])],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Convert indices back to tokens using the French vocabulary</span>
    <span class="n">translated_sentence</span> <span class="o">=</span> <span class="p">[</span><span class="n">fr_index_to_word</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">translation</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">translated_sentence</span><span class="p">)</span>

<span class="k">for</span> <span class="n">src_sentence</span> <span class="ow">in</span> <span class="n">en_data</span><span class="p">:</span>
    <span class="n">translation</span> <span class="o">=</span> <span class="n">translate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">src_sentence</span><span class="p">,</span> <span class="n">en_vocab</span><span class="p">,</span> <span class="n">fr_vocab</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Source:&quot;</span><span class="p">,</span> <span class="n">src_sentence</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Translation:&quot;</span><span class="p">,</span> <span class="n">translation</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ocademy-ai/machine-learning",
            ref: "release",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./assignments/llm/basic"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../../deep-learning/nlp/news-topic-classification-tasks.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">42.129. </span>News topic classification tasks</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../../../slides/introduction.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">43. </span>Slides</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ocademy<br/>
  
      &copy; Copyright 2022-2023.<br/>
    <div class="extra_footer">
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> Text content of this work is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>