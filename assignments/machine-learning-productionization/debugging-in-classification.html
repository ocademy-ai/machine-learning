
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>39.64. Case Study: Debugging in Classification &#8212; Machine Learning Open Book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/drawio.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/youtube.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "open-academy/machine-learning-utterances");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "üí¨ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"></script>
    <script>quizdown.init({"quizdown_js": "https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"});</script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="39.65. Case Study: Debugging in Regression" href="debugging-in-regression.html" />
    <link rel="prev" title="39.63. Counterintuitive Challenges in ML Debugging" href="counterintuitive-challenges-in-ml-debugging.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning Open Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PREREQUISITES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../prerequisites/python-programming-introduction.html">
   1. Python programming introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prerequisites/python-programming-basics.html">
   2. Python programming basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prerequisites/python-programming-advanced.html">
   3. Python programming advanced
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATA SCIENCE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data-science/introduction/introduction.html">
   4. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction/defining-data-science.html">
     4.1. Defining data science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction/data-science-ethics.html">
     4.2. Data Science ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction/defining-data.html">
     4.3. Defining data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction/introduction-to-statistics-and-probability.html">
     4.4. Introduction to statistics and probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data-science/working-with-data/working-with-data.html">
   5. Working with data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/working-with-data/relational-databases.html">
     5.1. Relational databases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/working-with-data/non-relational-data.html">
     5.2. Non-relational data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/working-with-data/numpy.html">
     5.3. NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/working-with-data/pandas.html">
     5.4. Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/working-with-data/data-preparation.html">
     5.5. Data preparation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data-science/data-visualization/data-visualization.html">
   6. Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-visualization/visualizing-quantities.html">
     6.1. Visualizing quantities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-visualization/visualization-distributions.html">
     6.2. Visualizing distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-visualization/visualization-proportions.html">
     6.3. Visualizing proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-visualization/visualization-relationships.html">
     6.4. Visualizing relationships: all about honey üçØ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-visualization/meaningful-visualizations.html">
     6.5. Making meaningful visualizations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data-science/data-science-lifecycle/data-science-lifecycle.html">
   7. Data Science lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-lifecycle/introduction.html">
     7.1. Introduction to the Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-lifecycle/analyzing.html">
     7.2. Analyzing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-lifecycle/communication.html">
     7.3. Communication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data-science/data-science-in-the-cloud/data-science-in-the-cloud.html">
   8. Data Science in the cloud
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-in-the-cloud/introduction.html">
     8.1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-in-the-cloud/the-low-code-no-code-way.html">
     8.2. The ‚Äúlow code/no code‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-in-the-cloud/the-azure-ml-sdk-way.html">
     8.3. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data-science/data-science-in-the-wild.html">
   9. Data Science in the real world
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  FUNDAMENTALS OF MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-fundamentals/ml-overview.html">
   10. Machine learning overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-fundamentals/regression/regression-models-for-machine-learning.html">
   11. Regression models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression/tools-of-the-trade.html">
     11.1. Tools of the trade
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression/managing-data.html">
     11.2. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression/linear-and-polynomial-regression.html">
     11.3. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression/logistic-regression.html">
     11.4. Logistic regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-fundamentals/build-a-web-app-to-use-a-machine-learning-model.html">
   12. Build a web app to use a Machine Learning model
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-fundamentals/classification/getting-started-with-classification.html">
   13. Getting started with classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/classification/introduction-to-classification.html">
     13.1. Introduction to classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/classification/more-classifiers.html">
     13.2. More classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/classification/yet-other-classifiers.html">
     13.3. Yet other classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/classification/applied-ml-build-a-web-app.html">
     13.4. Applied Machine Learning : build a web app
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ADVANCED MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-advanced/clustering/clustering-models-for-machine-learning.html">
   14. Clustering models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/clustering/introduction-to-clustering.html">
     14.1. Introduction to clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/clustering/k-means-clustering.html">
     14.2. K-Means clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/kernel-method.html">
   15. Kernel method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/model-selection.html">
   16. Model selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/ensemble-learning.html">
   17. Ensemble learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/unsupervised-learning.html">
   18. Unsupervised learning (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/generative-models.html">
   19. Generative models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/dl-overview.html">
   20. Deep learning overview (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/CNN.html">
   21. Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/GAN.html">
   22. Generative adversarial networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/RNN.html">
   23. Recurrent Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/AutoEncoder.html">
   24. Autoencoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/LSTM.html">
   25. Long-short term memory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/NLP.html">
   26. NLP (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/time-series.html">
   27. Time series (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/DQN.html">
   28. DQN (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/dl-summary.html">
   29. Summary of deep learning (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/image-classification.html">
   30. Image classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/image-segmentation.html">
   31. Image segmentation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING PRODUCTIONIZATION
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/overview.html">
   32. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/problem-framing.html">
   33. Problem framing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/data-engineering.html">
   34. Data engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/model-training-and-evaluation.html">
   35. Model training &amp; evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/model-deployment.html">
   36. Model deployment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  SUPPORTING MATERIALS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../supporting-materials/unbalanced-problems.html">
   37. Unbalanced problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../supporting-materials/automl.html">
   38. AutoML (TBD)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OTHERS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../introduction.html">
   39. Assignments
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../get-started.html">
     39.1. Get started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../set-up-env/first-assignment.html">
     39.2. First assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../set-up-env/second-assignment.html">
     39.3. Second assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../project-plan-template.html">
     39.4. Project Plan‚Äã Template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prerequisites/python-programming-introduction.html">
     39.5. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prerequisites/python-programming-basics.html">
     39.6. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prerequisites/python-programming-advanced.html">
     39.7. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/analyzing-text-about-data-science.html">
     39.8. Analyzing text about Data Science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-scenarios.html">
     39.9. Data Science scenarios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/write-a-data-ethics-case-study.html">
     39.10. Write a data ethics case study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/lines-scatters-and-bars.html">
     39.11. Lines, scatters and bars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/apply-your-skills.html">
     39.12. Apply your skills
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/try-it-in-excel.html">
     39.13. Try it in Excel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/let-us-learn-about-birds.html">
     39.14. Let‚Äôs learn about birds
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/bird-distributions.html">
     39.15. Bird distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/dive-into-the-beehive.html">
     39.16. Dive into the beehive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/build-your-own-custom-vis.html">
     39.17. Build your own custom vis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/classifying-datasets.html">
     39.18. Classifying datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/small-diabetes-study.html">
     39.19. Small diabetes study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/introduction-to-statistics-and-probability.html">
     39.20. Introduction to probability and statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/displaying-airport-data.html">
     39.21. Displaying airport data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/soda-profits.html">
     39.22. Soda profits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/analyzing-COVID-19-papers.html">
     39.23. Analyzing COVID-19 papers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/estimation-of-COVID-19-pandemic.html">
     39.24. Estimation of COVID-19 pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-processing-in-python.html">
     39.25. Data processing in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/evaluating-data-from-a-form.html">
     39.26. Evaluating data from a form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-preparation.html">
     39.27. Data preparation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/analyzing-data.html">
     39.28. Analyzing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/nyc-taxi-data-in-winter-and-summer.html">
     39.29. NYC taxi data in winter and summer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/matplotlib-applied.html">
     39.30. Matplotlib applied
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/tell-a-story.html">
     39.36. Tell a story
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/explore-a-planetary-computer-dataset.html">
     39.37. Explore a planetary computer dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/exploring-for-anwser.html">
     39.38. Exploring for answers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/market-research.html">
     39.39. Market research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/low-code-no-code-data-science-project-on-azure-ml.html">
     39.40. Low code/no code Data Science project on Azure ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-project-using-azure-ml-sdk.html">
     39.41. Data Science project using Azure ML SDK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-in-the-cloud-the-azure-ml-sdk-way.html">
     39.42. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/ml-overview-iris.html">
     39.43. Machine Learning overview - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/ml-overview-mnist-digits.html">
     39.44. Machine Learning overview - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/regression-with-scikit-learn.html">
     39.45. Regression with Scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/ml-linear-regression-1.html">
     39.46. ML linear regression - Assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/ml-linear-regression-2.html">
     39.47. ML linear regression - Assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/regression-tools.html">
     39.48. Regression tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/managing-data.html">
     39.49. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/exploring-visualizations.html">
     39.50. Exploring visualizations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/try-a-different-model.html">
     39.51. Try a different model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/create-a-regression-model.html">
     39.52. Create a regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/linear-and-polynomial-regression.html">
     39.53. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/build-classification-models-predict-the-price-range.html">
     39.54. Build classification modelsÔºöPredict the price range
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/retrying-some-regression.html">
     39.55. Retrying some regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/pumpkin-varieties-and-color.html">
     39.56. Pumpkin varieties and color
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/delicious-asian-and-indian-cuisines.html">
     39.57. Delicious asian and indian cuisines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/explore-classification-methods.html">
     39.58. Explore classification methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/ensemble-learning/random-forests-intro-and-regression.html">
     39.59. Random forests intro and regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/ensemble-learning/random-forests-for-classification.html">
     39.60. Random forests for classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.html">
     39.61. Beyond random forests: more ensemble models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="data-engineering.html">
     39.62. Data engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="counterintuitive-challenges-in-ml-debugging.html">
     39.63. Counterintuitive Challenges in ML Debugging
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     39.64. Case Study: Debugging in Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="debugging-in-regression.html">
     39.65. Case Study: Debugging in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/study-the-solvers.html">
     39.66. Study the solvers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/build-classification-models.html">
     39.67. Build classification models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/build-classification-model.html">
     39.68. Build Classification Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/parameter-play.html">
     39.69. Parameter play
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../slides/introduction.html">
   40. Slides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/python-programming/python-programming-introduction.html">
     40.1. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/python-programming/python-programming-basics.html">
     40.2. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/python-programming/python-programming-advanced.html">
     40.3. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/data-science-introduction.html">
     40.4. Data Science introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/relational-vs-non-relational-database.html">
     40.5. Relational vs. non-relational database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/numpy-and-pandas.html">
     40.6. NumPy and Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/data-visualization.html">
     40.7. Data visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/data-science-lifecycle.html">
     40.8. Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/data-science-in-the-cloud.html">
     40.9. Data Science in the cloud
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/data-science-in-real-world.html">
     40.10. Data Science in real world
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-fundamentals/ml-overview.html">
     40.11. Machine Learning overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-fundamentals/linear-regression.html">
     40.12. Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-fundamentals/logistic-regression.html">
     40.13. Logistic Regression
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/open-academy/machine-learning/main?urlpath=tree/open-machine-learning-jupyter-book/assignments/machine-learning-productionization/debugging-in-classification.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/open-academy/machine-learning/blob/main/open-machine-learning-jupyter-book/assignments/machine-learning-productionization/debugging-in-classification.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/open-academy/machine-learning/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/open-academy/machine-learning//issues/new?title=Issue%20on%20page%20%2Fassignments/machine-learning-productionization/debugging-in-classification.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/open-academy/machine-learning/edit/main/open-machine-learning-jupyter-book/assignments/machine-learning-productionization/debugging-in-classification.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/assignments/machine-learning-productionization/debugging-in-classification.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-mnist-data">
   39.64.1. Load MNIST Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#understanding-the-data-format">
   39.64.2. Understanding the Data Format
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#do-you-have-imbalanced-classes">
   39.64.3. Do you have Imbalanced Classes?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shuffle-and-split-dataset">
   39.64.4. Shuffle and Split Dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#process-data">
   39.64.5. Process Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#solution">
     39.64.5.1. Solution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#remove-all-zero-features">
   39.64.6. Remove All-Zero Features?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#establish-baseline">
   39.64.7. Establish Baseline
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-a-linear-model">
   39.64.8. Train a Linear Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     39.64.8.1. Solution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fixing-loss-calculation">
   39.64.9. Fixing Loss Calculation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-a-nonlinear-model">
   39.64.10. Train a Nonlinear Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adding-a-second-layer">
   39.64.11. Adding a Second Layer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-for-training-validation-data-skew">
   39.64.12. Check for Training/Validation Data Skew
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#apply-dropout-regularization">
   39.64.13. Apply Dropout Regularization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-accuracy-for-data-slices">
   39.64.14. Check Accuracy for Data Slices
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-for-anomalous-values">
   39.64.15. Testing for Anomalous Values
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optional-pass-tests-by-fixing-loss-calculation">
   39.64.16. Optional: Pass Tests by Fixing Loss Calculation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   39.64.17. Conclusion
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Case Study: Debugging in Classification</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-mnist-data">
   39.64.1. Load MNIST Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#understanding-the-data-format">
   39.64.2. Understanding the Data Format
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#do-you-have-imbalanced-classes">
   39.64.3. Do you have Imbalanced Classes?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shuffle-and-split-dataset">
   39.64.4. Shuffle and Split Dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#process-data">
   39.64.5. Process Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#solution">
     39.64.5.1. Solution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#remove-all-zero-features">
   39.64.6. Remove All-Zero Features?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#establish-baseline">
   39.64.7. Establish Baseline
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-a-linear-model">
   39.64.8. Train a Linear Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     39.64.8.1. Solution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fixing-loss-calculation">
   39.64.9. Fixing Loss Calculation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-a-nonlinear-model">
   39.64.10. Train a Nonlinear Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adding-a-second-layer">
   39.64.11. Adding a Second Layer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-for-training-validation-data-skew">
   39.64.12. Check for Training/Validation Data Skew
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#apply-dropout-regularization">
   39.64.13. Apply Dropout Regularization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-accuracy-for-data-slices">
   39.64.14. Check Accuracy for Data Slices
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-for-anomalous-values">
   39.64.15. Testing for Anomalous Values
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optional-pass-tests-by-fixing-loss-calculation">
   39.64.16. Optional: Pass Tests by Fixing Loss Calculation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   39.64.17. Conclusion
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <details><summary><b>LICENSE</b></summary>
<p>Copyright 2018 Google LLC.</p>
<p>Licensed under the Apache License, Version 2.0 (the ‚ÄúLicense‚Äù);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p>
<p><a class="reference external" href="https://www.apache.org/licenses/LICENSE-2.0">https://www.apache.org/licenses/LICENSE-2.0</a></p>
<p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ‚ÄúAS IS‚Äù BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</p>
</details><section class="tex2jax_ignore mathjax_ignore" id="case-study-debugging-in-classification">
<h1><span class="section-number">39.64. </span>Case Study: Debugging in Classification<a class="headerlink" href="#case-study-debugging-in-classification" title="Permalink to this headline">#</a></h1>
<p>This Colab quickly demonstrates a few concepts related to debugging classification models. You will explore potential problems in implementing these tasks:</p>
<ul class="simple">
<li><p>Calculating loss for classification problems.</p></li>
<li><p>Optimizing your model</p></li>
<li><p>Applying regularization.</p></li>
<li><p>Following best practices in development and debugging.</p></li>
</ul>
<p>Please <strong>make a copy</strong> of this Colab before running it. Click on <em>File</em>, and then click on <em>Save a copy in Drive</em>.</p>
<section id="load-mnist-data">
<h2><span class="section-number">39.64.1. </span>Load MNIST Data<a class="headerlink" href="#load-mnist-data" title="Permalink to this headline">#</a></h2>
<p>MNIST is a dataset of images of the numbers 0 to 9. The problem is to classify the images as numbers. Setup libraries and load the MNIST dataset. Display the first few rows to verify that the data loaded. You‚Äôll explore the data format after the data loads.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reset environment for a new run</span>
<span class="o">%</span><span class="k">reset</span> -f

<span class="c1"># Load Libraries</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">join</span> <span class="c1"># for joining file pathnames</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">unittest</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># Set Pandas display options</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">float_format</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{:.1f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span>

<span class="c1"># Load data</span>
<span class="n">mnistDf_backup</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
  <span class="s2">&quot;https://download.mlcc.google.com/mledu-datasets/mnist_train_small.csv&quot;</span><span class="p">,</span>
  <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">,</span>
  <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># Shuffle data</span>
<span class="n">mnistDf_backup</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Use the first 5000 examples for faster prototyping</span>
<span class="n">mnistDf</span> <span class="o">=</span> <span class="n">mnistDf_backup</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5000</span><span class="p">]</span>

<span class="n">mnistDf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="understanding-the-data-format">
<h2><span class="section-number">39.64.2. </span>Understanding the Data Format<a class="headerlink" href="#understanding-the-data-format" title="Permalink to this headline">#</a></h2>
<p>Each row represents one labeled example. Column 0 represents the label that a human rater has assigned for one handwritten digit. For example, if Column 0 contains ‚Äò6‚Äô, then a human rater interpreted the handwritten character as the digit ‚Äò6‚Äô.  The ten digits 0-9 are each represented, with a unique class label for each possible digit. Thus, this is a multi-class classification problem with 10 classes.</p>
<p><img alt="img" src="https://www.tensorflow.org/versions/r0.11/images/MNIST-Matrix.png" /></p>
<p>Columns 1 through 784 contain the feature values, one per pixel for the 28√ó28=784 pixel values. The pixel values are on a gray scale in which 0 represents white, 255 represents black, and values between 0 and 255 represent shades of gray. Most of the pixel values are 0; you may want to take a minute to confirm that they aren‚Äôt all 0.  Modify the form below and run the code to view data for a given example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">showExample</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c1"># @param</span>
<span class="n">digitData</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">showExample</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">])</span>
<span class="nb">print</span> <span class="n">digitData</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="do-you-have-imbalanced-classes">
<h2><span class="section-number">39.64.3. </span>Do you have Imbalanced Classes?<a class="headerlink" href="#do-you-have-imbalanced-classes" title="Permalink to this headline">#</a></h2>
<p>As we read in the course, imbalanced classes make classification harder. Let‚Äôs look at the distribution of classes. Do you have imbalanced classes?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">hide_result</span> # hides result of cell computation
<span class="c1"># Calculate the number of classes</span>
<span class="n">numClasses</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># Plot histogram of class distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>The preceding graph shows that the 10 classes are roughly equally represented.</p>
</section>
<section id="shuffle-and-split-dataset">
<h2><span class="section-number">39.64.4. </span>Shuffle and Split Dataset<a class="headerlink" href="#shuffle-and-split-dataset" title="Permalink to this headline">#</a></h2>
<p>As part of <a class="reference external" href="https://developers.google.com/machine-learning/testing-debugging/common/data-errors">Data Debugging</a> best practices, ensure your splits are statistically equivalent by shuffling your data to remove any pre-existing order.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Shuffle data</span>
<span class="n">mnistDf</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Split dataset into data and labels</span>
<span class="n">mnistData</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mnistLabels</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="process-data">
<h2><span class="section-number">39.64.5. </span>Process Data<a class="headerlink" href="#process-data" title="Permalink to this headline">#</a></h2>
<p>Scale the data values to <code class="docutils literal notranslate"><span class="pre">[0,1]</span></code> since the values are bounded to <code class="docutils literal notranslate"><span class="pre">[0,255]</span></code> and do not contain outliers. Then check that the scaled data values are as expected by generating summary statistics using the <code class="docutils literal notranslate"><span class="pre">DataFrame.describe()</span></code> function.</p>
<p>Run the following cell to scale data and generate statistics. This cell takes a few minutes to run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">minMaxScaler</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
  <span class="nb">min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
  <span class="n">arr</span> <span class="o">=</span> <span class="p">(</span><span class="n">arr</span><span class="o">-</span><span class="nb">min</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>
  <span class="k">return</span> <span class="n">arr</span>

<span class="k">for</span> <span class="n">featureIdx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
  <span class="n">mnistData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="n">featureIdx</span><span class="p">]</span> <span class="o">=</span> <span class="n">minMaxScaler</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="n">featureIdx</span><span class="p">])</span>

<span class="n">mnistData</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Oh no! Some of your features are all <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. What do you think the cause is? Hint: While NaNs have many causes, in this case, the NaN values are caused by the properties of your data. Use the next code cell to explore your data. Then check the next cell for the solution. Try to find the solution yourself. Debugging <code class="docutils literal notranslate"><span class="pre">NaN</span></code>s and exploring your data are important skills.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First reload your data</span>
<span class="n">mnistData</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Explore your data</span>
</pre></div>
</div>
</div>
</div>
<section id="solution">
<h3><span class="section-number">39.64.5.1. </span>Solution<a class="headerlink" href="#solution" title="Permalink to this headline">#</a></h3>
<p>Start exploring your data by generating a high-level summary using <code class="docutils literal notranslate"><span class="pre">Dataframe.describe()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mnistData</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Because some of the feature columns are all zeros, the scaling function divided by 0 (because <code class="docutils literal notranslate"><span class="pre">np.max</span></code> returns 0). The division by 0 resulted in NaN values. This result shows you how easily NaNs can arise in engineered data. The <code class="docutils literal notranslate"><span class="pre">describe</span></code> function will not detect every occurrence of NaN (or None). Instead,  use the command <code class="docutils literal notranslate"><span class="pre">DataFrame.isnull().any()</span></code>.</p>
<p><em>Note</em>: Given the maximum value of the feature data is 255, you could simply divide the input by 255 instead of using min-max scaling, and avoid introducing NaNs. However, this example purposely uses min-max scaling to show how NaNs can appear in engineered data.</p>
<p>Now let‚Äôs try scaling the data again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Redefine the scaling function to check for zeros</span>
<span class="k">def</span> <span class="nf">minMaxScaler</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
  <span class="k">if</span><span class="p">(</span><span class="nb">max</span><span class="o">!=</span><span class="mi">0</span><span class="p">):</span>  <span class="c1"># avoid /0</span>
    <span class="nb">min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="p">(</span><span class="n">arr</span><span class="o">-</span><span class="nb">min</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>
  <span class="k">return</span> <span class="n">arr</span>

<span class="c1"># Reload data</span>
<span class="n">mnistData</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Scale data</span>
<span class="k">for</span> <span class="n">featureIdx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
  <span class="n">mnistData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="n">featureIdx</span><span class="p">]</span> <span class="o">=</span> <span class="n">minMaxScaler</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="n">featureIdx</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>You should follow best practice and prevent this bug from recurring by writing a unit test to check for not having <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values in your engineered data.</p>
</section>
</section>
<section id="remove-all-zero-features">
<h2><span class="section-number">39.64.6. </span>Remove All-Zero Features?<a class="headerlink" href="#remove-all-zero-features" title="Permalink to this headline">#</a></h2>
<p>You might think that getting NaNs and discovering that some features were all-zero is good luck because those features can be discarded. However, your training data and validation data might have different all-zero features. Since you should not use validation data to make modeling decisions, you cannot remove only those features that are all-zero in both. Furthermore, data in the future might have different characteristics. There are pros and cons in either case. This Colab keeps the features since reducing the feature set is not a concern.</p>
</section>
<section id="establish-baseline">
<h2><span class="section-number">39.64.7. </span>Establish Baseline<a class="headerlink" href="#establish-baseline" title="Permalink to this headline">#</a></h2>
<p>Following development best practices, you should establish a baseline. The simplest baseline is predicting the most common class. You saw that the most common class is 1. Let‚Äôs check the accuracy when always predicting 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mnistLabels</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mf">1.0</span><span class="o">/</span><span class="n">mnistLabels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span>
</pre></div>
</div>
</div>
</div>
<p>Your baseline accuracy is about 11%. Should be easy to beat, right?</p>
</section>
<section id="train-a-linear-model">
<h2><span class="section-number">39.64.8. </span>Train a Linear Model<a class="headerlink" href="#train-a-linear-model" title="Permalink to this headline">#</a></h2>
<p>Let‚Äôs start nice and easy with a linear model. All we need is an accuracy &gt; 11%.</p>
<p>First, let‚Äôs define a function to plot our loss and accuracy curves. The function will also print the final loss and accuracy. Instead of using <code class="docutils literal notranslate"><span class="pre">verbose=1</span></code>, you can call the function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Function to:</span>
<span class="sd">   * Print final loss &amp; accuracy.</span>
<span class="sd">   * Plot loss &amp; accuracy curves.</span>

<span class="sd">  Args:</span>
<span class="sd">    trainHistory: object returned by model.fit</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># Print final loss and accuracy</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final training loss: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final validation loss: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final training accuracy: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final validation accuracy: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

  <span class="c1"># Plot loss and accuracy curves</span>
  <span class="n">f</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
  <span class="n">axLoss</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
  <span class="n">axAcc</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
  <span class="n">axLoss</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
  <span class="n">axLoss</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
  <span class="n">axLoss</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation loss&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
  <span class="n">axLoss</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training epochs&#39;</span><span class="p">)</span>
  <span class="n">axLoss</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
  <span class="n">axAcc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">])</span>
  <span class="n">axAcc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">])</span>
  <span class="n">axAcc</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation accuracy&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
  <span class="n">axAcc</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training epochs&#39;</span><span class="p">)</span>
  <span class="n">axAcc</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now train a linear model with an output layer and a hidden layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                             <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
                             <span class="n">input_dim</span><span class="o">=</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span> <span class="n">mnistLabels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                         <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Wow, that accuracy is terrible! What could the cause be?</p>
<p>Hint: You followed the same procedure as for the previous regression problem. Do you need an adaptation for a classification problem? Experiment with the code above or skip to the solution below.</p>
<section id="id1">
<h3><span class="section-number">39.64.8.1. </span>Solution<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>In regression, the last layer uses a linear activation function. In classification, the last layer cannot use a linear transform. Instead, one option is a softmax transform. Furthermore, in regression, the loss is calculated using MSE while in classification, loss is calculated using crossentropy. Before running your model, if you wrote a test to validate the output values, your test would detect the anomalous output. You‚Äôll look at such a test later. Move onto the next section to fix the loss calculation.</p>
</section>
</section>
<section id="fixing-loss-calculation">
<h2><span class="section-number">39.64.9. </span>Fixing Loss Calculation<a class="headerlink" href="#fixing-loss-calculation" title="Permalink to this headline">#</a></h2>
<p>Since your labels are integers instead of one-hot encodings, use <code class="docutils literal notranslate"><span class="pre">sparse_categorical_crossentropy</span></code> instead of <code class="docutils literal notranslate"><span class="pre">categorical_crossentropy</span></code> so that you avoid converting the integers to one-hot encoding.</p>
<p>Retrain the model with the new loss calculation by running the following cell. Look through the code to note the changes. What do you think of the result?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
                             <span class="n">input_dim</span> <span class="o">=</span> <span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span> <span class="n">mnistLabels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                         <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Your loss curves are much better. Your accuracy has improved too. You‚Äôre on the right track.</p>
</section>
<section id="train-a-nonlinear-model">
<h2><span class="section-number">39.64.10. </span>Train a Nonlinear Model<a class="headerlink" href="#train-a-nonlinear-model" title="Permalink to this headline">#</a></h2>
<p>Switch to a nonlinear model by modifying the code below to use relu activation functions instead of linear activation functions. Run the code. What do you observe?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="c1"># use &#39;relu&#39;</span>
                             <span class="n">input_dim</span><span class="o">=</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span> <span class="n">mnistLabels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The quality of the nonlinear model is significantly better than of the linear model. Progress! Move onto the next section.</p>
</section>
<section id="adding-a-second-layer">
<h2><span class="section-number">39.64.11. </span>Adding a Second Layer<a class="headerlink" href="#adding-a-second-layer" title="Permalink to this headline">#</a></h2>
<p>Increasing the model‚Äôs capacity significantly improved your results. Perhaps you can continue this strategy by adding a second relu layer. Run the following code cell to train the model with another relu layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
                             <span class="n">input_dim</span> <span class="o">=</span> <span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span> <span class="n">mnistLabels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Guess what. Your previous model had training and validation accuracies of 100% and 95%. You can‚Äôt do much better than that! So your new accuracy is about the same. How high can you push your accuracy? With this configuration the highest training and validation accuracies appear to be 100% and 96% respectively. Since the neural net returns similar accuracy with 1 or 2 layers, let‚Äôs use the simpler model with 1 layer.</p>
<p>Does your model begin to overfit the training data if you train for long enough? (Your model starts overfitting training data at the point when your validation loss starts increasing.)</p>
</section>
<section id="check-for-training-validation-data-skew">
<h2><span class="section-number">39.64.12. </span>Check for Training/Validation Data Skew<a class="headerlink" href="#check-for-training-validation-data-skew" title="Permalink to this headline">#</a></h2>
<p>Our validation accuracy is a little worse than our training accuracy. While this result is always expected, you should check for typical errors. The commonest cause is having different distributions of data and labels in training and validation. Confirm that the distribution of classes in training and validation data is similar.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">hide_result</span> # hides result of cell computation

<span class="n">f</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)</span><span class="o">*</span><span class="mi">8</span><span class="o">/</span><span class="mi">10</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)</span><span class="o">*</span><span class="mi">8</span><span class="o">/</span><span class="mi">10</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="apply-dropout-regularization">
<h2><span class="section-number">39.64.13. </span>Apply Dropout Regularization<a class="headerlink" href="#apply-dropout-regularization" title="Permalink to this headline">#</a></h2>
<p>Dropout regularization is a common regularization method that removes a random selection of a fixed number of units in a network layer for a single gradient step. Typically, dropout will improve generalization at a dropout rate of between 10% and 50% of neurons.</p>
<p>Try to reduce the divergence between training and validation loss by using dropout regularization with values between 0.1 and 0.5. Dropout does not improve the results in this case. However, at a dropout of 0.5, the difference in loss decreases, though both training and validation loss decrease in absolute terms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">regularizers</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define lambda</span>
<span class="n">dropoutLambda</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1">#@param</span>
<span class="c1"># Define model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                             <span class="n">input_dim</span><span class="o">=</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                             <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropoutLambda</span><span class="p">,</span>
                               <span class="n">noise_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s2">&quot;adam&quot;</span><span class="p">,</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span>
                        <span class="n">mnistLabels</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Sample results using dropout regularization after 30 epochs:</p>
<p>Lambda | Training Loss | Validation Loss
‚Äî‚Äî- | ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
0.1 | 0.99 | 0.95
0.2 | 0.99 | 0.95
0.3 | 0.99 | 0.95
0.5 | 0.97 | 0.94</p>
</section>
<section id="check-accuracy-for-data-slices">
<h2><span class="section-number">39.64.14. </span>Check Accuracy for Data Slices<a class="headerlink" href="#check-accuracy-for-data-slices" title="Permalink to this headline">#</a></h2>
<p>For classification problems, you should always check the metrics by class to ensure your model predicts well across all classes. Check accuracy on the 10 classes by running the next cell by using the function <code class="docutils literal notranslate"><span class="pre">sklearn.metrics.classification_report</span></code> from the scikit-learn library. In the output, the rows with indices 0 to 9 correspond to the classes for the labels 0 to 9. The columns ‚ÄúPrecision‚Äù, ‚ÄúRecall‚Äù, and ‚Äú<a class="reference external" href="https://en.wikipedia.org/wiki/F1_score">F1-Score</a>‚Äù correspond to the respective classification metrics for each class. ‚ÄúSupport‚Äù is the number of examples for the class in question. For example, for the label ‚Äú4‚Äù, when predicting on 464 examples labelled ‚Äú4‚Äù, the model has a precision of 0.98, a recall of 0.97, and a F1 score of 0.98.</p>
<p>The classification metrics are very uniform across all classes, which is perfect. In your classification problem, in case any metric is lower for a class, then you should investigate why the model has lower-quality predictions for that class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="n">mnistPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">mnistData</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">,</span> <span class="n">mnistPred</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="testing-for-anomalous-values">
<h2><span class="section-number">39.64.15. </span>Testing for Anomalous Values<a class="headerlink" href="#testing-for-anomalous-values" title="Permalink to this headline">#</a></h2>
<p>In the section <a class="reference external" href="https://colab.corp.google.com/google_src/cloud/karangill/mlcc/google3/engedu/ml/capitalg/colab/testing_debugging_classification.ipynb#scrollTo=B6AOgLcC5nwp">Train a Linear Model</a>, you debugged an incorrect calculation of loss. Before running your model, if you wrote a test to validate the output values, your test would detect the anomalous output. For example, you could test whether the distribution of predicted labels on the training dataset is similar to the actual distribution of training labels. A simple statistical implementation of this concept is to compare the standard deviation and mean of the predicted and actual labels.</p>
<p>First, check the standard deviation and mean of the actual labels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean of actual labels: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Standard deviation of actual labels: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>Write tests to check if the mean and standard deviation of the predicted labels falls within the expected range. The expected range defined in the tests below is somewhat arbitrary. In practice, you will tune the range thresholds to accommodate natural variation in predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">mlTest</span><span class="p">(</span><span class="n">unittest</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span> 
<span class="w">  </span><span class="sd">&#39;&#39;&#39;Class to test statistics of predicted output on training data against</span>
<span class="sd">     statistics of labels to validate that model predictions are in the]</span>
<span class="sd">     expected range.</span>
<span class="sd">  &#39;&#39;&#39;</span>
     
  <span class="k">def</span> <span class="nf">testStd</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mnistData</span><span class="p">)</span>
    <span class="n">yStd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">yStdActual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)</span>
    <span class="n">deltaStd</span> <span class="o">=</span> <span class="mf">0.05</span>
    <span class="n">errorMsg</span> <span class="o">=</span> <span class="s1">&#39;Std. dev. of predicted values &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">yStd</span><span class="p">)</span> <span class="o">+</span> \
               <span class="s1">&#39; and actual values &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">yStdActual</span><span class="p">)</span> <span class="o">+</span> \
               <span class="s1">&#39; differs by &gt;&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">deltaStd</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAlmostEqual</span><span class="p">(</span><span class="n">yStd</span><span class="p">,</span> <span class="n">yStdActual</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="n">deltaStd</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="n">errorMsg</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">testMean</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mnistData</span><span class="p">)</span>
    <span class="n">yMean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">yMeanActual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)</span>
    <span class="n">deltaMean</span> <span class="o">=</span> <span class="mf">0.05</span>
    <span class="n">errorMsg</span> <span class="o">=</span> <span class="s1">&#39;Mean of predicted values &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">yMean</span><span class="p">)</span> <span class="o">+</span> \
               <span class="s1">&#39; and actual values &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">yMeanActual</span><span class="p">)</span> <span class="o">+</span> \
               <span class="s1">&#39; differs by &gt;&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">deltaMean</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAlmostEqual</span><span class="p">(</span><span class="n">yMean</span><span class="p">,</span> <span class="n">yMeanActual</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="n">deltaMean</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="n">errorMsg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Run the following cell to train a model with the wrong loss calculation and execute the tests. The tests should fail.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Train model and run tests</span>

<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                             <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
                             <span class="n">input_dim</span><span class="o">=</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span> <span class="n">mnistLabels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                         <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">suite</span> <span class="o">=</span> <span class="n">unittest</span><span class="o">.</span><span class="n">TestLoader</span><span class="p">()</span><span class="o">.</span><span class="n">loadTestsFromTestCase</span><span class="p">(</span><span class="n">mlTest</span><span class="p">)</span>
<span class="n">unittest</span><span class="o">.</span><span class="n">TextTestRunner</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">suite</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Since the tests fail, check the data distribution of predicted labels for anomalies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mnistData</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">yPred</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">11</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Given equally represented classes, the predicted labels are clearly skewed. From this plot, a possible explanation is that your loss calculation does not appear to be weighting all classes equally. This anomaly is a hint that your loss calculation is incorrect.</p>
</section>
<section id="optional-pass-tests-by-fixing-loss-calculation">
<h2><span class="section-number">39.64.16. </span>Optional: Pass Tests by Fixing Loss Calculation<a class="headerlink" href="#optional-pass-tests-by-fixing-loss-calculation" title="Permalink to this headline">#</a></h2>
<p>As an optional exercise, you can attempt to pass the tests by fixing the loss calculation. You will need to:</p>
<ol class="simple">
<li><p>Fix the loss calculation by setting the output layer‚Äôs activation to <code class="docutils literal notranslate"><span class="pre">softmax</span></code>.</p></li>
<li><p>Set the model‚Äôs loss to <code class="docutils literal notranslate"><span class="pre">sparse_categorical_crossentropy</span></code>.</p></li>
<li><p>Set the number of units in the output layer to 10 corresponding to the 10 classes.</p></li>
<li><p>Adapt the tests to the modified output layer.</p></li>
</ol>
</section>
<section id="conclusion">
<h2><span class="section-number">39.64.17. </span>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">#</a></h2>
<p>The Colab demonstrated the following principles:</p>
<ul class="simple">
<li><p>Calculate loss correctly for your problem.</p></li>
<li><p>Verify and unit test your engineered data.</p></li>
<li><p>Find the right model capacity through experimentation.</p></li>
<li><p>Find the best regularization through experimentation.</p></li>
<li><p>Check quality on data slices.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "open-academy/machine-learning",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./assignments/machine-learning-productionization"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="counterintuitive-challenges-in-ml-debugging.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">39.63. </span>Counterintuitive Challenges in ML Debugging</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="debugging-in-regression.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">39.65. </span>Case Study: Debugging in Regression</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ocademy<br/>
  
      &copy; Copyright 2022-2022.<br/>
    <div class="extra_footer">
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> Text content of this work is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>