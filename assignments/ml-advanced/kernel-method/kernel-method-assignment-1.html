
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>40.59. Kernel method assignment 1 &#8212; An interactive and visual Machine Learning book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/drawio.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/youtube.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "ocademy-ai/machine-learning-utterances");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "üí¨ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"></script>
    <script>quizdown.init({"quizdown_js": "https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"});</script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="40.60. Support Vector Machines (SVM) - Intro and SVM for Regression" href="support_vector_machines_for_regression.html" />
    <link rel="prev" title="40.58. Explore classification methods" href="../../ml-fundamentals/explore-classification-methods.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint">Learn AI together, for free! At <a color='lightblue' href='https://ocademy.cc'><u style='color:lightblue;'>Ocademy</u></a>.</div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo-long.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">An interactive and visual Machine Learning book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PREREQUISITES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-introduction.html">
   1. Python programming introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-basics.html">
   2. Python programming basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-advanced.html">
   3. Python programming advanced
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATA SCIENCE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/introduction/introduction.html">
   4. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/defining-data-science.html">
     4.1. Defining data science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/data-science-ethics.html">
     4.2. Data Science ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/defining-data.html">
     4.3. Defining data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/introduction-to-statistics-and-probability.html">
     4.4. Introduction to statistics and probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/working-with-data/working-with-data.html">
   5. Working with data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/relational-databases.html">
     5.1. Relational databases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/non-relational-data.html">
     5.2. Non-relational data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/numpy.html">
     5.3. NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/pandas.html">
     5.4. Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/data-preparation.html">
     5.5. Data preparation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-visualization/data-visualization.html">
   6. Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-distributions.html">
     6.1. Visualizing distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-proportions.html">
     6.2. Visualizing proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-relationships.html">
     6.3. Visualizing relationships: all about honey üçØ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/meaningful-visualizations.html">
     6.4. Making meaningful visualizations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-science-lifecycle/data-science-lifecycle.html">
   7. Data Science lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/introduction.html">
     7.1. Introduction to the Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/analyzing.html">
     7.2. Analyzing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/communication.html">
     7.3. Communication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/data-science-in-the-cloud.html">
   8. Data Science in the cloud
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/introduction.html">
     8.1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/the-low-code-no-code-way.html">
     8.2. The ‚Äúlow code/no code‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/the-azure-ml-sdk-way.html">
     8.3. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../data-science/data-science-in-the-wild.html">
   9. Data Science in the real world
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING BASICS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-fundamentals/ml-overview.html">
   10. Machine Learning overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/regression/regression-models-for-machine-learning.html">
   11. Regression models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/tools-of-the-trade.html">
     11.1. Tools of the trade
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/managing-data.html">
     11.2. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/linear-and-polynomial-regression.html">
     11.3. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/logistic-regression.html">
     11.4. Logistic regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-fundamentals/build-a-web-app-to-use-a-machine-learning-model.html">
   12. Build a web app to use a Machine Learning model
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/classification/getting-started-with-classification.html">
   13. Getting started with classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/introduction-to-classification.html">
     13.1. Introduction to classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/more-classifiers.html">
     13.2. More classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/yet-other-classifiers.html">
     13.3. Yet other classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/applied-ml-build-a-web-app.html">
     13.4. Applied Machine Learning : build a web app
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ADVANCED MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/clustering/clustering-models-for-machine-learning.html">
   14. Clustering models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/clustering/introduction-to-clustering.html">
     14.1. Introduction to clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/clustering/k-means-clustering.html">
     14.2. K-Means clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/ensemble-learning/getting-started-with-ensemble-learning.html">
   15. Getting started with ensemble learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/bagging.html">
     15.1. Bagging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/random-forest.html">
     15.2. Random forest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/feature-importance.html">
     15.3. Feature importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/gradient-boosting/introduction-to-gradient-boosting.html">
   16. Introduction to Gradient Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/gradient-boosting.html">
     16.1. Gradient Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/gradient-boosting-example.html">
     16.2. Gradient boosting example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/xgboost.html">
     16.3. XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/xgboost-k-fold-cv-feature-importance.html">
     16.4. XGBoost + k-fold CV + Feature Importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/unsupervised-learning.html">
   17. Unsupervised learning (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/kernel-method.html">
   18. Kernel method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/model-selection.html">
   19. Model selection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dl-overview.html">
   20. Deep learning overview (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/cnn.html">
   21. Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/gan.html">
   22. Generative adversarial networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/rnn.html">
   23. Recurrent Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/autoencoder.html">
   24. Autoencoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/lstm.html">
   25. Long-short term memory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/time-series.html">
   26. Time series
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dqn.html">
   27. Deep Q-learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dl-summary.html">
   28. Summary of deep learning (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/image-classification.html">
   29. Image classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/image-segmentation.html">
   30. Image segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/difussion-model.html">
   31. Diffusion Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/object-detection.html">
   32. Object detection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING OPERATIONS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/overview.html">
   33. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/problem-framing.html">
   34. Problem framing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/data-engineering.html">
   35. Data engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/model-training-and-evaluation.html">
   36. Model training &amp; evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/model-deployment.html">
   37. Model deployment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  SUPPORTING MATERIALS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../supporting-materials/unbalanced-problems.html">
   38. Unbalanced problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../supporting-materials/automl.html">
   39. AutoML (TBD)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OTHERS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../README.html">
   40. Self-paced assignments
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../../set-up-env/first-assignment.html">
     40.3. First assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../set-up-env/second-assignment.html">
     40.4. Second assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../project-plan-template.html">
     40.5. Project Plan‚Äã Template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-introduction.html">
     40.6. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-basics.html">
     40.7. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-advanced.html">
     40.8. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-text-about-data-science.html">
     40.9. Analyzing text about Data Science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-scenarios.html">
     40.10. Data Science scenarios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/write-a-data-ethics-case-study.html">
     40.11. Write a data ethics case study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/lines-scatters-and-bars.html">
     40.12. Lines, scatters and bars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/apply-your-skills.html">
     40.13. Apply your skills
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/try-it-in-excel.html">
     40.14. Try it in Excel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/dive-into-the-beehive.html">
     40.15. Dive into the beehive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/build-your-own-custom-vis.html">
     40.16. Build your own custom vis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/classifying-datasets.html">
     40.17. Classifying datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/small-diabetes-study.html">
     40.18. Small diabetes study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction-to-statistics-and-probability.html">
     40.19. Introduction to probability and statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/displaying-airport-data.html">
     40.20. Displaying airport data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/soda-profits.html">
     40.21. Soda profits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-COVID-19-papers.html">
     40.22. Analyzing COVID-19 papers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/estimation-of-COVID-19-pandemic.html">
     40.23. Estimation of COVID-19 pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-processing-in-python.html">
     40.24. Data processing in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/evaluating-data-from-a-form.html">
     40.25. Evaluating data from a form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-preparation.html">
     40.26. Data preparation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-data.html">
     40.27. Analyzing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/nyc-taxi-data-in-winter-and-summer.html">
     40.28. NYC taxi data in winter and summer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/matplotlib-applied.html">
     40.29. Matplotlib applied
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/tell-a-story.html">
     40.35. Tell a story
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/explore-a-planetary-computer-dataset.html">
     40.36. Explore a planetary computer dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/exploring-for-anwser.html">
     40.37. Exploring for answers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/market-research.html">
     40.38. Market research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/low-code-no-code-data-science-project-on-azure-ml.html">
     40.39. Low code/no code Data Science project on Azure ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-project-using-azure-ml-sdk.html">
     40.40. Data Science project using Azure ML SDK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-in-the-cloud-the-azure-ml-sdk-way.html">
     40.41. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-overview-iris.html">
     40.42. Machine Learning overview - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-overview-mnist-digits.html">
     40.43. Machine Learning overview - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression-with-scikit-learn.html">
     40.44. Regression with Scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-linear-regression-1.html">
     40.45. ML linear regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-linear-regression-2.html">
     40.46. ML linear regression - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-logistic-regression-1.html">
     40.47. ML logistic regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-neural-network-1.html">
     40.48. ML neural network - Assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression-tools.html">
     40.49. Regression tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/managing-data.html">
     40.50. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/exploring-visualizations.html">
     40.51. Exploring visualizations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/try-a-different-model.html">
     40.52. Try a different model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/create-a-regression-model.html">
     40.53. Create a regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/linear-and-polynomial-regression.html">
     40.54. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/retrying-some-regression.html">
     40.55. Retrying some regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/pumpkin-varieties-and-color.html">
     40.56. Pumpkin varieties and color
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/delicious-asian-and-indian-cuisines.html">
     40.57. Delicious asian and indian cuisines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/explore-classification-methods.html">
     40.58. Explore classification methods
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     40.59. Kernel method assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="support_vector_machines_for_regression.html">
     40.60. Support Vector Machines (SVM) - Intro and SVM for Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="support_vector_machines_for_classification.html">
     40.61. Support Vector Machines (SVM) - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decision_trees_for_regression.html">
     40.62. Decision Trees - Intro and Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decision_trees_for_classification.html">
     40.63. Decision Trees - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../model-selection/model-selection-assignment-1.html">
     40.64. Model selection assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../model-selection/learning-curve-to-identify-overfit-underfit.html">
     40.65. Learning Curve To Identify Overfit &amp; Underfit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../model-selection/dropout-and-batch-normalization.html">
     40.66. Dropout and Batch Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../model-selection/lasso-and-ridge-regression.html">
     40.67. Lasso and Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../model-selection/regularized-linear-models.html">
     40.68. Regularized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ensemble-learning/random-forests-intro-and-regression.html">
     40.69. Random forests intro and regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ensemble-learning/random-forests-for-classification.html">
     40.70. Random forests for classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ensemble-learning/beyond-random-forests-more-ensemble-models.html">
     40.71. Beyond random forests: more ensemble models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ensemble-learning/decision-trees.html">
     40.72. Decision trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../gradient-boosting/hyperparameter-tuning-gradient-boosting.html">
     40.73. Hyperparameter tuning gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/data-engineering.html">
     40.74. Data engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/counterintuitive-challenges-in-ml-debugging.html">
     40.75. Counterintuitive Challenges in ML Debugging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/debugging-in-classification.html">
     40.76. Case Study: Debugging in Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/debugging-in-regression.html">
     40.77. Case Study: Debugging in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/study-the-solvers.html">
     40.78. Study the solvers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/build-classification-models.html">
     40.79. Build classification models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/build-classification-model.html">
     40.80. Build Classification Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/parameter-play.html">
     40.81. Parameter play
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/how-to-choose-cnn-architecture-mnist.html">
     40.82. How to choose cnn architecture mnist
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/sign-language-digits-classification-with-cnn.html">
     40.84. Sign Language Digits Classification with CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/object-recognition-in-images-using-cnn.html">
     40.86. Object Recognition in Images using CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/tensorflow/intro_to_tensorflow_for_deeplearning.html">
     40.87. Intro to TensorFlow for Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/lstm/bitcoin-lstm-model-with-tweet-volume-and-sentiment.html">
     40.89. Bitcoin LSTM Model with Tweet Volume and Sentiment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/rnn/google-stock-price-prediction-rnn.html">
     40.91. Google Stock Price Prediction RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/autoencoder.html">
     40.93. Intro to Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/base-denoising-autoencoder-dimension-reduction.html">
     40.94. Base/Denoising Autoencoder &amp; Dimension Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/variational-autoencoder-and-faces-generation.html">
     40.95. Fun with Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/time-series-forecasting-assignment.html">
     40.96. Time Series Forecasting Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nn-for-classification-assignment.html">
     40.98. Neural Networks for Classification with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nn-classify-15-fruits-assignment.html">
     40.99. NN Classify 15 Fruits Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/dqn/dqn-on-foreign-exchange-market.html">
     40.104. DQN On Foreign Exchange Market
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/gan/art-by-gan.html">
     40.105. Art by gan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/gan/gan-introduction.html">
     40.107. Generative Adversarial Networks (GANs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/overview/basic-classification-classify-images-of-clothing.html">
     40.108. Basic classification: Classify images of clothing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../slides/introduction.html">
   41. Slides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-introduction.html">
     41.1. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-basics.html">
     41.2. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-advanced.html">
     41.3. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-introduction.html">
     41.4. Data Science introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/relational-vs-non-relational-database.html">
     41.5. Relational vs. non-relational database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/numpy-and-pandas.html">
     41.6. NumPy and Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-visualization.html">
     41.7. Data visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-lifecycle.html">
     41.8. Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-in-the-cloud.html">
     41.9. Data Science in the cloud
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-in-real-world.html">
     41.10. Data Science in real world
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/ml-overview.html">
     41.11. Machine Learning overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/linear-regression.html">
     41.12. Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/logistic-regression.html">
     41.13. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/neural-network.html">
     41.14. Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/build-an-ml-web-app.html">
     41.15. Build an machine learning web application
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/unsupervised-learning.html">
     41.16. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/kernel-method.html">
     41.17. Kernel method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/model-selection.html">
     41.18. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/deep-learning/cnn.html">
     41.19. Convolutional Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/deep-learning/gan.html">
     41.20. Generative Adversarial Network
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ocademy-ai/machine-learning/release?urlpath=lab/tree/open-machine-learning-jupyter-book/assignments/ml-advanced/kernel-method/kernel-method-assignment-1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ocademy-ai/machine-learning/blob/release/open-machine-learning-jupyter-book/assignments/ml-advanced/kernel-method/kernel-method-assignment-1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning//issues/new?title=Issue%20on%20page%20%2Fassignments/ml-advanced/kernel-method/kernel-method-assignment-1.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/edit/release/open-machine-learning-jupyter-book/assignments/ml-advanced/kernel-method/kernel-method-assignment-1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/assignments/ml-advanced/kernel-method/kernel-method-assignment-1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-to-support-vector-machines">
   40.59.1. Introduction to Support Vector Machines
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#support-vector-machines-intuition">
   40.59.2. Support Vector Machines intuition
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperplane">
     40.59.2.1. Hyperplane
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-vectors">
     40.59.2.2. Support Vectors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#margin">
     40.59.2.3. Margin
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#margin-in-svm">
     40.59.2.4. Margin in SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#svm-under-the-hood">
     40.59.2.5. SVM Under the hood
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-margin-hyperplane">
     40.59.2.6. Maximum margin hyperplane
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problem-with-dispersed-datasets">
     40.59.2.7. Problem with dispersed datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kernel-trick-transformation-of-input-space-to-higher-dimensional-space">
     40.59.2.8. Kernel trick - transformation of input space to higher dimensional space
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kernel-trick">
   40.59.3. Kernel trick
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kernel-function">
     40.59.3.1. Kernel function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-kernel">
     40.59.3.2. Linear kernel
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       40.59.3.2.1. Linear Kernel
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#polynomial-kernel">
   40.59.4. Polynomial Kernel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     40.59.4.1. Polynomial Kernel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#radial-basis-function-kernel">
     40.59.4.2. Radial Basis Function Kernel
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       40.59.4.2.1. Radial Basis Function kernel
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#svm-classification-with-rbf-kernel">
       40.59.4.2.2. SVM Classification with rbf kernel
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm-scikit-learn-libraries">
   40.59.5. SVM Scikit-Learn libraries
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-description">
   40.59.6. Dataset description
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attribute-information">
     40.59.6.1. Attribute Information:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-libraries">
   40.59.7. Import libraries
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-dataset">
   40.59.8. Import dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exploratory-data-analysis">
   40.59.9. Exploratory data analysis
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-missing-values-in-variables">
     40.59.9.1. Explore missing values in variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-of-numerical-variables">
     40.59.9.2. Summary of numerical variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#outliers-in-numerical-variables">
     40.59.9.3. Outliers in numerical variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#handle-outliers-with-svms">
     40.59.9.4. Handle outliers with SVMs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-the-distribution-of-variables">
     40.59.9.5. Check the distribution of variables
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#declare-feature-vector-and-target-variable">
   40.59.10. Declare feature vector and target variable
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-data-into-separate-training-and-test-set">
   40.59.11. Split data into separate training and test set
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-scaling">
   40.59.12. Feature Scaling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-svm-with-default-hyperparameters">
   40.59.13. Run SVM with default hyperparameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-rbf-kernel-and-c-100-0">
     40.59.13.1. Run SVM with rbf kernel and C=100.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-rbf-kernel-and-c-1000-0">
     40.59.13.2. Run SVM with rbf kernel and C=1000.0
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-svm-with-linear-kernel">
   40.59.14. Run SVM with linear kernel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-linear-kernel-and-c-1-0">
     40.59.14.1. Run SVM with linear kernel and C=1.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-linear-kernel-and-c-100-0">
     40.59.14.2. Run SVM with linear kernel and C=100.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-linear-kernel-and-c-1000-0">
     40.59.14.3. Run SVM with linear kernel and C=1000.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compare-the-train-set-and-test-set-accuracy">
     40.59.14.4. Compare the train-set and test-set accuracy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-for-overfitting-and-underfitting">
     40.59.14.5. Check for overfitting and underfitting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compare-model-accuracy-with-null-accuracy">
     40.59.14.6. Compare model accuracy with null accuracy
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-svm-with-polynomial-kernel">
   40.59.15. Run SVM with polynomial kernel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-polynomial-kernel-and-c-1-0">
     40.59.15.1. Run SVM with polynomial kernel and C=1.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-polynomial-kernel-and-c-100-0">
     40.59.15.2. Run SVM with polynomial kernel and C=100.0
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-svm-with-sigmoid-kernel">
   40.59.16. Run SVM with sigmoid kernel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-sigmoid-kernel-and-c-1-0">
     40.59.16.1. Run SVM with sigmoid kernel and C=1.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-sigmoid-kernel-and-c-100-0">
     40.59.16.2. Run SVM with sigmoid kernel and C=100.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comments">
     40.59.16.3. Comments
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confusion-matrix">
   40.59.17. Confusion matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-metrices">
   40.59.18. Classification metrices
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-report">
     40.59.18.1. Classification Report
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-accuracy">
     40.59.18.2. Classification accuracy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-error">
     40.59.18.3. Classification error
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#precision">
     40.59.18.4. Precision
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recall">
     40.59.18.5. Recall
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#true-positive-rate">
     40.59.18.6. True Positive Rate
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#false-positive-rate">
     40.59.18.7. False Positive Rate
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specificity">
     40.59.18.8. Specificity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#f1-score">
     40.59.18.9. f1-score
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support">
     40.59.18.10. Support
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#roc-auc">
   40.59.19. ROC - AUC
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#roc-curve">
     40.59.19.1. ROC Curve
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     40.59.19.2. ROC  AUC
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     40.59.19.3. Comments
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stratified-k-fold-cross-validation-with-shuffle-split">
   40.59.20. Stratified k-fold Cross Validation with shuffle split
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stratified-k-fold-cross-validation-with-shuffle-split-with-linear-kernel">
     40.59.20.1. Stratified k-Fold Cross Validation with shuffle split with  linear kernel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stratified-k-fold-cross-validation-with-shuffle-split-with-rbf-kernel">
     40.59.20.2. Stratified k-Fold Cross Validation with shuffle split with rbf kernel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     40.59.20.3. Comments
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-optimization-using-gridsearch-cv">
   40.59.21. Hyperparameter Optimization using GridSearch CV
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     40.59.21.1. Comments
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#results-and-conclusion">
   40.59.22. Results and conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   40.59.23. Acknowledgments
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Kernel method assignment 1</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-to-support-vector-machines">
   40.59.1. Introduction to Support Vector Machines
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#support-vector-machines-intuition">
   40.59.2. Support Vector Machines intuition
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperplane">
     40.59.2.1. Hyperplane
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-vectors">
     40.59.2.2. Support Vectors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#margin">
     40.59.2.3. Margin
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#margin-in-svm">
     40.59.2.4. Margin in SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#svm-under-the-hood">
     40.59.2.5. SVM Under the hood
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-margin-hyperplane">
     40.59.2.6. Maximum margin hyperplane
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problem-with-dispersed-datasets">
     40.59.2.7. Problem with dispersed datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kernel-trick-transformation-of-input-space-to-higher-dimensional-space">
     40.59.2.8. Kernel trick - transformation of input space to higher dimensional space
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kernel-trick">
   40.59.3. Kernel trick
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kernel-function">
     40.59.3.1. Kernel function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-kernel">
     40.59.3.2. Linear kernel
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       40.59.3.2.1. Linear Kernel
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#polynomial-kernel">
   40.59.4. Polynomial Kernel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     40.59.4.1. Polynomial Kernel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#radial-basis-function-kernel">
     40.59.4.2. Radial Basis Function Kernel
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       40.59.4.2.1. Radial Basis Function kernel
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#svm-classification-with-rbf-kernel">
       40.59.4.2.2. SVM Classification with rbf kernel
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm-scikit-learn-libraries">
   40.59.5. SVM Scikit-Learn libraries
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-description">
   40.59.6. Dataset description
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attribute-information">
     40.59.6.1. Attribute Information:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-libraries">
   40.59.7. Import libraries
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-dataset">
   40.59.8. Import dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exploratory-data-analysis">
   40.59.9. Exploratory data analysis
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-missing-values-in-variables">
     40.59.9.1. Explore missing values in variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-of-numerical-variables">
     40.59.9.2. Summary of numerical variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#outliers-in-numerical-variables">
     40.59.9.3. Outliers in numerical variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#handle-outliers-with-svms">
     40.59.9.4. Handle outliers with SVMs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-the-distribution-of-variables">
     40.59.9.5. Check the distribution of variables
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#declare-feature-vector-and-target-variable">
   40.59.10. Declare feature vector and target variable
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-data-into-separate-training-and-test-set">
   40.59.11. Split data into separate training and test set
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-scaling">
   40.59.12. Feature Scaling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-svm-with-default-hyperparameters">
   40.59.13. Run SVM with default hyperparameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-rbf-kernel-and-c-100-0">
     40.59.13.1. Run SVM with rbf kernel and C=100.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-rbf-kernel-and-c-1000-0">
     40.59.13.2. Run SVM with rbf kernel and C=1000.0
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-svm-with-linear-kernel">
   40.59.14. Run SVM with linear kernel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-linear-kernel-and-c-1-0">
     40.59.14.1. Run SVM with linear kernel and C=1.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-linear-kernel-and-c-100-0">
     40.59.14.2. Run SVM with linear kernel and C=100.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-linear-kernel-and-c-1000-0">
     40.59.14.3. Run SVM with linear kernel and C=1000.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compare-the-train-set-and-test-set-accuracy">
     40.59.14.4. Compare the train-set and test-set accuracy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-for-overfitting-and-underfitting">
     40.59.14.5. Check for overfitting and underfitting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compare-model-accuracy-with-null-accuracy">
     40.59.14.6. Compare model accuracy with null accuracy
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-svm-with-polynomial-kernel">
   40.59.15. Run SVM with polynomial kernel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-polynomial-kernel-and-c-1-0">
     40.59.15.1. Run SVM with polynomial kernel and C=1.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-polynomial-kernel-and-c-100-0">
     40.59.15.2. Run SVM with polynomial kernel and C=100.0
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-svm-with-sigmoid-kernel">
   40.59.16. Run SVM with sigmoid kernel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-sigmoid-kernel-and-c-1-0">
     40.59.16.1. Run SVM with sigmoid kernel and C=1.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-svm-with-sigmoid-kernel-and-c-100-0">
     40.59.16.2. Run SVM with sigmoid kernel and C=100.0
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comments">
     40.59.16.3. Comments
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confusion-matrix">
   40.59.17. Confusion matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-metrices">
   40.59.18. Classification metrices
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-report">
     40.59.18.1. Classification Report
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-accuracy">
     40.59.18.2. Classification accuracy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-error">
     40.59.18.3. Classification error
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#precision">
     40.59.18.4. Precision
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recall">
     40.59.18.5. Recall
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#true-positive-rate">
     40.59.18.6. True Positive Rate
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#false-positive-rate">
     40.59.18.7. False Positive Rate
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specificity">
     40.59.18.8. Specificity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#f1-score">
     40.59.18.9. f1-score
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support">
     40.59.18.10. Support
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#roc-auc">
   40.59.19. ROC - AUC
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#roc-curve">
     40.59.19.1. ROC Curve
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     40.59.19.2. ROC  AUC
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     40.59.19.3. Comments
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stratified-k-fold-cross-validation-with-shuffle-split">
   40.59.20. Stratified k-fold Cross Validation with shuffle split
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stratified-k-fold-cross-validation-with-shuffle-split-with-linear-kernel">
     40.59.20.1. Stratified k-Fold Cross Validation with shuffle split with  linear kernel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stratified-k-fold-cross-validation-with-shuffle-split-with-rbf-kernel">
     40.59.20.2. Stratified k-Fold Cross Validation with shuffle split with rbf kernel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     40.59.20.3. Comments
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameter-optimization-using-gridsearch-cv">
   40.59.21. Hyperparameter Optimization using GridSearch CV
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     40.59.21.1. Comments
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#results-and-conclusion">
   40.59.22. Results and conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   40.59.23. Acknowledgments
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="kernel-method-assignment-1">
<h1><span class="section-number">40.59. </span>Kernel method assignment 1<a class="headerlink" href="#kernel-method-assignment-1" title="Permalink to this headline">#</a></h1>
<p>Support Vector Machines (SVMs in short) are supervised machine learning algorithms that are used for classification and regression purposes. In this kernel, We build a Support Vector Machines classifier to classify a Pulsar star. We have used the <strong>Predicting a Pulsar Star</strong> dataset for this project.</p>
<section id="introduction-to-support-vector-machines">
<h2><span class="section-number">40.59.1. </span>Introduction to Support Vector Machines<a class="headerlink" href="#introduction-to-support-vector-machines" title="Permalink to this headline">#</a></h2>
<p><strong>Support Vector Machines</strong> (SVMs in short) are machine learning algorithms that are used for classification and regression purposes. SVMs are one of the powerful machine learning algorithms for classification, regression and outlier detection purposes. An SVM classifier builds a model that assigns new data points to one of the given categories. Thus, it can be viewed as a non-probabilistic binary linear classifier.</p>
<p>The original SVM algorithm was developed by Vladimir N Vapnik and Alexey Ya. Chervonenkis in 1963. At that time, the algorithm was in early stages. The only possibility is to draw hyperplanes for linear classifier. In 1992, Bernhard E. Boser, Isabelle M Guyon and Vladimir N Vapnik suggested a way to create non-linear classifiers by applying the kernel trick to maximum-margin hyperplanes. The current standard was proposed by Corinna Cortes and Vapnik in 1993 and published in 1995.</p>
<p>SVMs can be used for linear classification purposes. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using the <strong>kernel trick</strong>. It enable us to implicitly map the inputs into high dimensional feature spaces.</p>
</section>
<section id="support-vector-machines-intuition">
<h2><span class="section-number">40.59.2. </span>Support Vector Machines intuition<a class="headerlink" href="#support-vector-machines-intuition" title="Permalink to this headline">#</a></h2>
<p>Now, we should be familiar with some SVM terminology.</p>
<section id="hyperplane">
<h3><span class="section-number">40.59.2.1. </span>Hyperplane<a class="headerlink" href="#hyperplane" title="Permalink to this headline">#</a></h3>
<p>A hyperplane is a decision boundary which separates between given set of data points having different class labels. The SVM classifier separates data points using a hyperplane with the maximum amount of margin. This hyperplane is known as the <code class="docutils literal notranslate"><span class="pre">maximum</span> <span class="pre">margin</span> <span class="pre">hyperplane</span></code> and the linear classifier it defines is known as the <code class="docutils literal notranslate"><span class="pre">maximum</span> <span class="pre">margin</span> <span class="pre">classifier</span></code>.</p>
</section>
<section id="support-vectors">
<h3><span class="section-number">40.59.2.2. </span>Support Vectors<a class="headerlink" href="#support-vectors" title="Permalink to this headline">#</a></h3>
<p>Support vectors are the sample data points, which are closest to the hyperplane.  These data points will define the separating line or hyperplane better by calculating margins.</p>
</section>
<section id="margin">
<h3><span class="section-number">40.59.2.3. </span>Margin<a class="headerlink" href="#margin" title="Permalink to this headline">#</a></h3>
<p>A margin is a separation gap between the two lines on the closest data points. It is calculated as the perpendicular distance from the line to support vectors or closest data points. In SVMs, we try to maximize this separation gap so that we get maximum margin.</p>
<p>The following diagram illustrates these concepts visually.</p>
</section>
<section id="margin-in-svm">
<h3><span class="section-number">40.59.2.4. </span>Margin in SVM<a class="headerlink" href="#margin-in-svm" title="Permalink to this headline">#</a></h3>
<p><img alt="Margin in SVM" src="https://static.wixstatic.com/media/8f929f_7ecacdcf69d2450087cb4a898ef90837~mv2.png" /></p>
</section>
<section id="svm-under-the-hood">
<h3><span class="section-number">40.59.2.5. </span>SVM Under the hood<a class="headerlink" href="#svm-under-the-hood" title="Permalink to this headline">#</a></h3>
<p>In SVMs, our main objective is to select a hyperplane with the maximum possible margin between support vectors in the given dataset. SVM searches for the maximum margin hyperplane in the following 2 step process ‚Äì</p>
<ol class="simple">
<li><p>Generate hyperplanes which segregates the classes in the best possible way. There are many hyperplanes that might classify the data. We should look for the best hyperplane that represents the largest separation, or margin, between the two classes.</p></li>
<li><p>So, we choose the hyperplane so that distance from it to the support vectors on each side is maximized. If such a hyperplane exists, it is known as the <strong>maximum margin hyperplane</strong> and the linear classifier it defines is known as a <strong>maximum margin classifier</strong>.</p></li>
</ol>
<p>The following diagram illustrates the concept of <strong>maximum margin</strong> and <strong>maximum margin hyperplane</strong> in a clear manner.</p>
</section>
<section id="maximum-margin-hyperplane">
<h3><span class="section-number">40.59.2.6. </span>Maximum margin hyperplane<a class="headerlink" href="#maximum-margin-hyperplane" title="Permalink to this headline">#</a></h3>
<p><img alt="Maximum margin hyperplane" src="https://static.packt-cdn.com/products/9781783555130/graphics/3547_03_07.jpg" /></p>
</section>
<section id="problem-with-dispersed-datasets">
<h3><span class="section-number">40.59.2.7. </span>Problem with dispersed datasets<a class="headerlink" href="#problem-with-dispersed-datasets" title="Permalink to this headline">#</a></h3>
<p>Sometimes, the sample data points are so dispersed that it is not possible to separate them using a linear hyperplane.
In such a situation, SVMs uses a <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">trick</span></code> to transform the input space to a higher dimensional space as shown in the diagram below. It uses a mapping function to transform the 2-D input space into the 3-D input space. Now, we can easily segregate the data points using linear separation.</p>
</section>
<section id="kernel-trick-transformation-of-input-space-to-higher-dimensional-space">
<h3><span class="section-number">40.59.2.8. </span>Kernel trick - transformation of input space to higher dimensional space<a class="headerlink" href="#kernel-trick-transformation-of-input-space-to-higher-dimensional-space" title="Permalink to this headline">#</a></h3>
<p><img alt="Kernel trick" src="http://www.aionlinecourse.com/uploads/tutorials/2019/07/11_21_kernel_svm_3.png" /></p>
</section>
</section>
<section id="kernel-trick">
<h2><span class="section-number">40.59.3. </span>Kernel trick<a class="headerlink" href="#kernel-trick" title="Permalink to this headline">#</a></h2>
<p>In practice, SVM algorithm is implemented using a <code class="docutils literal notranslate"><span class="pre">kernel</span></code>. It uses a technique called the <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">trick</span></code>. In simple words, a <code class="docutils literal notranslate"><span class="pre">kernel</span></code> is just a function that maps the data to a higher dimension where data is separable. A kernel transforms a low-dimensional input data space into a higher dimensional space. So, it converts non-linear separable problems to linear separable problems by adding more dimensions to it. Thus, the kernel trick helps us to build a more accurate classifier. Hence, it is useful in non-linear separation problems.</p>
<p>We can define a kernel function as follows-</p>
<section id="kernel-function">
<h3><span class="section-number">40.59.3.1. </span>Kernel function<a class="headerlink" href="#kernel-function" title="Permalink to this headline">#</a></h3>
<p><img alt="Kernel function" src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTodZptqcRor0LGo8Qn7_kJB9n9BACMt6jgIPZ4C3g_rgh_uSRZLQ&amp;s" /></p>
<p>In the context of SVMs, there are 4 popular kernels ‚Äì <code class="docutils literal notranslate"><span class="pre">Linear</span> <span class="pre">kernel</span></code>,<code class="docutils literal notranslate"><span class="pre">Polynomial</span> <span class="pre">kernel</span></code>,<code class="docutils literal notranslate"><span class="pre">Radial</span> <span class="pre">Basis</span> <span class="pre">Function</span> <span class="pre">(RBF)</span> <span class="pre">kernel</span></code> (also called Gaussian kernel) and <code class="docutils literal notranslate"><span class="pre">Sigmoid</span> <span class="pre">kernel</span></code>. These are described below -</p>
</section>
<section id="linear-kernel">
<h3><span class="section-number">40.59.3.2. </span>Linear kernel<a class="headerlink" href="#linear-kernel" title="Permalink to this headline">#</a></h3>
<p>In linear kernel, the kernel function takes the form of a linear function as follows-</p>
<p><strong>linear kernel : K(xi , xj ) = xiT xj</strong></p>
<p>Linear kernel is used when the data is linearly separable. It means that data can be separated using a single line. It is one of the most common kernels to be used. It is mostly used when there are large number of features in a dataset. Linear kernel is often used for text classification purposes.</p>
<p>Training with a linear kernel is usually faster, because we only need to optimize the C regularization parameter. When training with other kernels, we also need to optimize the Œ≥ parameter. So, performing a grid search will usually take more time.</p>
<p>Linear kernel can be visualized with the following figure.</p>
<section id="id1">
<h4><span class="section-number">40.59.3.2.1. </span>Linear Kernel<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h4>
<p><img alt="Linear Kernel" src="https://scikit-learn.org/stable/_images/sphx_glr_plot_svm_kernels_thumb.png" /></p>
</section>
</section>
</section>
<section id="polynomial-kernel">
<h2><span class="section-number">40.59.4. </span>Polynomial Kernel<a class="headerlink" href="#polynomial-kernel" title="Permalink to this headline">#</a></h2>
<p>Polynomial kernel represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables. The polynomial kernel looks not only at the given features of input samples to determine their similarity, but also combinations of the input samples.</p>
<p>For degree-d polynomials, the polynomial kernel is defined as follows ‚Äì</p>
<p><strong>Polynomial kernel : K(xi , xj ) = (Œ≥xiT xj + r)d , Œ≥ &gt; 0</strong></p>
<p>Polynomial kernel is very popular in Natural Language Processing. The most common degree is d = 2 (quadratic), since larger degrees tend to overfit on NLP problems. It can be visualized with the following diagram.</p>
<section id="id2">
<h3><span class="section-number">40.59.4.1. </span>Polynomial Kernel<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<p><img alt="Polynomial Kernel" src="https://www.researchgate.net/profile/Cheng_Soon_Ong/publication/23442384/figure/fig12/AS:341444054274063&#64;1458418014823/The-effect-of-the-degree-of-a-polynomial-kernel-The-polynomial-kernel-of-degree-1-leads.png" /></p>
</section>
<section id="radial-basis-function-kernel">
<h3><span class="section-number">40.59.4.2. </span>Radial Basis Function Kernel<a class="headerlink" href="#radial-basis-function-kernel" title="Permalink to this headline">#</a></h3>
<p>Radial basis function kernel is a general purpose kernel. It is used when we have no prior knowledge about the data. The RBF kernel on two samples x and y is defined by the following equation ‚Äì</p>
<section id="id3">
<h4><span class="section-number">40.59.4.2.1. </span>Radial Basis Function kernel<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h4>
<p>![RBK Kernel](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYQAAACCCAMAAABxTU9IAAAAh1BMVEX///8AAAD+/v7T09O1tbXDw8P7+/vHx8dhYWGNjY2/v7/k5OSgoKAyMjJUVFM5OTnZ2dlvb28rKyutra3q6ury8vLLy8vf39+Xl5eGhoaAgICdnZ2kpKSvr69CQkIlJSVoaGhJSUkXFxd4eHhQUFAnJycQEBAeHh5AQEBjY2M3NzdaWlpISEgdoarBAAAQEElEQVR4nO1diWKqOhDNRBu3WjdArbi02tpe+//f92Ym7EQLAkp9nLe0RYSQk8ksmQlCNGjQoEGDBg0aNGjQ4DaQSt67CXFIKZWSNWtU5ajX80rqf/k/I6HdvncL4sDud5y6jYyqIHm09adf43u3JAEpLDi0xP9CFogDawd7JdS9m5KCdYIFKqt7N6N6IAcDgDb+rOPDLmFYN4OhGsyJA3V360gmftKvClk41nFwlArseeRgXYOpSIpx93D46SRV8RI2D64XaA7qwptQ9xYDRAcYi8Rh+530wv2bVx2w7ycwFPL+JEhx7A7E/A1gkDhuA8we2lIlMxCcTGfiYCQfttwx6TljChvSBz6SFAU8wQUo8541xAZ2mYYZiork/0rVHlJoESR6bT4CMI+fgSyMYF/mTWuHPol/hn7FrmhBX0grNWcXwxgvKsQrEMvUDIkmafwMRUKSYObBcIRJJq0nqSs6Al2KVan3f4In/P8JfM99BcnoCR0fPrRWGCT14AV4JDyX2gBNQpcnfextG3ams9qwtWvpS5YCF06Zz62cBJwWXw4muURuoPW4ovCVkv7zqJ4EdMwGpr6W+MHrw5Iwz2ifMqolgUyvnuYgZQYrVBXwmBzgJLuAj+wDrFoSFA13slIH0EpO/2g4Adil3rc2IG/5VBcSSA6+dt/f35/fIumLoGTswC31vrWBVD+wrgsJ6Ct4mKV0s6RPJ6Xety7gqMy8LiT80oz+o4YuZAtAZI/cVUyChzPtGTwqCTgLQ450hqpJYEVwjgW04zql3rg2WJBevooEqYMMivpMiWyBD+XFYPlk79sJP+E87CkHmR4QC+jlWFKLkCD5a5ZDyVlSzJ0s5qMe6nbLS+qgL+UgQbzwiQ8IIuFaSVi9Dz+hS2TsAIYZWKBo6ORj6wVEHYCjhbRkJuHw0CRkPjtGgnDbP0ARHRyiiCw5S0jC2sVz2eBHFxhoObmRhCGSkB0pxTwF/L4LSxQFK+tF0Btgg9/eUMSkIUEKKEICr7UcBQnTIGtIQUkHfK9r3UgCoxgJFGAGytSQOTJGkQReOpPi37RRzISCkqBIHTgxT8MaJ9GKXAEVMeW12MHVkqHsC2hIYKQkQUwAXuLRth6kEPmUnIqjR8LXkA81JBQlYQwwtWOS0JolEQ1+Svxnq0nwBKFKEool59ws3awQCdihOMGjXZRj7Rcf7INIkApe9ZEqSSiU0CZvVZ9SiAReaaFUrXwL8B/sKLz5kcMqSShYYfIXSJCiN0Srf5/zSY/E24pC6FWTIJzsSQxp7Ns3YqHYdNSHpycUBSXUOAcRqLpXNgqDrJYENBdeC6VI9bmNN0izuZIE3eOKIkdk/ahNjoVq9NFghs6Fj4pIQIb3BRPGnsCYflM6riahDTAeYfcLWo1cf+RRgTP8yqcVnF+VJMi9YZk0H151fLJqXE0C6KCd5DgcxYDykWCHD1eQBM4VTx3FMdGBr8xNMgIvfKTk28qNpKt1AkrCD9VVKusTvhxh6ggj8IFmEMubKCwJSg5W69RdxnkSqoyQlKyMBnjlauF6xayUt7pG1SXZhwp+bRbPXSlIQodzNA6Ju0hxiqid60BT7A6m1ZezX02CvyZP/+RpJD4YbGJDq7gkACRTOVUJgsDyhALfr1w5FyHBIyKds2iEFhc89fARl5yiOkG0wJCHcYL3MhL2bEBRqO90lBfMFD7OYZgQncIkLGiBIjEOkJhNKZ2318t/leJmJNC8NYFRa0OarlwSPtP1nrR855ZAAjNceaHW7UhgewWF+ymp6IrqBIss3uSMCDyXx+7vmZpnLc4g7SlSG8kl3tmLaPgxwxw2fTvKCNK1kTKBsLG3JWGkUmquKAmoOw9JX5EWjqzoMeoIr5fPqTDvGtxVvgxpElrG889cJLiGCcpLtuKp+fYkUN93+o6hC4qS8GKYMFwwpXf6fXtxiucVqqCRSvyAH3PPBsfh7YEiQSd/zUt3vtNBg6HlOJE6yFvqBBk0JIYiJJBtNsShOndn6/V65nKKHt5gSyQEd6JHn7nvL3x672hIkcIRP+sdpzZf8eUY6Hn86ydqexmFSEZ+WXzSnHukPCLpvn1Op9Pjq61679MjrOjzzhfOnS0+aWL5l8tDgiwmCTxfGh6jCAk4yFq0tjefLeix2rxWp1hXH0NPV4nnLT33UlAVKEA3fe3JccpqRFHZTMTtkGITkmCsow8nd/z5Bt0BX2DkFaICvNNFXngetnt0E2j7y77+kuQVJMwrKaG9WhLQDvrh+pKTFRwjz+E5nI7oF/XKnfkGIxMJdOYBdF7ugNnwjivKLoTgyiZ7K2RGnWBHlK95pYt6eMrFFsJBDvA02xmfqPP/9ecT+rnPLwnsP1ZAQp/79uXX+gQzCerA47aDwxyHsTef0yLHKjKxS6mzc5wxKtnnXrosnSwYh9ihFNvBJCSBU6v8MAv+tThOE3gP290Gz/6mMDHn2dJNpyQgrAyxddT5IzqXtBZ42iIPCQon1DHJdqkZ6kpxp4x/b4eJBH5MCzloR/VthyUhdiLVw8HkeMHmR/F50dURi2g6YV8PZu8ii+kogWl43x3OgQzQJpUOe8B+FXbyxM/3YQlb+KfHH15qW86ISx1UCRJzsEkn0IjaYKf3I96HNJNAE/TnhYqYFnsEtMNGzNqKkXBxOqIY1gnxcjp6di0O2y4R8h3cdBJMbiStOucnTcKZ29yDA5Fw64wk4FPNXB1wvkiC4rneTVUkhrBQdw+on3sx3y9KwmXFjCw+2xbDtm2l70p+RkSwAhLYePD0YIoE0T4OE3i3+faDdfvGmMfHrdFP8AyNqHtsIoEG5b9f3K6NlgSbrSgTCefmCO/Tld+roc3qTUjLwLgNJUG8XyJhmyaB7mSlM+sqRzyPw0QCCfUGn2wXewaTJNAKA17wwjLsRqdQfU1jch8nwfC14OQV2aNesCLwvrUGbvlHspFwZjrCf8etm8OKNcdEwoKyi+ekF6Iw6gTi6+3S/mYbNk3dsMcYMZ0gWylxXQfULHRvy5AXto+2UzaipYGEtzMknI96nG18dYiPPBMJ3HEkpJEaFd3fCRKEmH4AZefI2MQVxRfNGxZtoZGUhNBEfU2La3AVUsze/htKsHWkqGmKZMGvh4qT4Nn6JuvI0BflsiClyXNOn/a7Yia1N5fo6eFHUgQFiS3dHUEYjsa/C5SJ3Kb4tpLBpBG9fpdIOBxiG4JqP6EftHvuJKXVCd0RUrWOprDHoVcizWV2/S1qQhLobM9hyRc7Kgf87FdwaiBhqSeiHtedrBe6UAI7ny2PaOwIeWlTL6+EPWxzN7XbrcQOmKhCF8vELmiKa8H865zRCf5vPP239aWmfGSM7VLsy3zpqzIJ/AWcMr9F/thRWeBnuUKuDCRMdCYspSWrNn7srQiwzRTy3F44vJWVSwkBhy5P+TqGlCThlDRiYwG8MyZqcL7NoaHjavXjDfcxbW4s9ZS28husNQyJpW/93YUEIdGOzr8CnCBB6ln4iTqHLCkKqfh9tAxIwD6gUM6UpgfyFCaUtKknrGSxo+6qWD/j7z80YoO/DSSE+xpLzQJoHaAo63bFQ05NtWLheg6ANQrHCUIn/x4kiMEbdUs7rzgkSZDiGbxNkBYQT65wWeq9SBL7S+QBcDxtzItdA+6qePylT4v68SYpaX9kXk/A+9k7zYHrlyTBCgVrzOWtsHS0JKCwjAA+wsr4u5CAj/XKs2cxEjztKqivXFfFFCr4/hsNxM5szdE9abszveCIzLizZYqEkUo0SS8HZlzeZP0/cGcuG0a0c6nUt/UmOKW0JFgt13WtyBC8BwnPnzgVWR859t7TSOmEwF31raLouX4ycHBK5Bd97j5woPU3d0G2fngHImGUNWEgMG31QiZveuDt5+sdjFhHES1fIgky8fMsTo5n+mUufdbIkxDMKS9nW6KT1rYvntpQvF9+33j5ZSqxrBAifkKI8kiQEVc9w9loi3SLTUcXL49T+fG86ufl9iGMPWtK6AUrw9V5/rBKzDuqmATB85/K5IZpN8apjgRFOvv82WjHtLeTgW/ZdCY9HBPGlxfY7PX9HRLmewpJjZZZJhnaJf0t78PlkQRyFSZnc4xQL3/Pg4mToh4b05qn5DT+spIgeabQJCQcjpJI8EK2Gq3fEuWpa07b3MMrHwktXSN67uOIYuT4sGkuouTl8jQC5a/b5COuk05fWSTwkyxnvI4E88uBJq0FCztrF9ujqFhqdCbQwCMx/EjtDl1TzR2vxnVLm4pwXEy/Di+Hw8+/ROpsaSRsaeUCHXUKVv2ymdhZS+QX5JIESRFW94xEGtZrDTKDJuZ7nhTI39oUuUO8WWXphAE76mSB63BA1HGKN0VbRhT0VDl3U8tZOEjCaRcybNQI8lSlXo2ySFgF08tSx3PDj2JJdzwA++zNqn85053zltAKa5jXFYlfYEsc1K5w8DzGQeSmBRcz+qMqvEJnzTNG9kV28RwerDMJFiWjRGfN+0nB81h2lf3U6TgO/YfozMVgstfo5Xy+a3Z5KdKFN3tbQ/mxIwdgK8Ic9DZ8xhYD7evn2GarncxYcF6tjsnoupAo3pJxyhxoSMiMbVB06qV7nNzxvAuL+Xw+Ho+tAjGAhoRs4OCotjy9NZfD2LuP14EFUvkaEjJBkdPGhifZJoNPPwudirLzFB2Z0ZCQCQr18Iv0F7RO4IeBuQiyaIF9Q0JGOJxCIILkn7anonkRuIjjRGhI+BX8RsiRP+lIFe/3lTlQmQsNCb9D0rthglVb3gjJ3+uGQprFA/MNCb+CU3TC99Fx/n24WR7EE6evwkOTUEKckA3PIcccvRgxpyKu/L9dKGF1pCHhMpQSOBc9eb+KpasH/7POa+C64u/C92lIuAwc7T9BolpnzyLR41piFoQDwLtVeLn8YUk4UcFtCddRo2iEaMgRIvD26FcbgNHZ9d7MsI+PSgK/9bE4C7yAHUInv1H07uCMe1CO9p/Dg77YSPLLy4qTMH7tRbD03p9nL1g+Xhf2NeUISQwe9Q2otA5bQXWs9EPZwd8lkDB71JfdSfuznNeuJ7L6wzRdIQtFTiPXfy26z2ldQWnCOV6Aej8o2inlMd9CKymesP0bJKgSguH1BMU6jzdb0C4ARatFf2CwXAGqW/hXfBPXG4AiH7u/ILJXQFJ1omEjrNpBCa8G+QHBdYylbKVbNfrlFmvUCxRoW5XhS1WMXbnFGnXDijRe3R9vnPMdDX8MSkGudzLfB10qNqi/vF4L3pesWAp51eB6cLsMx7uukLT158tt0o+vg1e19LAMCL0ZwJb346nrU0q5g1N9m1cGaKZ9gnQxe43Qpp0NHlch+JgZCjvrAcUbdWR59/xfB+8sPBdlRP3LBr9j9UEjdzGQUl6/055NNVTOa3qDWA3bVTpoXd6elJN4USooUaNn3OvpIYHPaX3neltD9aBdu17/QmCrLPh5c7VC/K0ejw9Dkfvdwds21a1RDRo0aNCgQYMGNcR/NaSknxWdtb4AAAAASUVORK5CYII=)</p>
<p>The following diagram demonstrates the SVM classification with rbf kernel.</p>
</section>
<section id="svm-classification-with-rbf-kernel">
<h4><span class="section-number">40.59.4.2.2. </span>SVM Classification with rbf kernel<a class="headerlink" href="#svm-classification-with-rbf-kernel" title="Permalink to this headline">#</a></h4>
<p><img alt="SVM Classification with rbf kernel" src="https://www.researchgate.net/profile/Periklis_Gogas/publication/286180566/figure/fig5/AS:304327777374210&#64;1449568804246/An-example-of-an-SVM-classification-using-the-RBF-kernel-The-two-classes-are-separated.png" /></p>
</section>
</section>
</section>
<section id="svm-scikit-learn-libraries">
<h2><span class="section-number">40.59.5. </span>SVM Scikit-Learn libraries<a class="headerlink" href="#svm-scikit-learn-libraries" title="Permalink to this headline">#</a></h2>
<p>Scikit-Learn provides useful libraries to implement Support Vector Machine algorithm on a dataset. There are many libraries that can help us to implement SVM smoothly. We just need to call the library with parameters that suit to our needs. In this project, I am dealing with a classification task. So, I will mention the Scikit-Learn libraries for SVM classification purposes.</p>
<p>First, there is a <strong>LinearSVC()</strong> classifier. As the name suggests, this classifier uses only linear kernel. In LinearSVC() classifier, we don‚Äôt pass the value of kernel since it is used only for linear classification purposes.</p>
<p>Scikit-Learn provides two other classifiers - <strong>SVC()</strong> and <strong>NuSVC()</strong> which are used for classification purposes. These classifiers are mostly similar with some difference in parameters. <strong>NuSVC()</strong> is similar to <strong>SVC()</strong> but uses a parameter to control the number of support vectors. We pass the values of kernel, gamma and C along with other parameters. By default kernel parameter uses rbf as its value but we can pass values like poly, linear, sigmoid or callable function.</p>
</section>
<section id="dataset-description">
<h2><span class="section-number">40.59.6. </span>Dataset description<a class="headerlink" href="#dataset-description" title="Permalink to this headline">#</a></h2>
<p>I have used the <strong>Predicting a Pulsar Star</strong> dataset for this project.</p>
<p>Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter. Classification algorithms in particular are being adopted, which treat the data sets as binary classification problems. Here the legitimate pulsar examples form  minority positive class and spurious examples form the majority negative class.</p>
<p>The data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. Each row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive).</p>
<section id="attribute-information">
<h3><span class="section-number">40.59.6.1. </span>Attribute Information:<a class="headerlink" href="#attribute-information" title="Permalink to this headline">#</a></h3>
<p>Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile. The remaining four variables are similarly obtained from the DM-SNR curve . These are summarised below:</p>
<ol class="simple">
<li><p>Mean of the integrated profile.</p></li>
<li><p>Standard deviation of the integrated profile.</p></li>
<li><p>Excess kurtosis of the integrated profile.</p></li>
<li><p>Skewness of the integrated profile.</p></li>
<li><p>Mean of the DM-SNR curve.</p></li>
<li><p>Standard deviation of the DM-SNR curve.</p></li>
<li><p>Excess kurtosis of the DM-SNR curve.</p></li>
<li><p>Skewness of the DM-SNR curve.</p></li>
<li><p>Class</p></li>
</ol>
</section>
</section>
<section id="import-libraries">
<h2><span class="section-number">40.59.7. </span>Import libraries<a class="headerlink" href="#import-libraries" title="Permalink to this headline">#</a></h2>
<p>I will start off by importing the required Python libraries.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1"># linear algebra</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> <span class="c1"># data processing, CSV file I/O (e.g. pd.read_csv)</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> <span class="c1"># for data visualization</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span> <span class="c1"># for statistical data visualization</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="import-dataset">
<h2><span class="section-number">40.59.8. </span>Import dataset<a class="headerlink" href="#import-dataset" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="s1">&#39;../../../assets/data/pulsar_stars.csv&#39;</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="exploratory-data-analysis">
<h2><span class="section-number">40.59.9. </span>Exploratory data analysis<a class="headerlink" href="#exploratory-data-analysis" title="Permalink to this headline">#</a></h2>
<p>Now, we will explore the data to gain insights about the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># view dimensions of dataset</span>

<span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(17898, 9)
</pre></div>
</div>
</div>
</div>
<p>We can see that there are 17898 instances and 9 variables in the data set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># let&#39;s preview the dataset</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Mean of the integrated profile</th>
      <th>Standard deviation of the integrated profile</th>
      <th>Excess kurtosis of the integrated profile</th>
      <th>Skewness of the integrated profile</th>
      <th>Mean of the DM-SNR curve</th>
      <th>Standard deviation of the DM-SNR curve</th>
      <th>Excess kurtosis of the DM-SNR curve</th>
      <th>Skewness of the DM-SNR curve</th>
      <th>target_class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>140.562500</td>
      <td>55.683782</td>
      <td>-0.234571</td>
      <td>-0.699648</td>
      <td>3.199833</td>
      <td>19.110426</td>
      <td>7.975532</td>
      <td>74.242225</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>102.507812</td>
      <td>58.882430</td>
      <td>0.465318</td>
      <td>-0.515088</td>
      <td>1.677258</td>
      <td>14.860146</td>
      <td>10.576487</td>
      <td>127.393580</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>103.015625</td>
      <td>39.341649</td>
      <td>0.323328</td>
      <td>1.051164</td>
      <td>3.121237</td>
      <td>21.744669</td>
      <td>7.735822</td>
      <td>63.171909</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>136.750000</td>
      <td>57.178449</td>
      <td>-0.068415</td>
      <td>-0.636238</td>
      <td>3.642977</td>
      <td>20.959280</td>
      <td>6.896499</td>
      <td>53.593661</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>88.726562</td>
      <td>40.672225</td>
      <td>0.600866</td>
      <td>1.123492</td>
      <td>1.178930</td>
      <td>11.468720</td>
      <td>14.269573</td>
      <td>252.567306</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see that there are 9 variables in the dataset. 8 are continuous variables and 1 is discrete variable. The discrete variable is <code class="docutils literal notranslate"><span class="pre">target_class</span></code> variable. It is also the target variable.</p>
<p>Now, I will view the column names to check for leading and trailing spaces.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># view the column names of the dataframe</span>

<span class="n">col_names</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span>

<span class="n">col_names</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39; Mean of the integrated profile&#39;,
       &#39; Standard deviation of the integrated profile&#39;,
       &#39; Excess kurtosis of the integrated profile&#39;,
       &#39; Skewness of the integrated profile&#39;, &#39; Mean of the DM-SNR curve&#39;,
       &#39; Standard deviation of the DM-SNR curve&#39;,
       &#39; Excess kurtosis of the DM-SNR curve&#39;, &#39; Skewness of the DM-SNR curve&#39;,
       &#39;target_class&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>We can see that there are leading spaces (spaces at the start of the string name) in the dataframe. So, I will remove these leading spaces.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># remove leading spaces from column names</span>

<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>I have removed the leading spaces from the column names. Let‚Äôs again view the column names to confirm the same.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># view column names again</span>

<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;Mean of the integrated profile&#39;,
       &#39;Standard deviation of the integrated profile&#39;,
       &#39;Excess kurtosis of the integrated profile&#39;,
       &#39;Skewness of the integrated profile&#39;, &#39;Mean of the DM-SNR curve&#39;,
       &#39;Standard deviation of the DM-SNR curve&#39;,
       &#39;Excess kurtosis of the DM-SNR curve&#39;, &#39;Skewness of the DM-SNR curve&#39;,
       &#39;target_class&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>We can see that the leading spaces are removed from the column name. But the column names are very long. So, I will make them short by renaming them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># rename column names</span>

<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;IP Mean&#39;</span><span class="p">,</span> <span class="s1">&#39;IP Sd&#39;</span><span class="p">,</span> <span class="s1">&#39;IP Kurtosis&#39;</span><span class="p">,</span> <span class="s1">&#39;IP Skewness&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;DM-SNR Mean&#39;</span><span class="p">,</span> <span class="s1">&#39;DM-SNR Sd&#39;</span><span class="p">,</span> <span class="s1">&#39;DM-SNR Kurtosis&#39;</span><span class="p">,</span> <span class="s1">&#39;DM-SNR Skewness&#39;</span><span class="p">,</span> <span class="s1">&#39;target_class&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># view the renamed column names</span>

<span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;IP Mean&#39;, &#39;IP Sd&#39;, &#39;IP Kurtosis&#39;, &#39;IP Skewness&#39;, &#39;DM-SNR Mean&#39;,
       &#39;DM-SNR Sd&#39;, &#39;DM-SNR Kurtosis&#39;, &#39;DM-SNR Skewness&#39;, &#39;target_class&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>We can see that the column names are shortened. IP stands for <code class="docutils literal notranslate"><span class="pre">integrated</span> <span class="pre">profile</span></code> and DM-SNR stands for <code class="docutils literal notranslate"><span class="pre">delta</span> <span class="pre">modulation</span> <span class="pre">and</span> <span class="pre">signal</span> <span class="pre">to</span> <span class="pre">noise</span> <span class="pre">ratio</span></code>. Now, it is much more easy to work with the columns.</p>
<p>Our target variable is the <code class="docutils literal notranslate"><span class="pre">target_class</span></code> column. So, I will check its distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># check distribution of target_class column</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;target_class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    16259
1     1639
Name: target_class, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># view the percentage distribution of target_class column</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;target_class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    0.908426
1    0.091574
Name: target_class, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We can see that percentage of observations of the class label <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code> is 90.84% and 9.16%. So, this is a class imbalanced problem. I will deal with that in later section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># view summary of dataset</span>

<span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 17898 entries, 0 to 17897
Data columns (total 9 columns):
 #   Column           Non-Null Count  Dtype  
---  ------           --------------  -----  
 0   IP Mean          17898 non-null  float64
 1   IP Sd            17898 non-null  float64
 2   IP Kurtosis      17898 non-null  float64
 3   IP Skewness      17898 non-null  float64
 4   DM-SNR Mean      17898 non-null  float64
 5   DM-SNR Sd        17898 non-null  float64
 6   DM-SNR Kurtosis  17898 non-null  float64
 7   DM-SNR Skewness  17898 non-null  float64
 8   target_class     17898 non-null  int64  
dtypes: float64(8), int64(1)
memory usage: 1.2 MB
</pre></div>
</div>
</div>
</div>
<p>We can see that there are no missing values in the dataset and all the variables are numerical variables.</p>
<section id="explore-missing-values-in-variables">
<h3><span class="section-number">40.59.9.1. </span>Explore missing values in variables<a class="headerlink" href="#explore-missing-values-in-variables" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># check for missing values in variables</span>

<span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>IP Mean            0
IP Sd              0
IP Kurtosis        0
IP Skewness        0
DM-SNR Mean        0
DM-SNR Sd          0
DM-SNR Kurtosis    0
DM-SNR Skewness    0
target_class       0
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>We can see that there are no missing values in the dataset.</p>
</section>
<section id="summary-of-numerical-variables">
<h3><span class="section-number">40.59.9.2. </span>Summary of numerical variables<a class="headerlink" href="#summary-of-numerical-variables" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>There are 9 numerical variables in the dataset.</p></li>
<li><p>8 are continuous variables and 1 is discrete variable.</p></li>
<li><p>The discrete variable is <code class="docutils literal notranslate"><span class="pre">target_class</span></code> variable. It is also the target variable.</p></li>
<li><p>There are no missing values in the dataset.</p></li>
</ul>
</section>
<section id="outliers-in-numerical-variables">
<h3><span class="section-number">40.59.9.3. </span>Outliers in numerical variables<a class="headerlink" href="#outliers-in-numerical-variables" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># view summary statistics in numerical variables</span>

<span class="nb">round</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">(),</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>IP Mean</th>
      <th>IP Sd</th>
      <th>IP Kurtosis</th>
      <th>IP Skewness</th>
      <th>DM-SNR Mean</th>
      <th>DM-SNR Sd</th>
      <th>DM-SNR Kurtosis</th>
      <th>DM-SNR Skewness</th>
      <th>target_class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>17898.00</td>
      <td>17898.00</td>
      <td>17898.00</td>
      <td>17898.00</td>
      <td>17898.00</td>
      <td>17898.00</td>
      <td>17898.00</td>
      <td>17898.00</td>
      <td>17898.00</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>111.08</td>
      <td>46.55</td>
      <td>0.48</td>
      <td>1.77</td>
      <td>12.61</td>
      <td>26.33</td>
      <td>8.30</td>
      <td>104.86</td>
      <td>0.09</td>
    </tr>
    <tr>
      <th>std</th>
      <td>25.65</td>
      <td>6.84</td>
      <td>1.06</td>
      <td>6.17</td>
      <td>29.47</td>
      <td>19.47</td>
      <td>4.51</td>
      <td>106.51</td>
      <td>0.29</td>
    </tr>
    <tr>
      <th>min</th>
      <td>5.81</td>
      <td>24.77</td>
      <td>-1.88</td>
      <td>-1.79</td>
      <td>0.21</td>
      <td>7.37</td>
      <td>-3.14</td>
      <td>-1.98</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>100.93</td>
      <td>42.38</td>
      <td>0.03</td>
      <td>-0.19</td>
      <td>1.92</td>
      <td>14.44</td>
      <td>5.78</td>
      <td>34.96</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>115.08</td>
      <td>46.95</td>
      <td>0.22</td>
      <td>0.20</td>
      <td>2.80</td>
      <td>18.46</td>
      <td>8.43</td>
      <td>83.06</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>127.09</td>
      <td>51.02</td>
      <td>0.47</td>
      <td>0.93</td>
      <td>5.46</td>
      <td>28.43</td>
      <td>10.70</td>
      <td>139.31</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>max</th>
      <td>192.62</td>
      <td>98.78</td>
      <td>8.07</td>
      <td>68.10</td>
      <td>223.39</td>
      <td>110.64</td>
      <td>34.54</td>
      <td>1191.00</td>
      <td>1.00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>On closer inspection, we can suspect that all the continuous variables may contain outliers.</p>
<p>I will draw boxplots to visualise outliers in the above variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># draw boxplots to visualize outliers</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;IP Mean&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;IP Mean&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;IP Sd&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;IP Sd&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;IP Kurtosis&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;IP Kurtosis&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;IP Skewness&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;IP Skewness&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;DM-SNR Mean&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;DM-SNR Mean&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;DM-SNR Sd&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;DM-SNR Sd&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;DM-SNR Kurtosis&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;DM-SNR Kurtosis&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;DM-SNR Skewness&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;DM-SNR Skewness&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;DM-SNR Skewness&#39;)
</pre></div>
</div>
<img alt="../../../_images/kernel-method-assignment-1_43_1.png" src="../../../_images/kernel-method-assignment-1_43_1.png" />
</div>
</div>
<p>The above boxplots confirm that there are lot of outliers in these variables.</p>
</section>
<section id="handle-outliers-with-svms">
<h3><span class="section-number">40.59.9.4. </span>Handle outliers with SVMs<a class="headerlink" href="#handle-outliers-with-svms" title="Permalink to this headline">#</a></h3>
<p>There are 2 variants of SVMs. They are <code class="docutils literal notranslate"><span class="pre">hard-margin</span> <span class="pre">variant</span> <span class="pre">of</span> <span class="pre">SVM</span></code> and <code class="docutils literal notranslate"><span class="pre">soft-margin</span> <span class="pre">variant</span> <span class="pre">of</span> <span class="pre">SVM</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">hard-margin</span> <span class="pre">variant</span> <span class="pre">of</span> <span class="pre">SVM</span></code> does not deal with outliers. In this case, we want to find the hyperplane with maximum margin such that every training point is correctly classified with margin at least 1. This technique does not handle outliers well.</p>
<p>Another version of SVM is called <code class="docutils literal notranslate"><span class="pre">soft-margin</span> <span class="pre">variant</span> <span class="pre">of</span> <span class="pre">SVM</span></code>. In this case, we can have a few points incorrectly classified or
classified with a margin less than 1. But for every such point, we have to pay a penalty in the form of <code class="docutils literal notranslate"><span class="pre">C</span></code> parameter, which controls the outliers. <code class="docutils literal notranslate"><span class="pre">Low</span> <span class="pre">C</span></code> implies we are allowing more outliers and <code class="docutils literal notranslate"><span class="pre">high</span> <span class="pre">C</span></code> implies less outliers.</p>
<p>The message is that since the dataset contains outliers, so the value of C should be high while training the model.</p>
</section>
<section id="check-the-distribution-of-variables">
<h3><span class="section-number">40.59.9.5. </span>Check the distribution of variables<a class="headerlink" href="#check-the-distribution-of-variables" title="Permalink to this headline">#</a></h3>
<p>Now, I will plot the histograms to check distributions to find out if they are normal or skewed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot histogram to check distribution</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;IP Mean&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;IP Mean&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Number of pulsar stars&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;IP Sd&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;IP Sd&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Number of pulsar stars&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;IP Kurtosis&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;IP Kurtosis&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Number of pulsar stars&#39;</span><span class="p">)</span>



<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;IP Skewness&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;IP Skewness&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Number of pulsar stars&#39;</span><span class="p">)</span>



<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;DM-SNR Mean&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;DM-SNR Mean&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Number of pulsar stars&#39;</span><span class="p">)</span>



<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;DM-SNR Sd&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;DM-SNR Sd&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Number of pulsar stars&#39;</span><span class="p">)</span>



<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;DM-SNR Kurtosis&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;DM-SNR Kurtosis&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Number of pulsar stars&#39;</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;DM-SNR Skewness&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;DM-SNR Skewness&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Number of pulsar stars&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Number of pulsar stars&#39;)
</pre></div>
</div>
<img alt="../../../_images/kernel-method-assignment-1_47_1.png" src="../../../_images/kernel-method-assignment-1_47_1.png" />
</div>
</div>
<p>We can see that all the 8 continuous variables are skewed.</p>
</section>
</section>
<section id="declare-feature-vector-and-target-variable">
<h2><span class="section-number">40.59.10. </span>Declare feature vector and target variable<a class="headerlink" href="#declare-feature-vector-and-target-variable" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;target_class&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target_class&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="split-data-into-separate-training-and-test-set">
<h2><span class="section-number">40.59.11. </span>Split data into separate training and test set<a class="headerlink" href="#split-data-into-separate-training-and-test-set" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># split X and y into training and testing sets</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># check the shape of X_train and X_test</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((14318, 8), (3580, 8))
</pre></div>
</div>
</div>
</div>
</section>
<section id="feature-scaling">
<h2><span class="section-number">40.59.12. </span>Feature Scaling<a class="headerlink" href="#feature-scaling" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cols</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">cols</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">cols</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>IP Mean</th>
      <th>IP Sd</th>
      <th>IP Kurtosis</th>
      <th>IP Skewness</th>
      <th>DM-SNR Mean</th>
      <th>DM-SNR Sd</th>
      <th>DM-SNR Kurtosis</th>
      <th>DM-SNR Skewness</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1.431800e+04</td>
      <td>1.431800e+04</td>
      <td>1.431800e+04</td>
      <td>1.431800e+04</td>
      <td>1.431800e+04</td>
      <td>1.431800e+04</td>
      <td>1.431800e+04</td>
      <td>1.431800e+04</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1.908113e-16</td>
      <td>-6.550610e-16</td>
      <td>1.042143e-17</td>
      <td>3.870815e-17</td>
      <td>-8.734147e-17</td>
      <td>-1.617802e-16</td>
      <td>-1.513588e-17</td>
      <td>1.122785e-16</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.000035e+00</td>
      <td>1.000035e+00</td>
      <td>1.000035e+00</td>
      <td>1.000035e+00</td>
      <td>1.000035e+00</td>
      <td>1.000035e+00</td>
      <td>1.000035e+00</td>
      <td>1.000035e+00</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-4.035499e+00</td>
      <td>-3.181033e+00</td>
      <td>-2.185946e+00</td>
      <td>-5.744051e-01</td>
      <td>-4.239001e-01</td>
      <td>-9.733707e-01</td>
      <td>-2.455649e+00</td>
      <td>-1.003411e+00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-3.896291e-01</td>
      <td>-6.069473e-01</td>
      <td>-4.256221e-01</td>
      <td>-3.188054e-01</td>
      <td>-3.664918e-01</td>
      <td>-6.125457e-01</td>
      <td>-5.641035e-01</td>
      <td>-6.627590e-01</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.587461e-01</td>
      <td>5.846646e-02</td>
      <td>-2.453172e-01</td>
      <td>-2.578142e-01</td>
      <td>-3.372294e-01</td>
      <td>-4.067482e-01</td>
      <td>3.170446e-02</td>
      <td>-2.059136e-01</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.267059e-01</td>
      <td>6.501017e-01</td>
      <td>-1.001238e-02</td>
      <td>-1.419621e-01</td>
      <td>-2.463724e-01</td>
      <td>1.078934e-01</td>
      <td>5.362759e-01</td>
      <td>3.256217e-01</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3.151882e+00</td>
      <td>7.621116e+00</td>
      <td>7.008906e+00</td>
      <td>1.054430e+01</td>
      <td>7.025568e+00</td>
      <td>4.292181e+00</td>
      <td>5.818557e+00</td>
      <td>1.024613e+01</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We now have <code class="docutils literal notranslate"><span class="pre">X_train</span></code> dataset ready to be fed into the Logistic Regression classifier. I will do it as follows.</p>
</section>
<section id="run-svm-with-default-hyperparameters">
<h2><span class="section-number">40.59.13. </span>Run SVM with default hyperparameters<a class="headerlink" href="#run-svm-with-default-hyperparameters" title="Permalink to this headline">#</a></h2>
<p>Default hyperparameter means C=1.0,  kernel=<code class="docutils literal notranslate"><span class="pre">rbf</span></code> and gamma=<code class="docutils literal notranslate"><span class="pre">auto</span></code> among other parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import SVC classifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>


<span class="c1"># import metrics to compute accuracy</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>


<span class="c1"># instantiate classifier with default hyperparameters</span>
<span class="n">svc</span><span class="o">=</span><span class="n">SVC</span><span class="p">()</span> 


<span class="c1"># fit classifier to training set</span>
<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>


<span class="c1"># make predictions on test set</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="c1"># compute and print accuracy score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model accuracy score with default hyperparameters: </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model accuracy score with default hyperparameters: 0.9827
</pre></div>
</div>
</div>
</div>
<section id="run-svm-with-rbf-kernel-and-c-100-0">
<h3><span class="section-number">40.59.13.1. </span>Run SVM with rbf kernel and C=100.0<a class="headerlink" href="#run-svm-with-rbf-kernel-and-c-100-0" title="Permalink to this headline">#</a></h3>
<p>We have seen that there are outliers in our dataset. So, we should increase the value of C as higher C means fewer outliers.
So, I will run SVM with kernel=<code class="docutils literal notranslate"><span class="pre">rbf</span></code> and C=100.0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate classifier with rbf kernel and C=100</span>
<span class="n">svc</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">100.0</span><span class="p">)</span> 


<span class="c1"># fit classifier to training set</span>
<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>


<span class="c1"># make predictions on test set</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="c1"># compute and print accuracy score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model accuracy score with rbf kernel and C=100.0 : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model accuracy score with rbf kernel and C=100.0 : 0.9832
</pre></div>
</div>
</div>
</div>
<p>We can see that we obtain a higher accuracy with C=100.0 as higher C means less outliers.</p>
<p>Now, I will further increase the value of C=1000.0 and check accuracy.</p>
</section>
<section id="run-svm-with-rbf-kernel-and-c-1000-0">
<h3><span class="section-number">40.59.13.2. </span>Run SVM with rbf kernel and C=1000.0<a class="headerlink" href="#run-svm-with-rbf-kernel-and-c-1000-0" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate classifier with rbf kernel and C=1000</span>
<span class="n">svc</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">1000.0</span><span class="p">)</span> 


<span class="c1"># fit classifier to training set</span>
<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>


<span class="c1"># make predictions on test set</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="c1"># compute and print accuracy score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model accuracy score with rbf kernel and C=1000.0 : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model accuracy score with rbf kernel and C=1000.0 : 0.9816
</pre></div>
</div>
</div>
</div>
<p>In this case, we can see that the accuracy had decreased with C=1000.0</p>
</section>
</section>
<section id="run-svm-with-linear-kernel">
<h2><span class="section-number">40.59.14. </span>Run SVM with linear kernel<a class="headerlink" href="#run-svm-with-linear-kernel" title="Permalink to this headline">#</a></h2>
<section id="run-svm-with-linear-kernel-and-c-1-0">
<h3><span class="section-number">40.59.14.1. </span>Run SVM with linear kernel and C=1.0<a class="headerlink" href="#run-svm-with-linear-kernel-and-c-1-0" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate classifier with linear kernel and C=1.0</span>
<span class="n">linear_svc</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> 


<span class="c1"># fit classifier to training set</span>
<span class="n">linear_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>


<span class="c1"># make predictions on test set</span>
<span class="n">y_pred_test</span><span class="o">=</span><span class="n">linear_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="c1"># compute and print accuracy score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model accuracy score with linear kernel and C=1.0 : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model accuracy score with linear kernel and C=1.0 : 0.9830
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-svm-with-linear-kernel-and-c-100-0">
<h3><span class="section-number">40.59.14.2. </span>Run SVM with linear kernel and C=100.0<a class="headerlink" href="#run-svm-with-linear-kernel-and-c-100-0" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate classifier with linear kernel and C=100.0</span>
<span class="n">linear_svc100</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">100.0</span><span class="p">)</span> 


<span class="c1"># fit classifier to training set</span>
<span class="n">linear_svc100</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


<span class="c1"># make predictions on test set</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">linear_svc100</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="c1"># compute and print accuracy score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model accuracy score with linear kernel and C=100.0 : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model accuracy score with linear kernel and C=100.0 : 0.9832
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-svm-with-linear-kernel-and-c-1000-0">
<h3><span class="section-number">40.59.14.3. </span>Run SVM with linear kernel and C=1000.0<a class="headerlink" href="#run-svm-with-linear-kernel-and-c-1000-0" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate classifier with linear kernel and C=1000.0</span>
<span class="n">linear_svc1000</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1000.0</span><span class="p">)</span> 


<span class="c1"># fit classifier to training set</span>
<span class="n">linear_svc1000</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


<span class="c1"># make predictions on test set</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">linear_svc1000</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="c1"># compute and print accuracy score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model accuracy score with linear kernel and C=1000.0 : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model accuracy score with linear kernel and C=1000.0 : 0.9832
</pre></div>
</div>
</div>
</div>
<p>We can see that we can obtain higher accuracy with C=100.0 and C=1000.0 as compared to C=1.0.</p>
<p>Here, <strong>y_test</strong> are the true class labels and <strong>y_pred</strong> are the predicted class labels in the test-set.</p>
</section>
<section id="compare-the-train-set-and-test-set-accuracy">
<h3><span class="section-number">40.59.14.4. </span>Compare the train-set and test-set accuracy<a class="headerlink" href="#compare-the-train-set-and-test-set-accuracy" title="Permalink to this headline">#</a></h3>
<p>Now, I will compare the train-set and test-set accuracy to check for overfitting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">linear_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">y_pred_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 0, 1, ..., 0, 0, 0], dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training-set accuracy score: </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training-set accuracy score: 0.9783
</pre></div>
</div>
</div>
</div>
<p>We can see that the training set and test-set accuracy are very much comparable.</p>
</section>
<section id="check-for-overfitting-and-underfitting">
<h3><span class="section-number">40.59.14.5. </span>Check for overfitting and underfitting<a class="headerlink" href="#check-for-overfitting-and-underfitting" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print the scores on training and test set</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training set score: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">linear_svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test set score: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">linear_svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.9783
Test set score: 0.9830
</pre></div>
</div>
</div>
</div>
<p>The training-set accuracy score is 0.9783 while the test-set accuracy to be 0.9830. These two values are quite comparable. So, there is no question of overfitting.</p>
</section>
<section id="compare-model-accuracy-with-null-accuracy">
<h3><span class="section-number">40.59.14.6. </span>Compare model accuracy with null accuracy<a class="headerlink" href="#compare-model-accuracy-with-null-accuracy" title="Permalink to this headline">#</a></h3>
<p>So, the model accuracy is 0.9832. But, we cannot say that our model is very good based on the above accuracy. We must compare it with the <strong>null accuracy</strong>. Null accuracy is the accuracy that could be achieved by always predicting the most frequent class.</p>
<p>So, we should first check the class distribution in the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># check class distribution in test set</span>

<span class="n">y_test</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    3306
1     274
Name: target_class, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>We can see that the occurences of most frequent class <code class="docutils literal notranslate"><span class="pre">0</span></code> is 3306. So, we can calculate null accuracy by dividing 3306 by total number of occurences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># check null accuracy score</span>

<span class="n">null_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3306</span><span class="o">/</span><span class="p">(</span><span class="mi">3306</span><span class="o">+</span><span class="mi">274</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Null accuracy score: </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">null_accuracy</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Null accuracy score: 0.9235
</pre></div>
</div>
</div>
</div>
<p>We can see that our model accuracy score is 0.9830 but null accuracy score is 0.9235. So, we can conclude that our SVM classifier is doing a very good job in predicting the class labels.</p>
</section>
</section>
<section id="run-svm-with-polynomial-kernel">
<h2><span class="section-number">40.59.15. </span>Run SVM with polynomial kernel<a class="headerlink" href="#run-svm-with-polynomial-kernel" title="Permalink to this headline">#</a></h2>
<section id="run-svm-with-polynomial-kernel-and-c-1-0">
<h3><span class="section-number">40.59.15.1. </span>Run SVM with polynomial kernel and C=1.0<a class="headerlink" href="#run-svm-with-polynomial-kernel-and-c-1-0" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate classifier with polynomial kernel and C=1.0</span>
<span class="n">poly_svc</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> 


<span class="c1"># fit classifier to training set</span>
<span class="n">poly_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>


<span class="c1"># make predictions on test set</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">poly_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="c1"># compute and print accuracy score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model accuracy score with polynomial kernel and C=1.0 : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model accuracy score with polynomial kernel and C=1.0 : 0.9807
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-svm-with-polynomial-kernel-and-c-100-0">
<h3><span class="section-number">40.59.15.2. </span>Run SVM with polynomial kernel and C=100.0<a class="headerlink" href="#run-svm-with-polynomial-kernel-and-c-100-0" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate classifier with polynomial kernel and C=100.0</span>
<span class="n">poly_svc100</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">100.0</span><span class="p">)</span> 


<span class="c1"># fit classifier to training set</span>
<span class="n">poly_svc100</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


<span class="c1"># make predictions on test set</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">poly_svc100</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="c1"># compute and print accuracy score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model accuracy score with polynomial kernel and C=1.0 : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model accuracy score with polynomial kernel and C=1.0 : 0.9824
</pre></div>
</div>
</div>
</div>
<p>Polynomial kernel gives poor performance. It may be overfitting the training set.</p>
</section>
</section>
<section id="run-svm-with-sigmoid-kernel">
<h2><span class="section-number">40.59.16. </span>Run SVM with sigmoid kernel<a class="headerlink" href="#run-svm-with-sigmoid-kernel" title="Permalink to this headline">#</a></h2>
<section id="run-svm-with-sigmoid-kernel-and-c-1-0">
<h3><span class="section-number">40.59.16.1. </span>Run SVM with sigmoid kernel and C=1.0<a class="headerlink" href="#run-svm-with-sigmoid-kernel-and-c-1-0" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate classifier with sigmoid kernel and C=1.0</span>
<span class="n">sigmoid_svc</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> 


<span class="c1"># fit classifier to training set</span>
<span class="n">sigmoid_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>


<span class="c1"># make predictions on test set</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">sigmoid_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="c1"># compute and print accuracy score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model accuracy score with sigmoid kernel and C=1.0 : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model accuracy score with sigmoid kernel and C=1.0 : 0.8858
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-svm-with-sigmoid-kernel-and-c-100-0">
<h3><span class="section-number">40.59.16.2. </span>Run SVM with sigmoid kernel and C=100.0<a class="headerlink" href="#run-svm-with-sigmoid-kernel-and-c-100-0" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate classifier with sigmoid kernel and C=100.0</span>
<span class="n">sigmoid_svc100</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">100.0</span><span class="p">)</span> 


<span class="c1"># fit classifier to training set</span>
<span class="n">sigmoid_svc100</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>


<span class="c1"># make predictions on test set</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">sigmoid_svc100</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="c1"># compute and print accuracy score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model accuracy score with sigmoid kernel and C=100.0 : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model accuracy score with sigmoid kernel and C=100.0 : 0.8855
</pre></div>
</div>
</div>
</div>
<p>We can see that sigmoid kernel is also performing poorly just like with polynomial kernel.</p>
</section>
<section id="comments">
<h3><span class="section-number">40.59.16.3. </span>Comments<a class="headerlink" href="#comments" title="Permalink to this headline">#</a></h3>
<p>We get maximum accuracy with <code class="docutils literal notranslate"><span class="pre">rbf</span></code> and <code class="docutils literal notranslate"><span class="pre">linear</span></code> kernel with C=100.0. and the accuracy is 0.9832. Based on the above analysis we can conclude that our classification model accuracy is very good. Our model is doing a very good job in terms of predicting the class labels.</p>
<p>But, this is not true. Here, we have an imbalanced dataset. The problem is that accuracy is an inadequate measure for quantifying predictive performance in the imbalanced dataset problem.</p>
<p>So, we must explore alternative metrices that provide better guidance in selecting models. In particular, we would like to know the underlying distribution of values and the type of errors our classifer is making.</p>
<p>One such metric to analyze the model performance in imbalanced classes problem is <code class="docutils literal notranslate"><span class="pre">Confusion</span> <span class="pre">matrix</span></code>.</p>
</section>
</section>
<section id="confusion-matrix">
<h2><span class="section-number">40.59.17. </span>Confusion matrix<a class="headerlink" href="#confusion-matrix" title="Permalink to this headline">#</a></h2>
<p>A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.</p>
<p>Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-</p>
<p><strong>True Positives (TP)</strong> ‚Äì True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.</p>
<p><strong>True Negatives (TN)</strong> ‚Äì True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.</p>
<p><strong>False Positives (FP)</strong> ‚Äì False Positives occur when we predict an observation belongs to a    certain class but the observation actually does not belong to that class. This type of error is called <strong>Type I error.</strong></p>
<p><strong>False Negatives (FN)</strong> ‚Äì False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called <strong>Type II error.</strong></p>
<p>These four outcomes are summarized in a confusion matrix given below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print the Confusion Matrix and slice it into four pieces</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Confusion matrix</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">cm</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">True Positives(TP) = &#39;</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">True Negatives(TN) = &#39;</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">False Positives(FP) = &#39;</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">False Negatives(FN) = &#39;</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Confusion matrix

 [[3289   17]
 [  44  230]]

True Positives(TP) =  3289

True Negatives(TN) =  230

False Positives(FP) =  17

False Negatives(FN) =  44
</pre></div>
</div>
</div>
</div>
<p>The confusion matrix shows <code class="docutils literal notranslate"><span class="pre">3289</span> <span class="pre">+</span> <span class="pre">230</span> <span class="pre">=</span> <span class="pre">3519</span> <span class="pre">correct</span> <span class="pre">predictions</span></code> and <code class="docutils literal notranslate"><span class="pre">17</span> <span class="pre">+</span> <span class="pre">44</span> <span class="pre">=</span> <span class="pre">61</span> <span class="pre">incorrect</span> <span class="pre">predictions</span></code>.</p>
<p>In this case, we have</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span> <span class="pre">Positives</span></code> (Actual Positive:1 and Predict Positive:1) - 3289</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">True</span> <span class="pre">Negatives</span></code> (Actual Negative:0 and Predict Negative:0) - 230</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span> <span class="pre">Positives</span></code> (Actual Negative:0 but Predict Positive:1) - 17 <code class="docutils literal notranslate"><span class="pre">(Type</span> <span class="pre">I</span> <span class="pre">error)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span> <span class="pre">Negatives</span></code> (Actual Positive:1 but Predict Negative:0) - 44 <code class="docutils literal notranslate"><span class="pre">(Type</span> <span class="pre">II</span> <span class="pre">error)</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># visualize confusion matrix with seaborn heatmap</span>

<span class="n">cm_matrix</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">cm</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Actual Positive:1&#39;</span><span class="p">,</span> <span class="s1">&#39;Actual Negative:0&#39;</span><span class="p">],</span> 
                                 <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Predict Positive:1&#39;</span><span class="p">,</span> <span class="s1">&#39;Predict Negative:0&#39;</span><span class="p">])</span>

<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;YlGnBu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot: &gt;
</pre></div>
</div>
<img alt="../../../_images/kernel-method-assignment-1_103_1.png" src="../../../_images/kernel-method-assignment-1_103_1.png" />
</div>
</div>
</section>
<section id="classification-metrices">
<h2><span class="section-number">40.59.18. </span>Classification metrices<a class="headerlink" href="#classification-metrices" title="Permalink to this headline">#</a></h2>
<section id="classification-report">
<h3><span class="section-number">40.59.18.1. </span>Classification Report<a class="headerlink" href="#classification-report" title="Permalink to this headline">#</a></h3>
<p><strong>Classification report</strong> is another way to evaluate the classification model performance. It displays the  <strong>precision</strong>, <strong>recall</strong>, <strong>f1</strong> and <strong>support</strong> scores for the model. I have described these terms in later.</p>
<p>We can print a classification report as follows:-</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.99      0.99      0.99      3306
           1       0.93      0.84      0.88       274

    accuracy                           0.98      3580
   macro avg       0.96      0.92      0.94      3580
weighted avg       0.98      0.98      0.98      3580
</pre></div>
</div>
</div>
</div>
</section>
<section id="classification-accuracy">
<h3><span class="section-number">40.59.18.2. </span>Classification accuracy<a class="headerlink" href="#classification-accuracy" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TP</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">FN</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print classification accuracy</span>

<span class="n">classification_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Classification accuracy : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">classification_accuracy</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Classification accuracy : 0.9830
</pre></div>
</div>
</div>
</div>
</section>
<section id="classification-error">
<h3><span class="section-number">40.59.18.3. </span>Classification error<a class="headerlink" href="#classification-error" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print classification error</span>

<span class="n">classification_error</span> <span class="o">=</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Classification error : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">classification_error</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Classification error : 0.0170
</pre></div>
</div>
</div>
</div>
</section>
<section id="precision">
<h3><span class="section-number">40.59.18.4. </span>Precision<a class="headerlink" href="#precision" title="Permalink to this headline">#</a></h3>
<p><strong>Precision</strong> can be defined as the percentage of correctly predicted positive outcomes out of all the predicted positive outcomes. It can be given as the ratio of true positives (TP) to the sum of true and false positives (TP + FP).</p>
<p>So, <strong>Precision</strong> identifies the proportion of correctly predicted positive outcome. It is more concerned with the positive class than the negative class.</p>
<p>Mathematically, precision can be defined as the ratio of <code class="docutils literal notranslate"><span class="pre">TP</span> <span class="pre">to</span> <span class="pre">(TP</span> <span class="pre">+</span> <span class="pre">FP)</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print precision score</span>

<span class="n">precision</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Precision : 0.9949
</pre></div>
</div>
</div>
</div>
</section>
<section id="recall">
<h3><span class="section-number">40.59.18.5. </span>Recall<a class="headerlink" href="#recall" title="Permalink to this headline">#</a></h3>
<p>Recall can be defined as the percentage of correctly predicted positive outcomes out of all the actual positive outcomes.
It can be given as the ratio of true positives (TP) to the sum of true positives and false negatives (TP + FN). <strong>Recall</strong> is also called <strong>Sensitivity</strong>.</p>
<p><strong>Recall</strong> identifies the proportion of correctly predicted actual positives.</p>
<p>Mathematically, <strong>recall</strong> can be defined as the ratio of <code class="docutils literal notranslate"><span class="pre">TP</span> <span class="pre">to</span> <span class="pre">(TP</span> <span class="pre">+</span> <span class="pre">FN)</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">recall</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Recall or Sensitivity : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">recall</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Recall or Sensitivity : 0.9868
</pre></div>
</div>
</div>
</div>
</section>
<section id="true-positive-rate">
<h3><span class="section-number">40.59.18.6. </span>True Positive Rate<a class="headerlink" href="#true-positive-rate" title="Permalink to this headline">#</a></h3>
<p><strong>True Positive Rate</strong> is synonymous with <strong>Recall</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">true_positive_rate</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;True Positive Rate : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">true_positive_rate</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True Positive Rate : 0.9868
</pre></div>
</div>
</div>
</div>
</section>
<section id="false-positive-rate">
<h3><span class="section-number">40.59.18.7. </span>False Positive Rate<a class="headerlink" href="#false-positive-rate" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">false_positive_rate</span> <span class="o">=</span> <span class="n">FP</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;False Positive Rate : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>False Positive Rate : 0.0688
</pre></div>
</div>
</div>
</div>
</section>
<section id="specificity">
<h3><span class="section-number">40.59.18.8. </span>Specificity<a class="headerlink" href="#specificity" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">specificity</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Specificity : </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">specificity</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Specificity : 0.9312
</pre></div>
</div>
</div>
</div>
</section>
<section id="f1-score">
<h3><span class="section-number">40.59.18.9. </span>f1-score<a class="headerlink" href="#f1-score" title="Permalink to this headline">#</a></h3>
<p><strong>f1-score</strong> is the weighted harmonic mean of precision and recall. The best possible <strong>f1-score</strong> would be 1.0 and the worst
would be 0.0.  <strong>f1-score</strong> is the harmonic mean of precision and recall. So, <strong>f1-score</strong> is always lower than accuracy measures as they embed precision and recall into their computation. The weighted average of <code class="docutils literal notranslate"><span class="pre">f1-score</span></code> should be used to
compare classifier models, not global accuracy.</p>
</section>
<section id="support">
<h3><span class="section-number">40.59.18.10. </span>Support<a class="headerlink" href="#support" title="Permalink to this headline">#</a></h3>
<p><strong>Support</strong> is the actual number of occurrences of the class in our dataset.</p>
</section>
</section>
<section id="roc-auc">
<h2><span class="section-number">40.59.19. </span>ROC - AUC<a class="headerlink" href="#roc-auc" title="Permalink to this headline">#</a></h2>
<section id="roc-curve">
<h3><span class="section-number">40.59.19.1. </span>ROC Curve<a class="headerlink" href="#roc-curve" title="Permalink to this headline">#</a></h3>
<p>Another tool to measure the classification model performance visually is <strong>ROC Curve</strong>. ROC Curve stands for <strong>Receiver Operating Characteristic Curve</strong>. An <strong>ROC Curve</strong> is a plot which shows the performance of a classification model at various
classification threshold levels.</p>
<p>The <strong>ROC Curve</strong> plots the <strong>True Positive Rate (TPR)</strong> against the <strong>False Positive Rate (FPR)</strong> at various threshold levels.</p>
<p><strong>True Positive Rate (TPR)</strong> is also called <strong>Recall</strong>. It is defined as the ratio of <code class="docutils literal notranslate"><span class="pre">TP</span> <span class="pre">to</span> <span class="pre">(TP</span> <span class="pre">+</span> <span class="pre">FN)</span></code>.</p>
<p><strong>False Positive Rate (FPR)</strong> is defined as the ratio of <code class="docutils literal notranslate"><span class="pre">FP</span> <span class="pre">to</span> <span class="pre">(FP</span> <span class="pre">+</span> <span class="pre">TN)</span></code>.</p>
<p>In the ROC Curve, we will focus on the TPR (True Positive Rate) and FPR (False Positive Rate) of a single point. This will give us the general performance of the ROC curve which consists of the TPR and FPR at various threshold levels. So, an ROC Curve plots TPR vs FPR at different classification threshold levels. If we lower the threshold levels, it may result in more items being classified as positve. It will increase both True Positives (TP) and False Positives (FP).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot ROC Curve</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span> <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;ROC curve for Predicting a Pulsar Star classifier&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate (1 - Specificity)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate (Sensitivity)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/kernel-method-assignment-1_125_0.png" src="../../../_images/kernel-method-assignment-1_125_0.png" />
</div>
</div>
<p>ROC curve help us to choose a threshold level that balances sensitivity and specificity for a particular context.</p>
</section>
<section id="id4">
<h3><span class="section-number">40.59.19.2. </span>ROC  AUC<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h3>
<p><strong>ROC AUC</strong> stands for <strong>Receiver Operating Characteristic - Area Under Curve</strong>. It is a technique to compare classifier performance. In this technique, we measure the <code class="docutils literal notranslate"><span class="pre">area</span> <span class="pre">under</span> <span class="pre">the</span> <span class="pre">curve</span> <span class="pre">(AUC)</span></code>. A perfect classifier will have a ROC AUC equal to 1, whereas a purely random classifier will have a ROC AUC equal to 0.5.</p>
<p>So, <strong>ROC AUC</strong> is the percentage of the ROC plot that is underneath the curve.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute ROC AUC</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>

<span class="n">ROC_AUC</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;ROC AUC : </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ROC_AUC</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ROC AUC : 0.9171
</pre></div>
</div>
</div>
</div>
</section>
<section id="id5">
<h3><span class="section-number">40.59.19.3. </span>Comments<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>ROC AUC is a single number summary of classifier performance. The higher the value, the better the classifier.</p></li>
<li><p>ROC AUC of our model approaches towards 1. So, we can conclude that our classifier does a good job in classifying the pulsar star.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate cross-validated ROC AUC </span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">Cross_validated_ROC_AUC</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_svc</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Cross validated ROC AUC : </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">Cross_validated_ROC_AUC</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross validated ROC AUC : 0.9756
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="stratified-k-fold-cross-validation-with-shuffle-split">
<h2><span class="section-number">40.59.20. </span>Stratified k-fold Cross Validation with shuffle split<a class="headerlink" href="#stratified-k-fold-cross-validation-with-shuffle-split" title="Permalink to this headline">#</a></h2>
<p>k-fold cross-validation is a very useful technique to evaluate model performance. But, it fails here because we have a imbalnced dataset. So, in the case of imbalanced dataset, I will use another technique to evaluate model performance. It is called <code class="docutils literal notranslate"><span class="pre">stratified</span> <span class="pre">k-fold</span> <span class="pre">cross-validation</span></code>.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">stratified</span> <span class="pre">k-fold</span> <span class="pre">cross-validation</span></code>, we split the data such that the proportions between classes are the same in each fold as they are in the whole dataset.</p>
<p>Moreover, I will shuffle the data before splitting because shuffling yields much better result.</p>
<section id="stratified-k-fold-cross-validation-with-shuffle-split-with-linear-kernel">
<h3><span class="section-number">40.59.20.1. </span>Stratified k-Fold Cross Validation with shuffle split with  linear kernel<a class="headerlink" href="#stratified-k-fold-cross-validation-with-shuffle-split-with-linear-kernel" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>


<span class="n">kfold</span><span class="o">=</span><span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="n">linear_svc</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>


<span class="n">linear_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_svc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print cross-validation scores with linear kernel</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Stratified cross-validation scores with linear kernel:</span><span class="se">\n\n</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">linear_scores</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Stratified cross-validation scores with linear kernel:

[0.98296089 0.97458101 0.97988827 0.97876502 0.97848561]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print average cross-validation score with linear kernel</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average stratified cross-validation score with linear kernel:</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">linear_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average stratified cross-validation score with linear kernel:0.9789
</pre></div>
</div>
</div>
</div>
</section>
<section id="stratified-k-fold-cross-validation-with-shuffle-split-with-rbf-kernel">
<h3><span class="section-number">40.59.20.2. </span>Stratified k-Fold Cross Validation with shuffle split with rbf kernel<a class="headerlink" href="#stratified-k-fold-cross-validation-with-shuffle-split-with-rbf-kernel" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rbf_svc</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">)</span>


<span class="n">rbf_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rbf_svc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print cross-validation scores with rbf kernel</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Stratified Cross-validation scores with rbf kernel:</span><span class="se">\n\n</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rbf_scores</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Stratified Cross-validation scores with rbf kernel:

[0.97849162 0.97011173 0.97318436 0.9709416  0.96982397]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print average cross-validation score with rbf kernel</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average stratified cross-validation score with rbf kernel:</span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rbf_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average stratified cross-validation score with rbf kernel:0.9725
</pre></div>
</div>
</div>
</div>
</section>
<section id="id6">
<h3><span class="section-number">40.59.20.3. </span>Comments<a class="headerlink" href="#id6" title="Permalink to this headline">#</a></h3>
<p>I obtain higher average stratified k-fold cross-validation score of 0.9789 with linear kernel but the model accuracy is 0.9832.
So, stratified cross-validation technique does not help to improve the model performance.</p>
</section>
</section>
<section id="hyperparameter-optimization-using-gridsearch-cv">
<h2><span class="section-number">40.59.21. </span>Hyperparameter Optimization using GridSearch CV<a class="headerlink" href="#hyperparameter-optimization-using-gridsearch-cv" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>


<span class="c1"># import SVC classifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>


<span class="c1"># instantiate classifier with default hyperparameters with kernel=rbf, C=1.0 and gamma=auto</span>
<span class="n">svc</span><span class="o">=</span><span class="n">SVC</span><span class="p">()</span> 



<span class="c1"># declare parameters for hyperparameter tuning</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">[</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="s1">&#39;kernel&#39;</span><span class="p">:[</span><span class="s1">&#39;linear&#39;</span><span class="p">]},</span>
               <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="s1">&#39;kernel&#39;</span><span class="p">:[</span><span class="s1">&#39;rbf&#39;</span><span class="p">],</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]},</span>
               <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="s1">&#39;kernel&#39;</span><span class="p">:[</span><span class="s1">&#39;poly&#39;</span><span class="p">],</span> <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span> <span class="p">,</span><span class="s1">&#39;gamma&#39;</span><span class="p">:[</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.02</span><span class="p">,</span><span class="mf">0.03</span><span class="p">,</span><span class="mf">0.04</span><span class="p">,</span><span class="mf">0.05</span><span class="p">]}</span> 
              <span class="p">]</span>




<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">svc</span><span class="p">,</span>  
                           <span class="n">param_grid</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">,</span>
                           <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span>
                           <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                           <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># examine the best model</span>


<span class="c1"># best score achieved during the GridSearchCV</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;GridSearch CV best score : </span><span class="si">{:.4f}</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>


<span class="c1"># print parameters that give the best results</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Parameters that give the best results :&#39;</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>


<span class="c1"># print estimator that was chosen by the GridSearch</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">Estimator that was chosen by the search :&#39;</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate GridSearch CV score on test set</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;GridSearch CV score on test set: </span><span class="si">{0:0.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<section id="id7">
<h3><span class="section-number">40.59.21.1. </span>Comments<a class="headerlink" href="#id7" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Our original model test accuracy is 0.9832 while GridSearch CV score on test-set is 0.9835.</p></li>
<li><p>So, GridSearch CV helps to identify the parameters that will improve the performance for this particular model.</p></li>
<li><p>Here, we should not confuse <code class="docutils literal notranslate"><span class="pre">best_score_</span></code> attribute of <code class="docutils literal notranslate"><span class="pre">grid_search</span></code> with the <code class="docutils literal notranslate"><span class="pre">score</span></code> method on the test-set.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">score</span></code> method on the test-set gives the generalization performance of the model. Using the <code class="docutils literal notranslate"><span class="pre">score</span></code> method, we employ a model trained on the whole training set.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">best_score_</span></code> attribute gives the mean cross-validation accuracy, with cross-validation performed on the training set.</p></li>
</ul>
</section>
</section>
<section id="results-and-conclusion">
<h2><span class="section-number">40.59.22. </span>Results and conclusion<a class="headerlink" href="#results-and-conclusion" title="Permalink to this headline">#</a></h2>
<ol class="simple">
<li><p>There are outliers in our dataset. So, as we increase the value of C to limit fewer outliers, the accuracy increased. This is true with different kinds of kernels.</p></li>
<li><p>We get maximum accuracy with <code class="docutils literal notranslate"><span class="pre">rbf</span></code> and <code class="docutils literal notranslate"><span class="pre">linear</span></code> kernel with C=100.0 and the accuracy is 0.9832. So, we can conclude that our model is doing a very good job in terms of predicting the class labels. But, this is not true. Here, we have an imbalanced dataset. Accuracy is an inadequate measure for quantifying predictive performance in the imbalanced dataset problem. So, we must explore <code class="docutils literal notranslate"><span class="pre">confusion</span> <span class="pre">matrix</span></code> that provide better guidance in selecting models.</p></li>
<li><p>ROC AUC of our model is very close to 1. So, we can conclude that our classifier does a good job in classifying the pulsar star.</p></li>
<li><p>We obtain higher average stratified k-fold cross-validation score of 0.9789 with linear kernel but the model accuracy is 0.9832. So, stratified cross-validation technique does not help to improve the model performance.</p></li>
<li><p>Our original model test accuracy is 0.9832 while GridSearch CV score on test-set is 0.9835. So, GridSearch CV helps to identify the parameters that will improve the performance for this particular model.</p></li>
</ol>
</section>
<section id="acknowledgments">
<h2><span class="section-number">40.59.23. </span>Acknowledgments<a class="headerlink" href="#acknowledgments" title="Permalink to this headline">#</a></h2>
<p>Thanks to PRASHANT BANERJEE for creating the open-source course <a class="reference external" href="https://www.kaggle.com/code/prashant111/svm-classifier-tutorial"> SVM Classifier Tutorial </a>. It inspires the majority of the content in this chapter.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ocademy-ai/machine-learning",
            ref: "release",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./assignments/ml-advanced/kernel-method"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../../ml-fundamentals/explore-classification-methods.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">40.58. </span>Explore classification methods</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="support_vector_machines_for_regression.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">40.60. </span>Support Vector Machines (SVM) - Intro and SVM for Regression</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ocademy<br/>
  
      &copy; Copyright 2022-2023.<br/>
    <div class="extra_footer">
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> Text content of this work is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>