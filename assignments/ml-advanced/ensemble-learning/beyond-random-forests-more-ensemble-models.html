
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>38.71. Beyond random forests: more ensemble models &#8212; Ocademy Open Machine Learning Book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/drawio.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/youtube.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "ocademy-ai/machine-learning-utterances");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "üí¨ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"></script>
    <script>quizdown.init({"quizdown_js": "https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"});</script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="38.72. Decision trees" href="decision-trees.html" />
    <link rel="prev" title="38.70. Random forests for classification" href="random-forests-for-classification.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint">Learn AI together, for free! At <a color='lightblue' href='https://ocademy.cc'><u style='color:lightblue;'>Ocademy</u></a>.</div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo-long.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Ocademy Open Machine Learning Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PREREQUISITES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-introduction.html">
   1. Python programming introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-basics.html">
   2. Python programming basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../prerequisites/python-programming-advanced.html">
   3. Python programming advanced
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATA SCIENCE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/introduction/introduction.html">
   4. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/defining-data-science.html">
     4.1. Defining data science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/data-science-ethics.html">
     4.2. Data Science ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/defining-data.html">
     4.3. Defining data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/introduction/introduction-to-statistics-and-probability.html">
     4.4. Introduction to statistics and probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/working-with-data/working-with-data.html">
   5. Working with data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/relational-databases.html">
     5.1. Relational databases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/non-relational-data.html">
     5.2. Non-relational data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/numpy.html">
     5.3. NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/pandas.html">
     5.4. Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/working-with-data/data-preparation.html">
     5.5. Data preparation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-visualization/data-visualization.html">
   6. Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-distributions.html">
     6.1. Visualizing distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-proportions.html">
     6.2. Visualizing proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/visualization-relationships.html">
     6.3. Visualizing relationships: all about honey üçØ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-visualization/meaningful-visualizations.html">
     6.4. Making meaningful visualizations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-science-lifecycle/data-science-lifecycle.html">
   7. Data Science lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/introduction.html">
     7.1. Introduction to the Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/analyzing.html">
     7.2. Analyzing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-lifecycle/communication.html">
     7.3. Communication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/data-science-in-the-cloud.html">
   8. Data Science in the cloud
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/introduction.html">
     8.1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/the-low-code-no-code-way.html">
     8.2. The ‚Äúlow code/no code‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../data-science/data-science-in-the-cloud/the-azure-ml-sdk-way.html">
     8.3. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../data-science/data-science-in-the-wild.html">
   9. Data Science in the real world
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING BASICS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-fundamentals/ml-overview.html">
   10. Machine Learning overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/regression/regression-models-for-machine-learning.html">
   11. Regression models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/tools-of-the-trade.html">
     11.1. Tools of the trade
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/managing-data.html">
     11.2. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/linear-and-polynomial-regression.html">
     11.3. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/loss-function.html">
     11.4. Stock Market Prediction Hands-On: Training a Linear Regression Model (1/6)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/regression/logistic-regression.html">
     11.10. Logistic regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-fundamentals/build-a-web-app-to-use-a-machine-learning-model.html">
   12. Build a web app to use a Machine Learning model
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-fundamentals/classification/getting-started-with-classification.html">
   13. Getting started with classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/introduction-to-classification.html">
     13.1. Introduction to classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/more-classifiers.html">
     13.2. More classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/yet-other-classifiers.html">
     13.3. Yet other classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-fundamentals/classification/applied-ml-build-a-web-app.html">
     13.4. Applied Machine Learning : build a web app
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ADVANCED MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/clustering/clustering-models-for-machine-learning.html">
   14. Clustering models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/clustering/introduction-to-clustering.html">
     14.1. Introduction to clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/clustering/k-means-clustering.html">
     14.2. K-Means clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/ensemble-learning/getting-started-with-ensemble-learning.html">
   15. Getting started with ensemble learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/bagging.html">
     15.1. Bagging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/random-forest.html">
     15.2. Random forest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/ensemble-learning/feature-importance.html">
     15.3. Feature importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-advanced/gradient-boosting/introduction-to-gradient-boosting.html">
   16. Introduction to Gradient Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/gradient-boosting.html">
     16.1. Gradient Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/gradient-boosting-example.html">
     16.2. Gradient boosting example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/xgboost.html">
     16.3. XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-advanced/gradient-boosting/xgboost-k-fold-cv-feature-importance.html">
     16.4. XGBoost + k-fold CV + Feature Importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/unsupervised-learning.html">
   17. Unsupervised learning (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/kernel-method.html">
   18. Kernel method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ml-advanced/model-selection.html">
   19. Model selection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dl-overview.html">
   20. Deep learning overview (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/cnn.html">
   21. Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/gan.html">
   22. Generative adversarial networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/rnn.html">
   23. Recurrent Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/autoencoder.html">
   24. Autoencoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/lstm.html">
   25. Long-short term memory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/time-series.html">
   26. Time series
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dqn.html">
   27. Deep Q-learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/dl-summary.html">
   28. Summary of deep learning (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/image-classification.html">
   29. Image classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/image-segmentation.html">
   30. Image segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/difussion-model.html">
   31. Diffusion Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../deep-learning/object-detection.html">
   32. Object detection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING OPERATIONS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/overview.html">
   33. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/problem-framing.html">
   34. Problem framing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/data-engineering.html">
   35. Data engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/model-training-and-evaluation.html">
   36. Model training &amp; evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../machine-learning-productionization/model-deployment.html">
   37. Model deployment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OTHERS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../README.html">
   38. Self-paced assignments
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../../set-up-env/first-assignment.html">
     38.3. First assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../set-up-env/second-assignment.html">
     38.4. Second assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../project-plan-template.html">
     38.5. Project Plan‚Äã Template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-introduction.html">
     38.6. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-basics.html">
     38.7. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prerequisites/python-programming-advanced.html">
     38.8. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-text-about-data-science.html">
     38.9. Analyzing text about Data Science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-scenarios.html">
     38.10. Data Science scenarios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/write-a-data-ethics-case-study.html">
     38.11. Write a data ethics case study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/lines-scatters-and-bars.html">
     38.12. Lines, scatters and bars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/apply-your-skills.html">
     38.13. Apply your skills
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/try-it-in-excel.html">
     38.14. Try it in Excel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/dive-into-the-beehive.html">
     38.15. Dive into the beehive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/build-your-own-custom-vis.html">
     38.16. Build your own custom vis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/classifying-datasets.html">
     38.17. Classifying datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/small-diabetes-study.html">
     38.18. Small diabetes study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction-to-statistics-and-probability.html">
     38.19. Introduction to probability and statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/displaying-airport-data.html">
     38.20. Displaying airport data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/soda-profits.html">
     38.21. Soda profits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-COVID-19-papers.html">
     38.22. Analyzing COVID-19 papers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/estimation-of-COVID-19-pandemic.html">
     38.23. Estimation of COVID-19 pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-processing-in-python.html">
     38.24. Data processing in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/evaluating-data-from-a-form.html">
     38.25. Evaluating data from a form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-preparation.html">
     38.26. Data preparation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/analyzing-data.html">
     38.27. Analyzing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/nyc-taxi-data-in-winter-and-summer.html">
     38.28. NYC taxi data in winter and summer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/matplotlib-applied.html">
     38.29. Matplotlib applied
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/tell-a-story.html">
     38.35. Tell a story
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/explore-a-planetary-computer-dataset.html">
     38.36. Explore a planetary computer dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/exploring-for-anwser.html">
     38.37. Exploring for answers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/market-research.html">
     38.38. Market research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/low-code-no-code-data-science-project-on-azure-ml.html">
     38.39. Low code/no code Data Science project on Azure ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-project-using-azure-ml-sdk.html">
     38.40. Data Science project using Azure ML SDK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-in-the-cloud-the-azure-ml-sdk-way.html">
     38.41. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-overview-iris.html">
     38.42. Machine Learning overview - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-overview-mnist-digits.html">
     38.43. Machine Learning overview - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression-with-scikit-learn.html">
     38.44. Regression with Scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-linear-regression-1.html">
     38.45. ML linear regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-linear-regression-2.html">
     38.46. ML linear regression - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-logistic-regression-1.html">
     38.47. ML logistic regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/ml-neural-network-1.html">
     38.48. ML neural network - Assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression-tools.html">
     38.49. Regression tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/managing-data.html">
     38.50. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/exploring-visualizations.html">
     38.51. Exploring visualizations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/try-a-different-model.html">
     38.52. Try a different model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/create-a-regression-model.html">
     38.53. Create a regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/linear-and-polynomial-regression.html">
     38.54. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/retrying-some-regression.html">
     38.55. Retrying some regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/pumpkin-varieties-and-color.html">
     38.56. Pumpkin varieties and color
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/delicious-asian-and-indian-cuisines.html">
     38.57. Delicious asian and indian cuisines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/explore-classification-methods.html">
     38.58. Explore classification methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../kernel-method/kernel-method-assignment-1.html">
     38.59. Kernel method assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../kernel-method/support_vector_machines_for_regression.html">
     38.60. Support Vector Machines (SVM) - Intro and SVM for Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../kernel-method/support_vector_machines_for_classification.html">
     38.61. Support Vector Machines (SVM) - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../kernel-method/decision_trees_for_regression.html">
     38.62. Decision Trees - Intro and Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../kernel-method/decision_trees_for_classification.html">
     38.63. Decision Trees - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../model-selection/model-selection-assignment-1.html">
     38.64. Model selection assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../model-selection/learning-curve-to-identify-overfit-underfit.html">
     38.65. Learning Curve To Identify Overfit &amp; Underfit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../model-selection/dropout-and-batch-normalization.html">
     38.66. Dropout and Batch Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../model-selection/lasso-and-ridge-regression.html">
     38.67. Lasso and Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../model-selection/regularized-linear-models.html">
     38.68. Regularized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="random-forests-intro-and-regression.html">
     38.69. Random forests intro and regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="random-forests-for-classification.html">
     38.70. Random forests for classification
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     38.71. Beyond random forests: more ensemble models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decision-trees.html">
     38.72. Decision trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../gradient-boosting/hyperparameter-tuning-gradient-boosting.html">
     38.73. Hyperparameter tuning gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../gradient-boosting/gradient-boosting-assignment.html">
     38.74. Gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../gradient-boosting/boosting-with-tuning.html">
     38.75. Boosting with tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="random-forest-classifier-feature-importance.html">
     38.76. Random Forest Classifier with Feature Importance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/data-engineering.html">
     38.78. Data engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/counterintuitive-challenges-in-ml-debugging.html">
     38.79. Counterintuitive Challenges in ML Debugging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/debugging-in-classification.html">
     38.80. Case Study: Debugging in Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine-learning-productionization/debugging-in-regression.html">
     38.81. Case Study: Debugging in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/study-the-solvers.html">
     38.82. Study the solvers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/build-classification-models.html">
     38.83. Build classification models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/build-classification-model.html">
     38.84. Build Classification Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/parameter-play.html">
     38.85. Parameter play
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/how-to-choose-cnn-architecture-mnist.html">
     38.86. How to choose cnn architecture mnist
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/sign-language-digits-classification-with-cnn.html">
     38.88. Sign Language Digits Classification with CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/object-recognition-in-images-using-cnn.html">
     38.90. Object Recognition in Images using CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/tensorflow/intro_to_tensorflow_for_deeplearning.html">
     38.91. Intro to TensorFlow for Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/lstm/bitcoin-lstm-model-with-tweet-volume-and-sentiment.html">
     38.93. Bitcoin LSTM Model with Tweet Volume and Sentiment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/rnn/google-stock-price-prediction-rnn.html">
     38.95. Google Stock Price Prediction RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/autoencoder.html">
     38.97. Intro to Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/base-denoising-autoencoder-dimension-reduction.html">
     38.98. Base/Denoising Autoencoder &amp; Dimension Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/autoencoder/variational-autoencoder-and-faces-generation.html">
     38.99. Fun with Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/time-series-forecasting-assignment.html">
     38.100. Time Series Forecasting Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nn-for-classification-assignment.html">
     38.102. Neural Networks for Classification with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nn-classify-15-fruits-assignment.html">
     38.103. NN Classify 15 Fruits Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/dqn/dqn-on-foreign-exchange-market.html">
     38.108. DQN On Foreign Exchange Market
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/gan/art-by-gan.html">
     38.109. Art by gan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/gan/gan-introduction.html">
     38.111. Generative Adversarial Networks (GANs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/overview/basic-classification-classify-images-of-clothing.html">
     38.112. Basic classification: Classify images of clothing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../slides/introduction.html">
   39. Slides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-introduction.html">
     39.1. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-basics.html">
     39.2. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/python-programming/python-programming-advanced.html">
     39.3. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-introduction.html">
     39.4. Data Science introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/relational-vs-non-relational-database.html">
     39.5. Relational vs. non-relational database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/numpy-and-pandas.html">
     39.6. NumPy and Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-visualization.html">
     39.7. Data visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-lifecycle.html">
     39.8. Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-in-the-cloud.html">
     39.9. Data Science in the cloud
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/data-science/data-science-in-real-world.html">
     39.10. Data Science in real world
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/ml-overview.html">
     39.11. Machine Learning overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/linear-regression.html">
     39.12. Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/logistic-regression.html">
     39.13. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/neural-network.html">
     39.14. Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-fundamentals/build-an-ml-web-app.html">
     39.15. Build an machine learning web application
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/unsupervised-learning.html">
     39.16. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/kernel-method.html">
     39.17. Kernel method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/ml-advanced/model-selection.html">
     39.18. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/deep-learning/cnn.html">
     39.19. Convolutional Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../slides/deep-learning/gan.html">
     39.20. Generative Adversarial Network
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ocademy-ai/machine-learning/release?urlpath=lab/tree/open-machine-learning-jupyter-book/assignments/ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ocademy-ai/machine-learning/blob/release/open-machine-learning-jupyter-book/assignments/ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning//issues/new?title=Issue%20on%20page%20%2Fassignments/ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/edit/release/open-machine-learning-jupyter-book/assignments/ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/assignments/ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ensemble-methods-for-classification">
   38.71.1. Ensemble methods for classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   38.71.2. Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loading-the-data">
   38.71.3. Loading the data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tasks-and-roles">
   38.71.4. Tasks and roles
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-1-exploratory-data-analysis">
     38.71.4.1. Task 1: Exploratory data analysis
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-2-more-data-exploration">
     38.71.4.2. Task 2: More data exploration
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-3-data-preprocessing">
     38.71.4.3. Task 3: Data preprocessing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-4-training-ensemble-classifiers">
     38.71.4.4. Task 4: Training ensemble classifiers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#voting-classifier">
       38.71.4.4.1. 4.1: Voting classifier
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bagging-classifier">
       38.71.4.4.2. 4.2: Bagging classifier
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-boosting-classifier">
       38.71.4.4.3. 4.3: Gradient boosting classifier
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adaboost-classifier">
       38.71.4.4.4. 4.4: AdaBoost classifier
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stacking-classifier">
       38.71.4.4.5. 4.5: Stacking classifier
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-5-evaluating-the-ensemble-model-on-the-test-set">
     38.71.4.5. Task 5: Evaluating the ensemble model on the test set
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#final-note">
   38.71.5. Final note
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   38.71.6. Acknowledgments
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Beyond random forests: more ensemble models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ensemble-methods-for-classification">
   38.71.1. Ensemble methods for classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   38.71.2. Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loading-the-data">
   38.71.3. Loading the data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tasks-and-roles">
   38.71.4. Tasks and roles
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-1-exploratory-data-analysis">
     38.71.4.1. Task 1: Exploratory data analysis
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-2-more-data-exploration">
     38.71.4.2. Task 2: More data exploration
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-3-data-preprocessing">
     38.71.4.3. Task 3: Data preprocessing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-4-training-ensemble-classifiers">
     38.71.4.4. Task 4: Training ensemble classifiers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#voting-classifier">
       38.71.4.4.1. 4.1: Voting classifier
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bagging-classifier">
       38.71.4.4.2. 4.2: Bagging classifier
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-boosting-classifier">
       38.71.4.4.3. 4.3: Gradient boosting classifier
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adaboost-classifier">
       38.71.4.4.4. 4.4: AdaBoost classifier
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stacking-classifier">
       38.71.4.4.5. 4.5: Stacking classifier
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-5-evaluating-the-ensemble-model-on-the-test-set">
     38.71.4.5. Task 5: Evaluating the ensemble model on the test set
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#final-note">
   38.71.5. Final note
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   38.71.6. Acknowledgments
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="beyond-random-forests-more-ensemble-models">
<h1><span class="section-number">38.71. </span>Beyond random forests: more ensemble models<a class="headerlink" href="#beyond-random-forests-more-ensemble-models" title="Permalink to this headline">#</a></h1>
<p>Ensembles are the combination of different machine learning models, where by averaging the results of all models trained together on the same dataset, the result can be away good than any individual model. These types of models can be used for all kinds of tasks, including classification, regression and detecting anomalies.</p>
<p>In his book <em><a class="reference external" href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Hands-On Machine Learning with Scikit-Learn, Keras and TensorFlow</a></em>, <em>Aurelion Geron</em> gave a perfect analogy describing the ensemble learning: ‚ÄúSuppose you pose a complex question to thousands of random people, then aggregate their answers. In many cases you will find that this aggregated answer is better than an expert‚Äôs answer. This is called the <em>wisdom of the crowd</em>. Similarly, if you aggregate the predictions of a group of predictors (such as classifiers or regressors), you will often get better predictions than with the best individual predictor. A group of predictors is called an ensemble; thus, this technique is called Ensemble Learning, and an Ensemble Learning algorithm is called an Ensemble method.‚Äù</p>
<p>Random Forests that was used in the previous assignment is an example of ensemble models. It combined different decision trees. Usually, these types of models are classified into three groups that will be covered in this assignment:</p>
<ul class="simple">
<li><p>Averaging Methods: Such as voting classifiers/regressors, bagging classifiers/regressors, random forests, extra trees classifier/regressor, etc‚Ä¶</p></li>
<li><p>Boosting Methods: Gradient Boosting, AdaBoost, XGBoost</p></li>
<li><p>Stacking in which instead of averaging the results of multiple models, multiple models are trained on the full training set and there is a final model trained on the different subsets (folds) of the training set.</p></li>
</ul>
<p>Most of the above algorithms are implemented in Sklearn, except XGBoost and Stacking which is implemented indirectly.</p>
<p>Like said in the beginning, these types of models can be used for both regression and classification, but this assignment will consider classification domain and for giving focus on the ensemble models, we will use the same dataset we used previouly, in random forests.</p>
<section id="ensemble-methods-for-classification">
<h2><span class="section-number">38.71.1. </span>Ensemble methods for classification<a class="headerlink" href="#ensemble-methods-for-classification" title="Permalink to this headline">#</a></h2>
</section>
<section id="imports">
<h2><span class="section-number">38.71.2. </span>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="loading-the-data">
<h2><span class="section-number">38.71.3. </span>Loading the data<a class="headerlink" href="#loading-the-data" title="Permalink to this headline">#</a></h2>
<p>In this assignment, we will use Random forests to build a classifier that identify the increase or decrease of the electricity using ‚Äúthe data that was collected from the Australian New South Wales Electricity Market. In this market, prices are not fixed and are affected by demand and supply of the market. They are set every five minutes. Electricity transfers to/from the neighboring state of Victoria were done to alleviate fluctuations.‚Äù</p>
<p>‚ÄúThe dataset contains 45,312 instances dated from 7 May 1996 to 5 December 1998. Each example of the dataset refers to a period of 30 minutes, i.e. there are 48 instances for each time period of one day. Each example on the dataset has 5 fields, the day of week, the time stamp, the New South Wales electricity demand, the Victoria electricity demand, the scheduled electricity transfer between states and the class label. The class label identifies the change of the price (UP or DOWN) in New South Wales relative to a moving average of the last 24 hours (and removes the impact of longer term price trends). Source: <a class="reference external" href="https://www.openml.org/d/151">Open ML electricity</a>.</p>
<p>Here are the information about the features:</p>
<ul class="simple">
<li><p>Date: date between 7 May 1996 to 5 December 1998. Here normalized between 0 and 1</p></li>
<li><p>Day: day of the week (1-7)</p></li>
<li><p>Period: time of the measurement (1-48) in half hour intervals over 24 hours. Here normalized between 0 and 1</p></li>
<li><p>NSWprice: New South Wales electricity price, normalized between 0 and 1</p></li>
<li><p>NSWdemand: New South Wales electricity demand, normalized between 0 and 1</p></li>
<li><p>VICprice: Victoria electricity price, normalized between 0 and 1</p></li>
<li><p>VICdemand: Victoria electricity demand, normalized between 0 and 1</p></li>
<li><p>transfer: scheduled electricity transfer between both states, normalized between 0 and 1</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s hide warnings</span>

<span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elec_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../../../assets/data/elec_data.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">elec_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elec_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elec_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="tasks-and-roles">
<h2><span class="section-number">38.71.4. </span>Tasks and roles<a class="headerlink" href="#tasks-and-roles" title="Permalink to this headline">#</a></h2>
<section id="task-1-exploratory-data-analysis">
<h3><span class="section-number">38.71.4.1. </span>Task 1: Exploratory data analysis<a class="headerlink" href="#task-1-exploratory-data-analysis" title="Permalink to this headline">#</a></h3>
<p>Before doing exploratory analysis, as always, let‚Äôs split the data into training and test sets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">elec_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;The size of training data is: </span><span class="si">{}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">The size of testing data is: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs take a quick look into the dataset</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Displaying the last rows</span>

<span class="n">train_data</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Two things to draw from the dataset for now:</p>
<ul class="simple">
<li><p>The target feature <code class="docutils literal notranslate"><span class="pre">class</span></code> is categorical. We will make sure to encode that during data preprocessing.</p></li>
<li><p>All numerical features are already normalized, so we won‚Äôt need to normalize these type of features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Checking summary stats</span>

<span class="n">train_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Checking missing values</span>

<span class="n">train_data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Great, we don‚Äôt have any missing values. Usually there are three things to do with if they are present:</p>
<ul class="simple">
<li><p>We can remove all missing values completely</p></li>
<li><p>We can leave them as they are</p></li>
<li><p>We can fill them with a given strategy such as mean, media or most frequent value. Either <code class="docutils literal notranslate"><span class="pre">Sklearn</span></code> or Pandas provides a quick ways to fill these kind of values.</p></li>
</ul>
<p>If you still want to know more about how to deal with missing values, please refer to <a class="reference external" href="https://medium.com/analytics-vidhya/a-comprehensive-guide-for-handling-missing-values-990c999c49ed?source=---------11----------------------------">this article</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Checking feature correlation</span>

<span class="n">corr</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Visualizing correlation</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;crest&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>It seems that we don‚Äôt have features which are too correlating. Correlation shown above varies from <code class="docutils literal notranslate"><span class="pre">-1</span> <span class="pre">to</span> <span class="pre">1</span></code>. If the correlation between two features is close to 1, it means that they nearly contain the same information. If it is close to -1, it means that these features contain different information.Take an example: <code class="docutils literal notranslate"><span class="pre">vicdemand</span></code> correlate with <code class="docutils literal notranslate"><span class="pre">nswdeman</span></code> at 0.67 ratio.</p>
<p>So if you drop one of those features, it‚Äôs likely that your model will not be affected much. So different to what you have seen in many articles, having features which does not correlate to the target feature doesn‚Äôt mean they are not useful.</p>
<p>In the above correlation matrix, you can see that class feature is not there and this is because it still has categorical values.</p>
</section>
<section id="task-2-more-data-exploration">
<h3><span class="section-number">38.71.4.2. </span>Task 2: More data exploration<a class="headerlink" href="#task-2-more-data-exploration" title="Permalink to this headline">#</a></h3>
<p>Before preprocessing the data, let‚Äôs take a look into specific features.</p>
<p>Let‚Äôs see how many Ups/Downs are in the class feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;class&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Day</span></code> is the days of the week, from 1-7, Monday to Sunday. Let‚Äôs count the days occurences in respect to the ups/downs of the electricity‚Äôs price.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;day&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;class&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>It seems that most days had downs. From the beginning of the week, there were consistent increase in downs(price of electricity went down) and decrease in ups.
Let‚Äôs see if there is an appealing relationship between the demand/price of electricity in New South Wales and Victoria.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;vicdemand&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;nswdemand&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;class&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The demand of the electricity in New South Wales and the Victoria is kind of linear. Let‚Äôs see if we can get any other insights by bringing days in the demand analysis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;vicdemand&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;nswdemand&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;day&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s2">&quot;day&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Although it is kind of hard to draw a strong point, there is less demand of electricity in both cities on Monday and Sunday than other days. We can use a line plot to plot the demand in both cities on the course of the days.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;day&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;nswdemand&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;day&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;vicdemand&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Another interesting thing to look in the dataset is if there are some seasonalities/trends in the demand/price in either Victoria or New South Wales over period of time. In time series analysis, seasonality is when there is repetitive scenarios or consistent behaviours over the course of time.</p>
<p>If you look at the demand of the electricity in both cities on the course of date (<code class="docutils literal notranslate"><span class="pre">7</span> <span class="pre">May</span> <span class="pre">1996</span> <span class="pre">to</span> <span class="pre">5</span> <span class="pre">December</span> <span class="pre">1998</span></code>), you can see that there are some types of seasonalities. Not 100% but it seems there is and if this dataset would have been collected for more than two years, it would probably be easy to know surely if there are seasonalities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;date&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;nswdemand&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;date&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;vicdemand&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>One last thing about data analysis, let‚Äôs plot all histograms of the numerical features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="task-3-data-preprocessing">
<h3><span class="section-number">38.71.4.3. </span>Task 3: Data preprocessing<a class="headerlink" href="#task-3-data-preprocessing" title="Permalink to this headline">#</a></h3>
<p>It is here that we prepare the data to be in the proper format for the machine learning model.</p>
<p>Let‚Äôs encode the categorical feature <code class="docutils literal notranslate"><span class="pre">class</span></code>. But before that, let‚Äôs take training input data and labels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;class&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="n">label_enc</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_train_prepared</span> <span class="o">=</span> <span class="n">label_enc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Because in python, it does not make sense to perform a multiplication between a sequence (list, tuple, etc.) and a float, so for subsequent operations, we need to convert X_train into an array.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train_prepared</span>
</pre></div>
</div>
</div>
</div>
<p>Now we are ready to train the machine learning model.</p>
<p>But again if you look at the dat, the <code class="docutils literal notranslate"><span class="pre">day</span></code> feature is not normalized as other features. We can normalize it or leave it but for now let‚Äôs go ahead and train the random forests classifier.</p>
</section>
<section id="task-4-training-ensemble-classifiers">
<h3><span class="section-number">38.71.4.4. </span>Task 4: Training ensemble classifiers<a class="headerlink" href="#task-4-training-ensemble-classifiers" title="Permalink to this headline">#</a></h3>
<section id="voting-classifier">
<h4><span class="section-number">38.71.4.4.1. </span>4.1: Voting classifier<a class="headerlink" href="#voting-classifier" title="Permalink to this headline">#</a></h4>
<p>Let‚Äôs assume that you have trained 3 different classifiers on the training data but none of these classifiers had an oustanding results.</p>
<p>The idea of Voting ensemble technique is fairly simple. We can aggregate the results of all those 3 classifiers and the result will be good than any single classifier.</p>
<p>Let‚Äôs train 3 classifiers on the training data and then we will go ahead and aggregate their results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">log_classifier</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">sv_classifier</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="n">sgd_classifier</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">classifiers</span><span class="p">(</span><span class="n">clf1</span><span class="p">,</span> <span class="n">clf2</span><span class="p">,</span> <span class="n">clf3</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A function that takes 5 inputs: 3 classifiers, training data &amp; labels</span>
<span class="sd">    And return the list of accuracies on all classifiers</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># A list of all classifiers</span>
    <span class="n">clfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">clf1</span><span class="p">,</span> <span class="n">clf2</span><span class="p">,</span> <span class="n">clf3</span><span class="p">]</span>

    <span class="c1"># An empty list to comprehend</span>
    <span class="n">all_clfs_acc</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Train each classifier, evaluate it on the training set</span>
    <span class="c1"># And append the accuracy to &#39;all_clfs_acc&#39;</span>

    <span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="n">clfs</span><span class="p">:</span>

        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">all_clfs_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">all_clfs_acc</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifiers</span><span class="p">(</span><span class="n">log_classifier</span><span class="p">,</span> <span class="n">sv_classifier</span><span class="p">,</span> <span class="n">sgd_classifier</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As you can see, the function returned 3 accuracies on the training set. The first accuracy correspond to Logistic Regression, the second is Support Vector Classifier, and the third is SGD(Stockastic Gradient Descent).</p>
<p>Now, let us use Voting Classifier to aggregate the results of all of those 3 classifiers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingClassifier</span>

<span class="n">vot_classifier</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;log_reg&quot;</span><span class="p">,</span> <span class="n">log_classifier</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;svc&quot;</span><span class="p">,</span> <span class="n">sv_classifier</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;sgd&quot;</span><span class="p">,</span> <span class="n">sgd_classifier</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">voting</span><span class="o">=</span><span class="s2">&quot;hard&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">vot_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Since we will need to calculate accuracy often, let‚Äôs make a function to be calling always.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>


<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>

    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">acc</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs use the above function to find the accuracy of the voting classifier</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">vot_classifier</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As we can see, it slightly outperformed all individual classifiers. It‚Äôs small increments in the accuracy but most of the time, it will be always better than any individual classifier.</p>
</section>
<section id="bagging-classifier">
<h4><span class="section-number">38.71.4.4.2. </span>4.2: Bagging classifier<a class="headerlink" href="#bagging-classifier" title="Permalink to this headline">#</a></h4>
<p>Instead of training different algorithms on the same data and average their results as Voting does, Bagging ensemble method train a single or multiple classifier/regressors on different subsets of the training data and aggregate the results on all subsets.</p>
<p>When this is used with complex models (that overfit data easily) like decision trees, the overfitting can be reduced.</p>
<p>Let‚Äôs use bagging to train 500 decision trees on different subsets of data and then average the predictions on those subsets.</p>
<p>By setting <code class="docutils literal notranslate"><span class="pre">max_samples=0.5</span></code>, <code class="docutils literal notranslate"><span class="pre">max_features=0.5</span></code>, <code class="docutils literal notranslate"><span class="pre">bootstrap=False</span></code>, we are using random 50% subsets of training data and random 50% subsets of features. If bootstrap is <code class="docutils literal notranslate"><span class="pre">True</span></code>, ratio of those training samples are sampled from the training data with replacement and if it is False, there is no replecement. When in fact bootstrap is <code class="docutils literal notranslate"><span class="pre">False</span></code>, this is called Pasting. There are also other techniques called Random Subspaces and Random Patches and they are all based off how the samples are drawn from the data. you can learn more about these techniques and more about other hyperparameters on the <a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#bagging">Scikit-Learn documentation</a>.</p>
<p>One of the great way to improve a particular machine learning model is to learn about its hyperparameters and what each stands for. So, you can learn more about Bagging <a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#id2">here</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="n">bag_classifier</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
    <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s2">&quot;balanced&quot;</span><span class="p">),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">max_features</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">bootstrap</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">bag_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">bag_classifier</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Wow, this is much better. Bagging ensembles work well and they outperform Voting ensembles a lot. Other remarkable thing about them is that they are able to overcome the overfitting especially when used with decision trees (decision trees tend to overfit easily). Let‚Äôs now see other type of ensemble models: Gradient Boosting Classifier.</p>
</section>
<section id="gradient-boosting-classifier">
<h4><span class="section-number">38.71.4.4.3. </span>4.3: Gradient boosting classifier<a class="headerlink" href="#gradient-boosting-classifier" title="Permalink to this headline">#</a></h4>
<p>Gradient boosting works like bagging methods. The only difference is that instead of training models on subsets of training data, models(decision trees) are trained in a sequence where each tree model takes the error of the previous tree to correct it and the sequence goes on‚Ä¶</p>
<p>Simply, the initial model is trained on the full data, but then the next models minimizes the previous errors.</p>
<p>Just like other models, gradient boosting classifier has hyperparameters but the most important ones are number of estimators or trees (<code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>) and learning rate (<code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>

<span class="n">grad_boost_clf</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>

<span class="n">grad_boost_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs evaluate it on the training set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">grad_boost_clf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>One disadvantage of the Gradient Boosting ensemble method is that it is easy to overfit, and that has to do with how they works. By minimizing the errors consecutively (tree after tree), they can be so perfect but the of course won‚Äôt be perfect when fed to the test data.</p>
<p>One way to avoid overfitting is to carefully choose the learning rate that scale well with the number of estimators. Although the high number of estimators can‚Äôt necessarily cause overfitting (gradient boosting is a robust model), the learning rate has to be low. In other words, there is a trade off between these two hyperparameters. The higher the learning rate, the lower estimators and vice versa. If you can get a good results with low learning rate, there is a chance that it will generalize well on test too.</p>
<p>You can spend sometime to change these two parameters and try to see their effects.</p>
<p>For classification problems beyond two classes, Scikit-Learn recommend using <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html#sklearn.ensemble.HistGradientBoostingClassifier">Histogram Gradient Boosting Classifier</a> which is a faster version of the Gradient Boosting Classifier. It is inspired by <a class="reference external" href="https://github.com/Microsoft/LightGBM">Microsoft Light Gradient Boosting Machine (LightGBM)</a>. LightGBM is fater, low memory usage, better performance, support distributed training and GPU, and can handle large datasets.</p>
</section>
<section id="adaboost-classifier">
<h4><span class="section-number">38.71.4.4.4. </span>4.4: AdaBoost classifier<a class="headerlink" href="#adaboost-classifier" title="Permalink to this headline">#</a></h4>
<p>AdaBoost is another ensemble model in class of boosting methods. It‚Äôs very much like gradient boost but instead of minimizing the error of the consecutive models, it updates the weights.</p>
<p>So, the first model (decision tree) is trained on the full training data, the next model weights are updated based off the previous weights and so forth.</p>
<p>The main parameters to tune to make AdaBoost work well are number of estimators and the maximum depth of each estimator.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="n">adaboost_clf</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span>
    <span class="n">base_estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s2">&quot;balanced&quot;</span><span class="p">),</span>
    <span class="c1"># base estimator is decision trees by default</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">adaboost_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs evaluate it on the training set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">adaboost_clf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Again, you can tune the number of estimators and the depth of the base estimator. The base estimator is Decision Trees by default.</p>
</section>
<section id="stacking-classifier">
<h4><span class="section-number">38.71.4.4.5. </span>4.5: Stacking classifier<a class="headerlink" href="#stacking-classifier" title="Permalink to this headline">#</a></h4>
<p>Also referred to as Stacked Generalization, it is an ensemble method employed to reduce the biases and the errors rate made by multiple predictors(individual models/estimators).</p>
<p>Instead of averaging the predictions made by individual models or predictors, in stacking, multiple models are trained on the full training data and then the final model that is trained on different subsets of the training data takes the predictions of the former models and find the final predictions.</p>
<p>From its <a class="reference external" href="http://machine-learning.martinsewell.com/ensembles/stacking/Wolpert1992.pdf">original paper</a>, it is noted that it can be seen as the sophisticated version of the cross validation (per the reason why the final estimator is trained on the subsets or folds of the training data).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">StackingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>


<span class="n">base_estimators</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;rand&quot;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
    <span class="p">(</span><span class="s2">&quot;svc&quot;</span><span class="p">,</span> <span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
<span class="p">]</span>

<span class="n">final_estimator</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">stack_clf</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="n">base_estimators</span><span class="p">,</span> <span class="n">final_estimator</span><span class="o">=</span><span class="n">final_estimator</span>
<span class="p">)</span>

<span class="n">stack_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs evaluate it on the training set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">stack_clf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Ohh the accuracy looks appealing! But is it really? It might be that we overfitted the training data.</p>
</section>
</section>
<section id="task-5-evaluating-the-ensemble-model-on-the-test-set">
<h3><span class="section-number">38.71.4.5. </span>Task 5: Evaluating the ensemble model on the test set<a class="headerlink" href="#task-5-evaluating-the-ensemble-model-on-the-test-set" title="Permalink to this headline">#</a></h3>
<p>Let‚Äôs say that all we have been doing was trying to find an ensemble model that can fit well the data and so we want to test it on the test set before shipping it into production.</p>
<p>To narrow the choice down, we will use A Gradient Boosting method.</p>
<p>As always, we will prepare the test set in the same way that we prepared the training set. Let‚Äôs go!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;class&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="n">y_test_prepared</span> <span class="o">=</span> <span class="n">label_enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">grad_boost_clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>That‚Äôs not really bad considering that the model never saw the test data anywhere in previous steps. The Gradient boosting method had nearly 92% on the training data.</p>
<p>Let‚Äôs also evaluate the stacking classifier. It was overly optimistic on the training data, nearly 100%!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">stack_clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>How about trying a bag classifier also? It had nearly 98% on the training data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">bag_classifier</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test_prepared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As we can see, all of the ensembles are not generalizing well on the test set. It‚Äôs not that bad again, but there is a room of improvement. One sure way to improve the results of machine learning model is to improve the data.</p>
<p>You may also have to tune the hyperparamaters of the particular ensemble method and this works sometime too.</p>
</section>
</section>
<section id="final-note">
<h2><span class="section-number">38.71.5. </span>Final note<a class="headerlink" href="#final-note" title="Permalink to this headline">#</a></h2>
<p>This notebook was all about ensemble learning methods. There is truly a <code class="docutils literal notranslate"><span class="pre">wisdom</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">crowd</span></code>(CC: Aurelion Geron). By averaging the results of different models, we are able to improve the overall prediction.</p>
<p>There is a notion that ensemble models are slow and expensive to run in production. It‚Äôs true, but with the advent of computation power and how incredible these types of ML models work well, that‚Äôs no longer issue for someone. They are complex algorithms but they can also reduce complexity. How?</p>
<p>Think about it: Instead of building a single complex model (typically a neural network), you can build small models that will train and compute predictions faster and then average their results using a given ensemble method. By that way, you are leveraging ensemble methods to reduce complexity.</p>
<p>To learn more about the ensemble models, you can refer to this chapter <code class="docutils literal notranslate"><span class="pre">Chapter</span> <span class="pre">7</span> <span class="pre">Ensemble</span> <span class="pre">Learning</span> <span class="pre">and</span> <span class="pre">Random</span> <span class="pre">Forests</span></code> of the book <a class="reference external" href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Hands-On Machine Learning with Scikit-Learn, Keras and TensorFlow</a>.</p>
</section>
<section id="acknowledgments">
<h2><span class="section-number">38.71.6. </span>Acknowledgments<a class="headerlink" href="#acknowledgments" title="Permalink to this headline">#</a></h2>
<p>Thanks to Nyandwi for creating the open-source course <a class="reference external" href="https://github.com/Nyandwi/machine_learning_complete">Machine Learning complete</a>. It inspires the majority of the content in this chapter.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ocademy-ai/machine-learning",
            ref: "release",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./assignments/ml-advanced/ensemble-learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="random-forests-for-classification.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">38.70. </span>Random forests for classification</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="decision-trees.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">38.72. </span>Decision trees</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ocademy<br/>
  
      &copy; Copyright 2022-2023.<br/>
    <div class="extra_footer">
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> Text content of this work is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>