{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "source": [
    "# K-Means Clustering Implementation in Python - assignment 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "## K-means clustering\n",
    "This work is based on Mubaris' great work (\n",
    "https://mubaris.com/2017/10/01/kmeans-clustering-in-python/).\n",
    "\n",
    "A description of the algorithm can be found:\n",
    "https://github.com/andrewxiechina/DataScience/blob/master/K-Means/cs229-notes7a%202.pdf\n",
    "\n",
    "![](https://github.com/andrewxiechina/DataScience/blob/master/K-Means/k4XcapI.gif?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f77c205-9066-43ea-801f-398dd7bc0f2b",
    "_uuid": "157bc30b9475ced37f0e73e452a9af3754534cd2"
   },
   "source": [
    "## Generate random data\n",
    "Generate random data normally distributed around 3 centers, with a noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2e4dd4c9-55f5-4b0b-8822-79ac91d945d1",
    "_uuid": "6b2252bd12385c95275e6662a33e5ba6f17ec5e8"
   },
   "outputs": [],
   "source": [
    "# Set three centers, the model should predict similar results\n",
    "center_1 = np.array([1, 1])\n",
    "center_2 = np.array([5, 5])\n",
    "center_3 = np.array([8, 1])\n",
    "\n",
    "# Generate random data and center it to the three centers\n",
    "data_1 = np.random.randn(200, 2) + center_1\n",
    "data_2 = np.random.randn(200, 2) + center_2\n",
    "data_3 = np.random.randn(200, 2) + center_3\n",
    "\n",
    "data = np.concatenate((data_1, data_2, data_3), axis=0)\n",
    "\n",
    "plt.scatter(data[:, 0], data[:, 1], s=7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "741d06af-14e7-4bff-a5c9-45e0c497fdde",
    "_uuid": "3369c3f3f03d1634891f2a0d3f092783abfe4415"
   },
   "source": [
    "## Create k-means algorithm\n",
    "Generate random data normally distributed around 3 centers, with a noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "76035f98-a38c-498c-93d5-64c89c22387c",
    "_uuid": "572e6484353099cec66bacb0fb393a8cb7a093f6"
   },
   "outputs": [],
   "source": [
    "# Number of clusters\n",
    "k = 3\n",
    "# Number of training data\n",
    "n = data.shape[0]\n",
    "# Number of features in the data\n",
    "c = data.shape[1]\n",
    "\n",
    "# Generate random centers, here we use sigma and mean to ensure it represent the whole data\n",
    "mean = np.mean(data, axis=0)\n",
    "std = np.std(data, axis=0)\n",
    "centers = np.random.randn(k, c)*std + mean\n",
    "\n",
    "# Plot the data and the centers generated as random\n",
    "plt.scatter(data[:, 0], data[:, 1], s=7)\n",
    "plt.scatter(centers[:, 0], centers[:, 1], marker='*', c='g', s=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3ce48e5d-fc96-478a-8530-5aae35d7cae8",
    "_uuid": "e8fae8a205f7752566970e1dbe566aebe75709e2"
   },
   "outputs": [],
   "source": [
    "centers_old = np.zeros(centers.shape)  # to store old centers\n",
    "centers_new = deepcopy(centers)  # Store new centers\n",
    "\n",
    "data.shape\n",
    "clusters = np.zeros(n)\n",
    "distances = np.zeros((n, k))\n",
    "\n",
    "error = np.linalg.norm(centers_new - centers_old)\n",
    "\n",
    "# When, after an update, the estimate of that center stays the same, exit loop\n",
    "while error != 0:\n",
    "    # Measure the distance to every center\n",
    "    for i in range(k):\n",
    "        distances[:, i] = np.linalg.norm(data - centers[i], axis=1)\n",
    "    # Assign all training data to closest center\n",
    "    clusters = np.argmin(distances, axis=1)\n",
    "\n",
    "    centers_old = deepcopy(centers_new)\n",
    "    # Calculate mean for every cluster and update the center\n",
    "    for i in range(k):\n",
    "        centers_new[i] = np.mean(data[clusters == i], axis=0)\n",
    "    error = np.linalg.norm(centers_new - centers_old)\n",
    "centers_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eac176c7-5448-4def-9339-eb0a90c9fb74",
    "_uuid": "9be1d0c21165ee6cd64183e00105f8ac29e2be2d"
   },
   "outputs": [],
   "source": [
    "# Plot the data and the centers generated as random\n",
    "plt.scatter(data[:, 0], data[:, 1], s=7)\n",
    "plt.scatter(centers_new[:, 0], centers_new[:, 1], marker='*', c='g', s=150)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cbeae481-b720-4db4-921d-6f2c898d6a37",
    "_uuid": "1fb25b113b7cd63edf80f827cf0a8cf31d7c9804"
   },
   "source": [
    "## Test on iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d6c56b06-d4be-4507-8543-eca0cf3fcee7",
    "_uuid": "60a0fc5eb5a6585c16012bb73a3f5352fd7dbebb"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv(\"../../../assets/data/k_means_clustering_iris.csv\")\n",
    "df.drop('Id', axis=1, inplace=True)  # Se elimina la columna no requerida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "beb0af7e357cd45f7630639449d7e463e16751c3"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "051acd8793e360345a375fd4e4dd5edce5c87c12"
   },
   "outputs": [],
   "source": [
    "# Change categorical data to number 0-2\n",
    "df[\"Species\"] = pd.Categorical(df[\"Species\"])\n",
    "df[\"Species\"] = df[\"Species\"].cat.codes\n",
    "# Change dataframe to numpy matrix\n",
    "data = df.values[:, 0:4]\n",
    "category = df.values[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebb96f300feda0789ea79ff2413dc3f797d3792e"
   },
   "outputs": [],
   "source": [
    "# Number of clusters\n",
    "k = 3\n",
    "# Number of training data\n",
    "n = data.shape[0]\n",
    "# Number of features in the data\n",
    "c = data.shape[1]\n",
    "\n",
    "# Generate random centers, here we use sigma and mean to ensure it represent the whole data\n",
    "mean = np.mean(data, axis=0)\n",
    "std = np.std(data, axis=0)\n",
    "centers = np.random.randn(k, c)*std + mean\n",
    "\n",
    "# Plot the data and the centers generated as random\n",
    "colors = ['orange', 'blue', 'green']\n",
    "for i in range(n):\n",
    "    plt.scatter(data[i, 0], data[i, 1], s=7, color=colors[int(category[i])])\n",
    "plt.scatter(centers[:, 0], centers[:, 1], marker='*', c='g', s=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9130e49ffd32229a737da3dc4b9d74ab7f3952c6"
   },
   "outputs": [],
   "source": [
    "centers_old = np.zeros(centers.shape)  # to store old centers\n",
    "centers_new = deepcopy(centers)  # Store new centers\n",
    "\n",
    "data.shape\n",
    "clusters = np.zeros(n)\n",
    "distances = np.zeros((n, k))\n",
    "\n",
    "error = np.linalg.norm(centers_new - centers_old)\n",
    "\n",
    "# When, after an update, the estimate of that center stays the same, exit loop\n",
    "while error != 0:\n",
    "    # Measure the distance to every center\n",
    "    for i in range(k):\n",
    "        distances[:, i] = np.linalg.norm(data - centers[i], axis=1)\n",
    "    # Assign all training data to closest center\n",
    "    clusters = np.argmin(distances, axis=1)\n",
    "\n",
    "    centers_old = deepcopy(centers_new)\n",
    "    # Calculate mean for every cluster and update the center\n",
    "    for i in range(k):\n",
    "        centers_new[i] = np.mean(data[clusters == i], axis=0)\n",
    "    error = np.linalg.norm(centers_new - centers_old)\n",
    "centers_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e7191388366bd12ae7e69284cc41d2f651d28da"
   },
   "outputs": [],
   "source": [
    "# Plot the data and the centers generated as random\n",
    "colors = ['orange', 'blue', 'green']\n",
    "for i in range(n):\n",
    "    plt.scatter(data[i, 0], data[i, 1], s=7, color=colors[int(category[i])])\n",
    "plt.scatter(centers_new[:, 0], centers_new[:, 1], marker='*', c='g', s=150)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "Thanks to Andrew Yue Xie for creating the Notebook [Customer Segmentation: Clustering](https://www.kaggle.com/code/andyxie/k-means-clustering-implementation-in-python), lisensed under the [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0). It inspires the majority of the content in this chapter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
