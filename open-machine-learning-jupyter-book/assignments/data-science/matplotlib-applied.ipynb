{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LICENSE\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2018 Oleksii Trekhleb\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matplotlib-applied\n",
    "\n",
    "* Applying Matplotlib Visualizations to Kaggle: Titanic\n",
    "* Bar Plots, Histograms, subplot2grid\n",
    "* Normalized Plots\n",
    "* Scatter Plots, subplots\n",
    "* Kernel Density Estimation Plots\n",
    "\n",
    "## Applying Matplotlib Visualizations to Kaggle: Titanic\n",
    "Prepare the titanic data to plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn\n",
    "\n",
    "# Set the global default size of matplotlib figures\n",
    "plt.rc('figure', figsize=(10, 5))\n",
    "\n",
    "# Set seaborn aesthetic parameters to defaults\n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/titanic/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-946d124c6187>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/titanic/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Get the unique values of Sex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\86199\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\86199\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\86199\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\86199\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\86199\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/titanic/train.csv'"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/titanic/train.csv')\n",
    "\n",
    "def clean_data(df):\n",
    "    \n",
    "    # Get the unique values of Sex\n",
    "    sexes = np.sort(df['Sex'].unique())\n",
    "    \n",
    "    # Generate a mapping of Sex from a string to a number representation    \n",
    "    genders_mapping = dict(zip(sexes, range(0, len(sexes) + 1)))\n",
    "\n",
    "    # Transform Sex from a string to a number representation\n",
    "    df['Sex_Val'] = df['Sex'].map(genders_mapping).astype(int)\n",
    "    \n",
    "    # Get the unique values of Embarked\n",
    "    embarked_locs = np.sort(df['Embarked'].unique())\n",
    "\n",
    "    # Generate a mapping of Embarked from a string to a number representation        \n",
    "    embarked_locs_mapping = dict(zip(embarked_locs, \n",
    "                                     range(0, len(embarked_locs) + 1)))\n",
    "    \n",
    "    # Transform Embarked from a string to dummy variables\n",
    "    df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked_Val')], axis=1)\n",
    "    \n",
    "    # Fill in missing values of Embarked\n",
    "    # Since the vast majority of passengers embarked in 'S': 3, \n",
    "    # we assign the missing values in Embarked to 'S':\n",
    "    if len(df[df['Embarked'].isnull()] > 0):\n",
    "        df.replace({'Embarked_Val' : \n",
    "                       { embarked_locs_mapping[np.nan] : embarked_locs_mapping['S'] \n",
    "                       }\n",
    "                   }, \n",
    "                   inplace=True)\n",
    "    \n",
    "    # Fill in missing values of Fare with the average Fare\n",
    "    if len(df[df['Fare'].isnull()] > 0):\n",
    "        avg_fare = df['Fare'].mean()\n",
    "        df.replace({ None: avg_fare }, inplace=True)\n",
    "    \n",
    "    # To keep Age in tact, make a copy of it called AgeFill \n",
    "    # that we will use to fill in the missing ages:\n",
    "    df['AgeFill'] = df['Age']\n",
    "\n",
    "    # Determine the Age typical for each passenger class by Sex_Val.  \n",
    "    # We'll use the median instead of the mean because the Age \n",
    "    # histogram seems to be right skewed.\n",
    "    df['AgeFill'] = df['AgeFill'] \\\n",
    "                        .groupby([df['Sex_Val'], df['Pclass']]) \\\n",
    "                        .apply(lambda x: x.fillna(x.median()))\n",
    "            \n",
    "    # Define a new feature FamilySize that is the sum of \n",
    "    # Parch (number of parents or children on board) and \n",
    "    # SibSp (number of siblings or spouses):\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train = clean_data(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<details><summary>üë©‚Äçüíª <b>Hint</b></summary>\n",
    "    \n",
    "Refer to <a href=\"https://pandas.pydata.org/docs/user_guide/indexing.html\">indexin and selecting data on</a> <code>pandas.DataFrame</code>.\n",
    "\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Plots, Histograms, subplot2grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Size of matplotlib figures that contain subplots\n",
    "figsize_with_subplots = (10, 10)\n",
    "\n",
    "# Set up a grid of plots\n",
    "fig = plt.figure(figsize=figsize_with_subplots) \n",
    "fig_dims = (3, 2)\n",
    "\n",
    "# Plot death and survival counts\n",
    "plt.subplot2grid(fig_dims, (0, 0))\n",
    "df_train['Survived'].value_counts().plot(kind='bar', \n",
    "                                         title='Death and Survival Counts',\n",
    "                                         color='r',\n",
    "                                         align='center')\n",
    "\n",
    "# Plot Pclass counts\n",
    "plt.subplot2grid(fig_dims, (0, 1))\n",
    "df_train['Pclass'].value_counts().plot(kind='bar', \n",
    "                                       title='Passenger Class Counts')\n",
    "\n",
    "# Plot Sex counts\n",
    "plt.subplot2grid(fig_dims, (1, 0))\n",
    "df_train['Sex'].value_counts().plot(kind='bar', \n",
    "                                    title='Gender Counts')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Plot Embarked counts\n",
    "plt.subplot2grid(fig_dims, (1, 1))\n",
    "df_train['Embarked'].value_counts().plot(kind='bar', \n",
    "                                         title='Ports of Embarkation Counts')\n",
    "\n",
    "# Plot the Age histogram\n",
    "plt.subplot2grid(fig_dims, (2, 0))\n",
    "df_train['Age'].hist()\n",
    "plt.title('Age Histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values of Embarked and its maximum\n",
    "family_sizes = np.sort(df_train['FamilySize'].unique())\n",
    "family_size_max = max(family_sizes)\n",
    "\n",
    "df1 = df_train[df_train['Survived'] == 0]['FamilySize']\n",
    "df2 = df_train[df_train['Survived'] == 1]['FamilySize']\n",
    "plt.hist([df1, df2], \n",
    "         bins=family_size_max + 1, \n",
    "         range=(0, family_size_max), \n",
    "         stacked=True)\n",
    "plt.legend(('Died', 'Survived'), loc='best')\n",
    "plt.title('Survivors by Family Size')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pclass_xt = pd.crosstab(df_train['Pclass'], df_train['Survived'])\n",
    "\n",
    "# Normalize the cross tab to sum to 1:\n",
    "pclass_xt_pct = pclass_xt.div(pclass_xt.sum(1).astype(float), axis=0)\n",
    "\n",
    "pclass_xt_pct.plot(kind='bar', \n",
    "                   stacked=True, \n",
    "                   title='Survival Rate by Passenger Classes')\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Survival Rate')\n",
    "\n",
    "# Plot survival rate by Sex\n",
    "females_df = df_train[df_train['Sex'] == 'female']\n",
    "females_xt = pd.crosstab(females_df['Pclass'], df_train['Survived'])\n",
    "females_xt_pct = females_xt.div(females_xt.sum(1).astype(float), axis=0)\n",
    "females_xt_pct.plot(kind='bar', \n",
    "                    stacked=True, \n",
    "                    title='Female Survival Rate by Passenger Class')\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Survival Rate')\n",
    "\n",
    "# Plot survival rate by Pclass\n",
    "males_df = df_train[df_train['Sex'] == 'male']\n",
    "males_xt = pd.crosstab(males_df['Pclass'], df_train['Survived'])\n",
    "males_xt_pct = males_xt.div(males_xt.sum(1).astype(float), axis=0)\n",
    "males_xt_pct.plot(kind='bar', \n",
    "                  stacked=True, \n",
    "                  title='Male Survival Rate by Passenger Class')\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Survival Rate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter Plots, subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up a grid of plots\n",
    "fig, axes = plt.subplots(2, 1, figsize=figsize_with_subplots)\n",
    "\n",
    "# Histogram of AgeFill segmented by Survived\n",
    "df1 = df_train[df_train['Survived'] == 0]['Age']\n",
    "df2 = df_train[df_train['Survived'] == 1]['Age']\n",
    "max_age = max(df_train['AgeFill'])\n",
    "\n",
    "axes[1].hist([df1, df2], \n",
    "             bins=max_age / 10, \n",
    "             range=(1, max_age), \n",
    "             stacked=True)\n",
    "axes[1].legend(('Died', 'Survived'), loc='best')\n",
    "axes[1].set_title('Survivors by Age Groups Histogram')\n",
    "axes[1].set_xlabel('Age')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "# Scatter plot Survived and AgeFill\n",
    "axes[0].scatter(df_train['Survived'], df_train['AgeFill'])\n",
    "axes[0].set_title('Survivors by Age Plot')\n",
    "axes[0].set_xlabel('Survived')\n",
    "axes[0].set_ylabel('Age')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Density Estimation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the unique values of Pclass:\n",
    "passenger_classes = np.sort(df_train['Pclass'].unique())\n",
    "\n",
    "for pclass in passenger_classes:\n",
    "    df_train.AgeFill[df_train.Pclass == pclass].plot(kind='kde')\n",
    "plt.title('Age Density Plot by Passenger Class')\n",
    "plt.xlabel('Age')\n",
    "plt.legend(('1st Class', '2nd Class', '3rd Class'), loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Thanks to below awesome open source projects for Python learning, which inspire this chapter.\n",
    "\n",
    "* <a href=\"https://github.com/trekhleb/learn-python\">learn-python</a> and <a href=\"https://github.com/trekhleb\">Oleksii Trekhleb</a>\n",
    "* <a href=\"https://github.com/huangsam/ultimate-python\">ultimate-python</a> and <a href=\"https://github.com/huangsam\">Samuel Huang</a>\n",
    "* <a href=\"https://github.com/jerry-git/learn-python3\">learn-python3</a> and <a href=\"https://github.com/jerry-gitq\">Jerry Pussine</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
