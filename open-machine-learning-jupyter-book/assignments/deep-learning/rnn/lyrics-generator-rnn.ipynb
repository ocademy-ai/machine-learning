{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:16.650314Z",
     "iopub.execute_input": "2023-07-20T14:36:16.650788Z",
     "iopub.status.idle": "2023-07-20T14:36:16.667616Z",
     "shell.execute_reply.started": "2023-07-20T14:36:16.650688Z",
     "shell.execute_reply": "2023-07-20T14:36:16.666447Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-07-30T05:17:10.170722435Z",
     "start_time": "2023-07-30T05:17:10.125835391Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <p style=\"background-color:#B291B6;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 60px;\">Lyrics Generator</p>\n",
    "\n",
    "<img src=\"https://github.com/KarnikaKapoor/Files/blob/main/Pink%20and%20White%20Geometric%20Marketing%20Presentation.gif?raw=true\">\n",
    "\n",
    "<p style=\"font-family:newtimeroman;font-size:120%;color:#444160;\">In this project, I will be building a model to generate text. My goal is to build a song lyrics generator to explore the \"creative\" side of the Recurrent Neural Networks(RNN). RNN Text generator is one of my most desired to-do projects. I am finally checking this one off my to-do list. So yeyyy! </p> \n",
    "\n",
    "<a id='top'></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<p style=\"background-color:#B291B6;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 60px;\">TABLE OF CONTENTS</p>   \n",
    "    \n",
    "* [1. IMPORTING LIBRARIES](#1)\n",
    "    \n",
    "* [2. LOADING DATA](#2)\n",
    "    \n",
    "* [3. DATA EXPLORATION](#3)  \n",
    "    \n",
    "* [4. DATA PREPREPROCESSING](#4)  \n",
    "    \n",
    "* [5. MODEL BUILDING](#5) \n",
    "      \n",
    "* [6. EVALUATING MODELS](#6)\n",
    "    \n",
    "* [7. CONCLUSION](#7)\n",
    "    \n",
    "* [8. END](#8)\n",
    "\n",
    "\n",
    "<a id=\"1\"></a>\n",
    "# <p style=\"background-color:#B291B6;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 60px;\">IMPORTING LIBRARIES</p>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string, os\n",
    "import nltk\n",
    "import re\n",
    "import keras\n",
    "import random\n",
    "import io\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adamax\n",
    "import sys\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:16.669033Z",
     "iopub.execute_input": "2023-07-20T14:36:16.669332Z",
     "iopub.status.idle": "2023-07-20T14:36:24.046475Z",
     "shell.execute_reply.started": "2023-07-20T14:36:16.669304Z",
     "shell.execute_reply": "2023-07-20T14:36:24.045474Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-07-30T05:17:10.449989582Z",
     "start_time": "2023-07-30T05:17:10.130067795Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstring\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'nltk'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"2\"></a>\n",
    "# <p style=\"background-color:#B291B6;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 60px;\">LOADING DATA</p>\n",
    "For this project, I have prepared a dataset of song lyrics. Let's load it and have a look."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"../input/lyrics/Songs.csv\")\n",
    "data.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:24.048386Z",
     "iopub.execute_input": "2023-07-20T14:36:24.048687Z",
     "iopub.status.idle": "2023-07-20T14:36:24.120004Z",
     "shell.execute_reply.started": "2023-07-20T14:36:24.048657Z",
     "shell.execute_reply": "2023-07-20T14:36:24.118992Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-07-30T05:17:10.443522327Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"3\"></a>\n",
    "# <p style=\"background-color:#B291B6;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 60px;\">DATA EXPLORATION</p>\n",
    "\n",
    "**In this section, I will be:**\n",
    "* Exploring the various artists in data\n",
    "* Explore the number of songs and their corresponding information\n",
    "* Explore the various words in lyrics via wordcloud "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#Printing the names of artists in the lyrics data\n",
    "print(\"Artists in the data:\\n\",data.Artist.value_counts()) "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:24.121788Z",
     "iopub.execute_input": "2023-07-20T14:36:24.122392Z",
     "iopub.status.idle": "2023-07-20T14:36:24.132149Z",
     "shell.execute_reply.started": "2023-07-20T14:36:24.122348Z",
     "shell.execute_reply": "2023-07-20T14:36:24.131205Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-07-30T05:17:10.443761813Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Printing the size of dataset\n",
    "print(\"Size of Dataset:\",data.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:24.133951Z",
     "iopub.execute_input": "2023-07-20T14:36:24.134522Z",
     "iopub.status.idle": "2023-07-20T14:36:24.140362Z",
     "shell.execute_reply.started": "2023-07-20T14:36:24.134467Z",
     "shell.execute_reply": "2023-07-20T14:36:24.139406Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-07-30T05:17:10.448801556Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "So I have a total of 745 songs\n",
    "\n",
    "**I will do a little feature engineering to extract more information on the songs such as:**\n",
    "* Number of characters\n",
    "* Number of words\n",
    "* Number of lines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#Adding a column of numbers of Characters,words and sentences in each msg\n",
    "data[\"No_of_Characters\"] = data[\"Lyrics\"].apply(len)\n",
    "data[\"No_of_Words\"]=data.apply(lambda row: nltk.word_tokenize(row[\"Lyrics\"]), axis=1).apply(len)\n",
    "data[\"No_of_Lines\"] = data[\"Lyrics\"].str.split('\\n').apply(len)\n",
    "data.describe()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:24.142055Z",
     "iopub.execute_input": "2023-07-20T14:36:24.142483Z",
     "iopub.status.idle": "2023-07-20T14:36:25.253519Z",
     "shell.execute_reply.started": "2023-07-20T14:36:24.142442Z",
     "shell.execute_reply": "2023-07-20T14:36:25.252668Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "To be noted: On average our songs have 1400-ish characters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#Plotting the comparative song lengths for various artists\n",
    "plt.figure(figsize=(15,15))\n",
    "ax = sns.pairplot(data, hue=\"Artist\", palette=\"plasma\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:25.254614Z",
     "iopub.execute_input": "2023-07-20T14:36:25.254912Z",
     "iopub.status.idle": "2023-07-20T14:36:31.668837Z",
     "shell.execute_reply.started": "2023-07-20T14:36:25.254859Z",
     "shell.execute_reply": "2023-07-20T14:36:31.667735Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate a word cloud image\n",
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"#444160\",colormap=\"Purples\", max_words=800).generate(\" \".join(data[\"Lyrics\"]))\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:31.671946Z",
     "iopub.execute_input": "2023-07-20T14:36:31.672487Z",
     "iopub.status.idle": "2023-07-20T14:36:33.005775Z",
     "shell.execute_reply.started": "2023-07-20T14:36:31.672443Z",
     "shell.execute_reply": "2023-07-20T14:36:33.005035Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Unsurprisingly one of the most frequent words in songs is \"Love\".*\n",
    "\n",
    "Next let us look at the lyrics of song No 42 in the lyrics. Why 42 you may ask! Well! because it is the answer to the Ultimate Question of Life, the Universe, and Everything. 🐬 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#A function to disply the song in an asthetically pleasing way! lol\n",
    "def My_song(song):\n",
    "    img = Image.open(\"../input/image-for-notebook/Pink and White Geometric Marketing Presentation (1).png\")\n",
    "    Text_on_image = ImageDraw.Draw(img)\n",
    "    myFont = ImageFont.truetype(\"../input/font-style/DancingScript-VariableFont_wght.ttf\", 45)\n",
    "    Text_on_image.text((620,90), song, font=myFont, fill =(255, 255, 255))\n",
    "    return img    \n",
    "#Having a look at the first 500 charachters of a random song lyrics\n",
    "My_song(data.Lyrics[42][:500])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.007558Z",
     "iopub.execute_input": "2023-07-20T14:36:33.008106Z",
     "iopub.status.idle": "2023-07-20T14:36:33.390345Z",
     "shell.execute_reply.started": "2023-07-20T14:36:33.008061Z",
     "shell.execute_reply": "2023-07-20T14:36:33.388916Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The generation of text with RNN involves the following workflow.  \n",
    "\n",
    "<p style=\"background-color:#B3C5E3;font-family:newtimeroman;color:#444160;text-align:center;font-size:120%;\">Loading Data ➡️ Preprocessing ➡️ Building Mapping Dictionary ➡️ Building Model ➡️ Generating Text</p>\n",
    "\n",
    "As I have loaded and explored the data,  I will proceed further by pre-processing the text.  \n",
    "\n",
    "\n",
    "<a id=\"4\"></a>\n",
    "# <p style=\"background-color:#B291B6;font-family:newtimeroman;color:#444160;font-size:150%;text-align:center;border-radius:20px 60px;\">DATA PREPROCESSING</p>\n",
    "\n",
    "**In this section, I will be performing the following:**\n",
    "\n",
    "**Creating a Corpus of Lyrics text:** For the model, we need a sequence of the text string. I am creating a Corpus out of Lyrics column. \n",
    "\n",
    "**Removing the unrequired characters that may have sneaked in my text corpus:** The data cleaning process for NLP is crucial preprocessing. To do that, I look into the Corpus to check for what this Corpus is comprised of. That is, all the unique symbols present. After examining the Corpus, I will be eliminating any foreign language or irrelevant symbols from the Corpus. \n",
    "\n",
    "**Creating a dictionary to map characters and their indices:** The computer doesn’t understand the text. For the computer, the text is just a cluster of symbols. It works with numbers. So we create a dictionary to map each unique character in our Corpus to a number and vice versa. This will be used to encode and decode the information going in and getting out of the RNN\n",
    "\n",
    "**Splitting the corpus into smaller sentences of equal length:** Encoding and splitting the corpus into smaller sequences of equal length: At this point, Corpus contain only intended characters (i.e, lower cap English alphabets, Numbers and a few punctuations). We will encode this corpus and create small sequences of equal lengths of features and the corresponding targets. Each feature and target will contain the mapped index in the dictionary of the unique characters they signify. \n",
    "\n",
    "The labels are then resized and normalized. Whereas the targets are one-hot encoded. Ready to be sent to the RNN for the training, but before that let us built the RNN model. \n",
    "\n",
    "**Creating a Corpus**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#Lining up all the lyrics to create corpus\n",
    "Corpus =''\n",
    "for listitem in data.Lyrics:\n",
    "    Corpus += listitem\n",
    "    \n",
    "Corpus = Corpus.lower() #converting all alphabets to lowecase \n",
    "print(\"Number of unique characters:\", len(set(Corpus)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.391225Z",
     "iopub.status.idle": "2023-07-20T14:36:33.391645Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The total number of unique characters present in the Corpus clearly shows, that some of the foreign language scripts have sneaked in. I will take a look at all the characters present. I will then remove the unrequired characters. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#To See all the unique characters present in the Corpus\n",
    "print(\"The unique characters:\",sorted(set(Corpus)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.392612Z",
     "iopub.status.idle": "2023-07-20T14:36:33.393075Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Keeping only a limited set of characters. \n",
    "to_remove = ['{', '}', '~', '©', 'à', 'á', 'ã', 'ä', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'ñ', 'ó', 'ö', 'ü', 'ŏ',\n",
    "             'е', 'ا', 'س', 'ل', 'م', 'و', '\\u2005', '\\u200a', '\\u200b', '–', '—', '‘', '’', '‚', '“', '”', \n",
    "             '…', '\\u205f', '\\ufeff', '!', '&', '(', ')', '*', '-',  '/', ]\n",
    "for symbol in to_remove:\n",
    "    Corpus = Corpus.replace(symbol,\" \")\n",
    "\n",
    "#Corpus = re.sub(\"[^A-Za-z0-9'\\.\\n]\",\"\",Corpus) Alterneativly could be used but I want to pick and chose (:"
   ],
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.393990Z",
     "iopub.status.idle": "2023-07-20T14:36:33.394391Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#To See all the unique characters present in the Corpus\n",
    "print(\"The unique characters:\",sorted(set(Corpus)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.395135Z",
     "iopub.status.idle": "2023-07-20T14:36:33.395540Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Creating a list of sorted unique characters**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Storing all the unique characters present in my corpus to bult a mapping dic. \n",
    "symb = sorted(list(set(Corpus)))\n",
    "\n",
    "L_corpus = len(Corpus) #length of corpus\n",
    "L_symb = len(symb) #length of total unique characters\n",
    "\n",
    "#Building dictionary to access the vocabulary from indices and vice versa\n",
    "mapping = dict((c, i) for i, c in enumerate(symb))\n",
    "reverse_mapping = dict((i, c) for i, c in enumerate(symb))\n",
    "\n",
    "print(\"Total number of characters:\", L_corpus)\n",
    "print(\"Number of unique characters:\", L_symb)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.396388Z",
     "iopub.status.idle": "2023-07-20T14:36:33.396799Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Splitting the Corpus in equal length of strings and output target\n",
    "length = 40\n",
    "features = []\n",
    "targets = []\n",
    "for i in range(0, L_corpus - length, 1):\n",
    "    feature = Corpus[i:i + length]\n",
    "    target = Corpus[i + length]\n",
    "    features.append([mapping[j] for j in feature])\n",
    "    targets.append(mapping[target])\n",
    "    \n",
    "    \n",
    "L_datapoints = len(targets)\n",
    "print(\"Total number of sequences in the Corpus:\", L_datapoints)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.397853Z",
     "iopub.status.idle": "2023-07-20T14:36:33.398270Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Encoding the Labels and Targets**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# reshape X and normalize\n",
    "X = (np.reshape(features, (L_datapoints, length, 1)))/ float(L_symb)\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(targets)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.399163Z",
     "iopub.status.idle": "2023-07-20T14:36:33.399556Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"5\"></a>\n",
    "# <p style=\"background-color:#B291B6;font-family:newtimeroman;font-size:150%;color:#444160;text-align:center;border-radius:20px 60px;\">MODEL BUILDING</p>\n",
    "\n",
    "\n",
    "Recurrent Neural Networks are pretty popular with generating text. In this project, I will be using a LSTM Model, an improved version of a standard recurrent neural network\n",
    "\n",
    "**Following steps are involved in the model building**\n",
    "\n",
    "* Initialising the Model\n",
    "* Defining by adding layers\n",
    "* Compiling the Model\n",
    "* Training the Model\n",
    "\n",
    "**Building the Model**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#Initialising the Model\n",
    "model = Sequential()\n",
    "#Adding layers\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "#Compiling the model for training  \n",
    "opt = Adamax(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "\n",
    "#Model's Summary               \n",
    "model.summary()\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.400379Z",
     "iopub.status.idle": "2023-07-20T14:36:33.400781Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Training the Model\n",
    "history = model.fit(X, y, batch_size=128, epochs=100)"
   ],
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.401579Z",
     "iopub.status.idle": "2023-07-20T14:36:33.401998Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.models import load_model\n",
    "#To be used later; I am saving the model \n",
    "model.save(\"Lyrics_Generator.h5\")"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.402968Z",
     "iopub.status.idle": "2023-07-20T14:36:33.403415Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"6\"></a>\n",
    "# <p style=\"background-color:#B291B6;font-family:newtimeroman;font-size:150%;color:#444160;text-align:center;border-radius:20px 60px;\">EVALUATING MODELS</p>\n",
    "\n",
    "Now that I have my model trained on the songs lyrics let us see how it performs. I hope it creates some sensible song.\n",
    "\n",
    "**To evaluate my model, I shall be having a look at:**\n",
    "* The performance of the model via Learning Curves\n",
    "* The outcome text it generates\n",
    "\n",
    "**Plotting the learning curve for the loss function**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "#Plotting the learnings \n",
    "\n",
    "fig = plt.figure(figsize=(15,4), facecolor=\"#B291B6\")\n",
    "fig.suptitle(\"Learning Plot of Model for Loss\")\n",
    "pl=sns.lineplot(data=history_df[\"loss\"],color=\"#444160\")\n",
    "pl.set(ylabel =\"Training Loss\")\n",
    "pl.set(xlabel =\"Epochs\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.404247Z",
     "iopub.status.idle": "2023-07-20T14:36:33.404699Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Generating the songs**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# The function to generate text from model\n",
    "def Lyrics_Generator(starter,Ch_count): #,temperature=1.0):\n",
    "    generated= \"\"\n",
    "    starter = starter \n",
    "    seed=[mapping[char] for char in starter]\n",
    "    generated += starter \n",
    "    # Generating new text of given length\n",
    "    for i in range(Ch_count):\n",
    "        seed=[mapping[char] for char in starter]\n",
    "        x_pred = np.reshape(seed, (1, len(seed), 1))\n",
    "        x_pred = x_pred/ float(L_symb)\n",
    "        prediction = model.predict(x_pred, verbose=0)[0]  \n",
    "        # Getting the index of the next most probable index\n",
    "        prediction = np.asarray(prediction).astype('float64')\n",
    "        prediction = np.log(prediction) / 1.0 \n",
    "        exp_preds = np.exp(prediction)\n",
    "        prediction = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, prediction, 1)\n",
    "        index = np.argmax(prediction)\n",
    "        next_char = reverse_mapping[index]  \n",
    "        # Generating new text\n",
    "        generated += next_char\n",
    "        starter = starter[1:] + next_char\n",
    "       \n",
    "    return generated"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.405549Z",
     "iopub.status.idle": "2023-07-20T14:36:33.405992Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us finally see the outcome by putting a seed in from one of my old blogposts [blogpost](https://karnikakapoor.blogspot.com/2017/04/killers-confession.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#Generating a song from the model\n",
    "song_1 = Lyrics_Generator(\"the shoe shrunk, and the school belt got ridiculously petit\", 400)\n",
    "#Let's have a look at the song\n",
    "My_song(song_1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.406859Z",
     "iopub.status.idle": "2023-07-20T14:36:33.407504Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another song generated by a seed of the lyrics of a song that's stuck in my head today. (Sunflower by Shannon Purser)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#Generating a song from the model using a song out of the corpus\n",
    "song_2 = Lyrics_Generator(\"i'm a sunflower, a little funny\", 400)\n",
    "#Let's have a look at the song\n",
    "My_song(song_2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-20T14:36:33.408420Z",
     "iopub.status.idle": "2023-07-20T14:36:33.408848Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"7\"></a>\n",
    "# <p style=\"background-color:#B291B6;font-family:newtimeroman;font-size:150%;color:#444160;text-align:center;border-radius:20px 60px;\">CONCLUSION</p>\n",
    "<p style=\"font-family:newtimeroman;font-size:120%;color:#444160\">On observing the output of the Lyrics Generator, it is clear that while some of the sentences might be correct, but most of the lyrics do not make sense. It does look like a song tho. The model didn't learn the meaning of the songs. However, the character-based approach is producing some legitimate words. \n",
    "To get to a song that makes better sense I may consider a transformer-based text generator, but that's for some other time.</p>\n",
    "\n",
    "<p style=\"font-family:newtimeroman;font-size:120%;color:#444160;\"> Neural networks amaze me all the time. There is something surreal about them that makes working with it exciting. Of course, we can peel off the layers and see the maths behind them. Get to the matrices and tensor to understand how these neurons are working. Even get the values of weights and biases and assure ourselves that this is no sorcery.  Still, when I see the result play out it is astonishing.</p>  \n",
    "\n",
    "**Some useful resources on Text generation:**\n",
    "\n",
    "[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "\n",
    "[RNN ](https://towardsdatascience.com/character-level-language-model-1439f5dd87fe)\n",
    "\n",
    "[GTP-2 ](https://openai.com/blog/better-language-models/) \n",
    "\n",
    "\n",
    "**<span style=\"color:#444160;\"> If you liked this Notebook, please do upvote.</span>**\n",
    "\n",
    "**<span style=\"color:#444160;\"> Best Wishes!</span>**\n",
    "\n",
    "<a id=\"8\"></a>\n",
    "# <p style=\"background-color:#B291B6;font-family:newtimeroman;font-size:150%;color:#444160;text-align:center;border-radius:20px 60px;\">END</p>"
   ],
   "metadata": {}
  }
 ]
}
