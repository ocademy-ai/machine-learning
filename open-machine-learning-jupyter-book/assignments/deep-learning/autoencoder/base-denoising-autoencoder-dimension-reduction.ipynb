{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d36c4e11",
   "metadata": {
    "papermill": {
     "duration": 0.037292,
     "end_time": "2022-02-14T01:36:39.437942",
     "exception": false,
     "start_time": "2022-02-14T01:36:39.400650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Base/Denoising Autoencoder & Dimension Reduction\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0d14aca",
   "metadata": {
    "papermill": {
     "duration": 0.034677,
     "end_time": "2022-02-14T01:36:39.507409",
     "exception": false,
     "start_time": "2022-02-14T01:36:39.472732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![](https://static-1300131294.cos.ap-shanghai.myqcloud.com/data/deep-learning/autoencoder/base-denoising-autoencoder-dimension-reduction/base_noise.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95248e0d",
   "metadata": {
    "papermill": {
     "duration": 0.034091,
     "end_time": "2022-02-14T01:36:39.576273",
     "exception": false,
     "start_time": "2022-02-14T01:36:39.542182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Autoencoder is a neural network that simply copies input to output. In some ways, it looks like a simple neural network, but it makes a difficult neural network by constraining the network in various ways. For example, the number of neurons in the hidden layer is smaller than that of the input layer to compress the data (reduce the dimension), or add noise to the input data and then restore the original input. There are various autoencoders, such as learning These constraints prevent the autoencoder from simply copying the input directly to the output, and control it to learn how to represent the data efficiently.\n",
    "\n",
    "In this notebook, we will cover two autoencoders:\n",
    "* **Base AutoEncoder**\n",
    "* **Denoising Autoencoder**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aaab51",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-02-14T01:36:39.724387Z",
     "iopub.status.busy": "2022-02-14T01:36:39.723574Z",
     "iopub.status.idle": "2022-02-14T01:36:44.685856Z",
     "shell.execute_reply": "2022-02-14T01:36:44.685263Z",
     "shell.execute_reply.started": "2021-12-24T14:32:34.971031Z"
    },
    "papermill": {
     "duration": 5.076383,
     "end_time": "2022-02-14T01:36:44.686013",
     "exception": false,
     "start_time": "2022-02-14T01:36:39.609630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3044c352",
   "metadata": {
    "papermill": {
     "duration": 0.032242,
     "end_time": "2022-02-14T01:36:44.751118",
     "exception": false,
     "start_time": "2022-02-14T01:36:44.718876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading and Scaling Datasets\n",
    "Train a basic autoencoder using the Fashon MNIST dataset. Each image in this dataset is 28x28 pixels.\n",
    "Inputs are scaled for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a420fc6",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-02-14T01:36:44.821035Z",
     "iopub.status.busy": "2022-02-14T01:36:44.820220Z",
     "iopub.status.idle": "2022-02-14T01:36:45.941753Z",
     "shell.execute_reply": "2022-02-14T01:36:45.941087Z",
     "shell.execute_reply.started": "2021-12-24T14:32:41.165982Z"
    },
    "papermill": {
     "duration": 1.158364,
     "end_time": "2022-02-14T01:36:45.941945",
     "exception": false,
     "start_time": "2022-02-14T01:36:44.783581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64b135",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7fb026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c65e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://static-1300131294.cos.ap-shanghai.myqcloud.com/data/deep-learning/autoencoder/base-denoising-autoencoder-dimension-reduction/base-denoising-autoencoder-dimension-reduction_model.zip\"\n",
    "\n",
    "notebook_path = os.getcwd()\n",
    "\n",
    "tmp_folder_path = os.path.join(notebook_path, \"tmp\")\n",
    "\n",
    "if not os.path.exists(tmp_folder_path):\n",
    "    os.makedirs(tmp_folder_path)\n",
    "\n",
    "file_path = os.path.join(tmp_folder_path,\"base-denoising-autoencoder-dimension-reduction\")\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path)\n",
    "\n",
    "zip_store_path = os.path.join(file_path, \"zip-store\")\n",
    "\n",
    "if not os.path.exists(zip_store_path):\n",
    "    os.makedirs(zip_store_path)\n",
    "\n",
    "model_response = requests.get(model_url)\n",
    "\n",
    "model_name = os.path.basename(model_url)\n",
    "\n",
    "model_save_path = os.path.join(zip_store_path, model_name)\n",
    "\n",
    "with open(model_save_path, \"wb\") as file:\n",
    "    file.write(model_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33335ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = f\"./tmp/base-denoising-autoencoder-dimension-reduction/zip-store/{model_name}\"\n",
    "extract_path = \"./tmp/base-denoising-autoencoder-dimension-reduction/base-denoising-autoencoder-dimension-reduction_model\"\n",
    "\n",
    "zip_ref = zipfile.ZipFile(zip_file_path, 'r')\n",
    "zip_ref.extractall(extract_path)\n",
    "zip_ref.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fece7eed",
   "metadata": {
    "papermill": {
     "duration": 0.038544,
     "end_time": "2022-02-14T01:36:46.017472",
     "exception": false,
     "start_time": "2022-02-14T01:36:45.978928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Checking dataset by 2D plot\n",
    "\n",
    "Autoencoding can be thought of as a kind of dimensionality reduction process. Therefore, after compressing the fashion MNIST dataset through UMAP in two dimensions, let's check how it is mapped for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e77bce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:36:46.094757Z",
     "iopub.status.busy": "2022-02-14T01:36:46.094004Z",
     "iopub.status.idle": "2022-02-14T01:36:46.096430Z",
     "shell.execute_reply": "2022-02-14T01:36:46.096035Z",
     "shell.execute_reply.started": "2021-12-24T14:32:43.475712Z"
    },
    "papermill": {
     "duration": 0.041663,
     "end_time": "2022-02-14T01:36:46.096535",
     "exception": false,
     "start_time": "2022-02-14T01:36:46.054872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc285986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:36:46.171899Z",
     "iopub.status.busy": "2022-02-14T01:36:46.171131Z",
     "iopub.status.idle": "2022-02-14T01:36:46.173138Z",
     "shell.execute_reply": "2022-02-14T01:36:46.173498Z",
     "shell.execute_reply.started": "2021-12-24T14:32:43.486619Z"
    },
    "papermill": {
     "duration": 0.041837,
     "end_time": "2022-02-14T01:36:46.173617",
     "exception": false,
     "start_time": "2022-02-14T01:36:46.131780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = { 0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', \n",
    "          5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8 : 'Bag', 9 : 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cffc9f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:36:46.255848Z",
     "iopub.status.busy": "2022-02-14T01:36:46.255093Z",
     "iopub.status.idle": "2022-02-14T01:36:46.264195Z",
     "shell.execute_reply": "2022-02-14T01:36:46.264571Z",
     "shell.execute_reply.started": "2021-12-24T14:32:43.497126Z"
    },
    "papermill": {
     "duration": 0.055676,
     "end_time": "2022-02-14T01:36:46.264695",
     "exception": false,
     "start_time": "2022-02-14T01:36:46.209019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train,columns=['class'])\n",
    "y_train[\"class\"].replace(labels, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be349a9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:36:46.343261Z",
     "iopub.status.busy": "2022-02-14T01:36:46.342618Z",
     "iopub.status.idle": "2022-02-14T01:38:31.942920Z",
     "shell.execute_reply": "2022-02-14T01:38:31.943348Z",
     "shell.execute_reply.started": "2021-12-24T14:32:43.524337Z"
    },
    "papermill": {
     "duration": 105.642345,
     "end_time": "2022-02-14T01:38:31.943512",
     "exception": false,
     "start_time": "2022-02-14T01:36:46.301167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import umap.plot\n",
    "mapper_org = umap.UMAP().fit(x_train_flat)\n",
    "umap.plot.points(mapper_org, labels=y_train[\"class\"], theme='fire')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471009ae",
   "metadata": {
    "papermill": {
     "duration": 0.044414,
     "end_time": "2022-02-14T01:38:32.032658",
     "exception": false,
     "start_time": "2022-02-14T01:38:31.988244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Looking at the distribution of data projected in two dimensions, it seems that compression with an autoencoder would be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765a806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:38:32.126354Z",
     "iopub.status.busy": "2022-02-14T01:38:32.125097Z",
     "iopub.status.idle": "2022-02-14T01:38:45.774951Z",
     "shell.execute_reply": "2022-02-14T01:38:45.775360Z",
     "shell.execute_reply.started": "2021-12-24T14:34:52.345191Z"
    },
    "papermill": {
     "duration": 13.698481,
     "end_time": "2022-02-14T01:38:45.775504",
     "exception": false,
     "start_time": "2022-02-14T01:38:32.077023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "umap.plot.connectivity(mapper_org, show_points=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff16c1",
   "metadata": {
    "papermill": {
     "duration": 0.053947,
     "end_time": "2022-02-14T01:38:45.883322",
     "exception": false,
     "start_time": "2022-02-14T01:38:45.829375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> UMAP works by constructing an intermediate topological representation of the approximate manifold the data may have been sampled from. In practice this structure can be simplified down to a weighted graph. Sometimes it can be beneficial to see how that graph (representing connectivity in the manifold) looks with respect to the resulting embedding. It can be used to better understand the embedding, and for diagnostic purposes. \n",
    "\n",
    "Ref: https://umap-learn.readthedocs.io/en"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "091849d2",
   "metadata": {
    "papermill": {
     "duration": 0.053762,
     "end_time": "2022-02-14T01:38:45.990514",
     "exception": false,
     "start_time": "2022-02-14T01:38:45.936752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Checking dataset by 3D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3dfd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:38:46.104787Z",
     "iopub.status.busy": "2022-02-14T01:38:46.104197Z",
     "iopub.status.idle": "2022-02-14T01:40:06.619020Z",
     "shell.execute_reply": "2022-02-14T01:40:06.619428Z",
     "shell.execute_reply.started": "2021-12-24T14:35:09.123673Z"
    },
    "papermill": {
     "duration": 80.575679,
     "end_time": "2022-02-14T01:40:06.619584",
     "exception": false,
     "start_time": "2022-02-14T01:38:46.043905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px\n",
    "from umap import UMAP\n",
    "\n",
    "umap_3d = UMAP(n_components=3, init='random', random_state=0)\n",
    "x_umap = umap_3d.fit_transform(x_train_flat)\n",
    "umap_df = pd.DataFrame(x_umap)\n",
    "new_df = pd.concat([umap_df,y_train[\"class\"]],axis=1)\n",
    "fig = px.scatter_3d(\n",
    "    new_df, x=0, y=1, z=2,\n",
    "    color='class', labels={'color': 'class'}\n",
    ")\n",
    "fig.update_traces(marker_size=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e88e8d",
   "metadata": {
    "papermill": {
     "duration": 0.116031,
     "end_time": "2022-02-14T01:40:06.851669",
     "exception": false,
     "start_time": "2022-02-14T01:40:06.735638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have approximated the distribution of the training dataset we want to train with 2D and 3D compressed datasets. Autoencoder is another compression method using neural networks.\n",
    "\n",
    "**Now, let's do modeling and training for Autoencoder.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e345f48",
   "metadata": {
    "papermill": {
     "duration": 0.115,
     "end_time": "2022-02-14T01:40:07.082706",
     "exception": false,
     "start_time": "2022-02-14T01:40:06.967706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Base Autoencoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1432432c",
   "metadata": {
    "papermill": {
     "duration": 0.115165,
     "end_time": "2022-02-14T01:40:07.313274",
     "exception": false,
     "start_time": "2022-02-14T01:40:07.198109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "### Modeling\n",
    "An autoencoder always consists of two parts: an encoder and a decoder.\n",
    "* Encoder (Recognition network): it transforms an input into an internal representation.\n",
    "* Decoder (generative network): it transforms an internal representation into an output.\n",
    "\n",
    "The autoencoder has the same structure as a general MLP (Multi-Layer Perceptron) except that the number of neurons in the input and output layers is same. Since the autoencoder reconstructs the input, the output is also called reconstruction, and the loss function is calculated with the difference between the input and the reconstruction (output).\n",
    "\n",
    "The neurons (nodes, units) of the hidden layer are smaller than the input layer, so the input is expressed in a low-dimensional manner. Such an autoencoder is called an undercomplete autoencoder. Because an undercomplete autoencoder cannot copy the input to the output as it is by a hidden layer with low dimensions, the output must learn to output the same as the input. Through this learning, the undercomplete autoencoder learns the most important features from the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd19578",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-02-14T01:40:07.551621Z",
     "iopub.status.busy": "2022-02-14T01:40:07.551066Z",
     "iopub.status.idle": "2022-02-14T01:40:11.000799Z",
     "shell.execute_reply": "2022-02-14T01:40:11.000277Z",
     "shell.execute_reply.started": "2021-12-24T14:36:51.643964Z"
    },
    "papermill": {
     "duration": 3.572095,
     "end_time": "2022-02-14T01:40:11.001048",
     "exception": false,
     "start_time": "2022-02-14T01:40:07.428953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_dim = 64 \n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, encoding_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),                  # (1,784)\n",
    "      layers.Dense(latent_dim, activation='relu'),  \n",
    "    ])                                   # (1,784)(784,64) => (1,64)\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(784, activation='sigmoid'),\n",
    "      layers.Reshape((28, 28))           # (1,64)(64,784) => (1,784) => (1,28,28)\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "  \n",
    "autoencoder = Autoencoder(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9224eebf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:40:11.250838Z",
     "iopub.status.busy": "2022-02-14T01:40:11.249968Z",
     "iopub.status.idle": "2022-02-14T01:40:11.258333Z",
     "shell.execute_reply": "2022-02-14T01:40:11.257447Z",
     "shell.execute_reply.started": "2021-12-24T14:36:55.788289Z"
    },
    "papermill": {
     "duration": 0.134713,
     "end_time": "2022-02-14T01:40:11.258450",
     "exception": false,
     "start_time": "2022-02-14T01:40:11.123737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81781f77",
   "metadata": {
    "papermill": {
     "duration": 0.211999,
     "end_time": "2022-02-14T01:40:11.585344",
     "exception": false,
     "start_time": "2022-02-14T01:40:11.373345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training\n",
    "\n",
    "Train the model using x_train as input and target. The encoder learns to compress the dataset into a latent space in 784 dimensions, and the decoder learns to reconstruct the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e59cb",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-02-14T01:40:11.967045Z",
     "iopub.status.busy": "2022-02-14T01:40:11.966385Z",
     "iopub.status.idle": "2022-02-14T01:40:44.887561Z",
     "shell.execute_reply": "2022-02-14T01:40:44.886907Z",
     "shell.execute_reply.started": "2021-12-24T14:36:55.811916Z"
    },
    "papermill": {
     "duration": 33.095092,
     "end_time": "2022-02-14T01:40:44.887749",
     "exception": false,
     "start_time": "2022-02-14T01:40:11.792657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# autoencoder.fit(x_train, x_train,\n",
    "#                 epochs=10,\n",
    "#                 shuffle=True,\n",
    "#                 validation_data=(x_test, x_test))\n",
    "\n",
    "# autoencoder.save(\"base-denoising-autoencoder-dimension-reduction_model\", save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dc8a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabda73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = tf.keras.models.load_model('./tmp/base-denoising-autoencoder-dimension-reduction/base-denoising-autoencoder-dimension-reduction_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e4342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:40:45.491342Z",
     "iopub.status.busy": "2022-02-14T01:40:45.490212Z",
     "iopub.status.idle": "2022-02-14T01:40:45.527653Z",
     "shell.execute_reply": "2022-02-14T01:40:45.527225Z",
     "shell.execute_reply.started": "2021-12-24T14:37:39.32293Z"
    },
    "papermill": {
     "duration": 0.311475,
     "end_time": "2022-02-14T01:40:45.527777",
     "exception": false,
     "start_time": "2022-02-14T01:40:45.216302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86673c20",
   "metadata": {
    "papermill": {
     "duration": 0.247633,
     "end_time": "2022-02-14T01:40:46.027955",
     "exception": false,
     "start_time": "2022-02-14T01:40:45.780322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Plotting the latent space after Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad13dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:40:46.536120Z",
     "iopub.status.busy": "2022-02-14T01:40:46.535307Z",
     "iopub.status.idle": "2022-02-14T01:40:46.539633Z",
     "shell.execute_reply": "2022-02-14T01:40:46.539220Z",
     "shell.execute_reply.started": "2021-12-24T14:37:39.38248Z"
    },
    "papermill": {
     "duration": 0.26028,
     "end_time": "2022-02-14T01:40:46.539750",
     "exception": false,
     "start_time": "2022-02-14T01:40:46.279470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test,columns=['class'])\n",
    "y_test[\"class\"].replace(labels, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d290be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:40:47.053275Z",
     "iopub.status.busy": "2022-02-14T01:40:47.052412Z",
     "iopub.status.idle": "2022-02-14T01:41:08.251708Z",
     "shell.execute_reply": "2022-02-14T01:41:08.252146Z",
     "shell.execute_reply.started": "2021-12-24T14:37:39.396999Z"
    },
    "papermill": {
     "duration": 21.462418,
     "end_time": "2022-02-14T01:41:08.252299",
     "exception": false,
     "start_time": "2022-02-14T01:40:46.789881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapper = umap.UMAP().fit(encoded_imgs)\n",
    "umap.plot.points(mapper, labels=y_test[\"class\"],theme='fire')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab47cae2",
   "metadata": {
    "papermill": {
     "duration": 0.262616,
     "end_time": "2022-02-14T01:41:08.771940",
     "exception": false,
     "start_time": "2022-02-14T01:41:08.509324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The $28*28$ dimension input is compressed into the $7*7$ latent space by the encoder. The latent space is compressed into 2D using Dimension Reduction. Although it is an approximate expression, it can be seen that each class is well clustered in the compressed latent space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8a3db99",
   "metadata": {
    "papermill": {
     "duration": 0.257116,
     "end_time": "2022-02-14T01:41:09.287991",
     "exception": false,
     "start_time": "2022-02-14T01:41:09.030875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Checking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1303b64d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:41:09.852270Z",
     "iopub.status.busy": "2022-02-14T01:41:09.831177Z",
     "iopub.status.idle": "2022-02-14T01:41:10.290932Z",
     "shell.execute_reply": "2022-02-14T01:41:10.290484Z",
     "shell.execute_reply.started": "2021-12-24T14:43:11.829954Z"
    },
    "papermill": {
     "duration": 0.745567,
     "end_time": "2022-02-14T01:41:10.291066",
     "exception": false,
     "start_time": "2022-02-14T01:41:09.545499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(n):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, n, i + 1)\n",
    "  plt.imshow(x_test[i])\n",
    "  plt.title(\"original\",fontsize=20)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reconstruction\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  plt.imshow(decoded_imgs[i])\n",
    "  plt.title(\"reconstructed\",fontsize=20)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf21b9",
   "metadata": {
    "papermill": {
     "duration": 0.255538,
     "end_time": "2022-02-14T01:41:10.864636",
     "exception": false,
     "start_time": "2022-02-14T01:41:10.609098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Looking at the result, the reconstructed image looks a little blurry. However, it can be confirmed that the overall characteristics are expressed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7d3260c",
   "metadata": {
    "papermill": {
     "duration": 0.256595,
     "end_time": "2022-02-14T01:41:11.382260",
     "exception": false,
     "start_time": "2022-02-14T01:41:11.125665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0cddba",
   "metadata": {
    "papermill": {
     "duration": 0.258844,
     "end_time": "2022-02-14T01:41:11.900564",
     "exception": false,
     "start_time": "2022-02-14T01:41:11.641720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Another way to constrain the autoencoder to learn meaningful features is to add noise to the input and train it to reconstruct the original noise-free input. Noise can be generated by adding Gaussian noise to the input as shown in the figure below, or by randomly turning off the input unit (node) like a dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d67929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:41:12.428605Z",
     "iopub.status.busy": "2022-02-14T01:41:12.427769Z",
     "iopub.status.idle": "2022-02-14T01:41:12.818135Z",
     "shell.execute_reply": "2022-02-14T01:41:12.817616Z",
     "shell.execute_reply.started": "2021-12-24T14:38:03.828039Z"
    },
    "papermill": {
     "duration": 0.655467,
     "end_time": "2022-02-14T01:41:12.818265",
     "exception": false,
     "start_time": "2022-02-14T01:41:12.162798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad59a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:41:13.351849Z",
     "iopub.status.busy": "2022-02-14T01:41:13.350691Z",
     "iopub.status.idle": "2022-02-14T01:41:13.427120Z",
     "shell.execute_reply": "2022-02-14T01:41:13.427507Z",
     "shell.execute_reply.started": "2021-12-24T14:38:04.302593Z"
    },
    "papermill": {
     "duration": 0.344422,
     "end_time": "2022-02-14T01:41:13.427660",
     "exception": false,
     "start_time": "2022-02-14T01:41:13.083238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6860659e",
   "metadata": {
    "papermill": {
     "duration": 0.264236,
     "end_time": "2022-02-14T01:41:13.950082",
     "exception": false,
     "start_time": "2022-02-14T01:41:13.685846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Adding random noise to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d6667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:41:14.475225Z",
     "iopub.status.busy": "2022-02-14T01:41:14.474271Z",
     "iopub.status.idle": "2022-02-14T01:41:14.681293Z",
     "shell.execute_reply": "2022-02-14T01:41:14.680711Z",
     "shell.execute_reply.started": "2021-12-24T14:38:04.409506Z"
    },
    "papermill": {
     "duration": 0.473086,
     "end_time": "2022-02-14T01:41:14.681439",
     "exception": false,
     "start_time": "2022-02-14T01:41:14.208353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.2\n",
    "x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape) \n",
    "\n",
    "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2812449b",
   "metadata": {
    "papermill": {
     "duration": 0.260944,
     "end_time": "2022-02-14T01:41:15.201551",
     "exception": false,
     "start_time": "2022-02-14T01:41:14.940607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Plotting a noisy image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83bcf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:41:15.745222Z",
     "iopub.status.busy": "2022-02-14T01:41:15.742661Z",
     "iopub.status.idle": "2022-02-14T01:41:16.196776Z",
     "shell.execute_reply": "2022-02-14T01:41:16.196351Z",
     "shell.execute_reply.started": "2021-12-24T14:44:44.194779Z"
    },
    "papermill": {
     "duration": 0.734577,
     "end_time": "2022-02-14T01:41:16.196926",
     "exception": false,
     "start_time": "2022-02-14T01:41:15.462349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.title(\"original + noise\",fontsize=20)\n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "    plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d50a0b38",
   "metadata": {
    "papermill": {
     "duration": 0.281413,
     "end_time": "2022-02-14T01:41:16.753064",
     "exception": false,
     "start_time": "2022-02-14T01:41:16.471651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Checking Noisy Dataset using Demension Reduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "135ff550",
   "metadata": {
    "papermill": {
     "duration": 0.280642,
     "end_time": "2022-02-14T01:41:17.323122",
     "exception": false,
     "start_time": "2022-02-14T01:41:17.042480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 1) Noisy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf9307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:41:18.191342Z",
     "iopub.status.busy": "2022-02-14T01:41:18.189606Z",
     "iopub.status.idle": "2022-02-14T01:41:18.192028Z",
     "shell.execute_reply": "2022-02-14T01:41:18.192551Z",
     "shell.execute_reply.started": "2021-12-24T14:38:05.267577Z"
    },
    "papermill": {
     "duration": 0.418953,
     "end_time": "2022-02-14T01:41:18.192725",
     "exception": false,
     "start_time": "2022-02-14T01:41:17.773772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_noisy_flat = x_train.reshape(x_train_noisy.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89d9fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:41:18.744799Z",
     "iopub.status.busy": "2022-02-14T01:41:18.744092Z",
     "iopub.status.idle": "2022-02-14T01:41:18.751512Z",
     "shell.execute_reply": "2022-02-14T01:41:18.751032Z",
     "shell.execute_reply.started": "2021-12-24T14:38:05.275427Z"
    },
    "papermill": {
     "duration": 0.277743,
     "end_time": "2022-02-14T01:41:18.751666",
     "exception": false,
     "start_time": "2022-02-14T01:41:18.473923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train,columns=['class'])\n",
    "y_train[\"class\"].replace(labels, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f1711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:41:19.297120Z",
     "iopub.status.busy": "2022-02-14T01:41:19.296176Z",
     "iopub.status.idle": "2022-02-14T01:42:24.363974Z",
     "shell.execute_reply": "2022-02-14T01:42:24.364882Z",
     "shell.execute_reply.started": "2021-12-24T14:38:05.292937Z"
    },
    "papermill": {
     "duration": 65.347813,
     "end_time": "2022-02-14T01:42:24.365128",
     "exception": false,
     "start_time": "2022-02-14T01:41:19.017315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapper_noisy = umap.UMAP().fit(x_train_noisy_flat)\n",
    "umap.plot.points(mapper_noisy, labels=y_train['class'], theme='fire')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e26e350",
   "metadata": {
    "papermill": {
     "duration": 0.411679,
     "end_time": "2022-02-14T01:42:25.215866",
     "exception": false,
     "start_time": "2022-02-14T01:42:24.804187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2) Orignal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92bfbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:42:25.757074Z",
     "iopub.status.busy": "2022-02-14T01:42:25.755448Z",
     "iopub.status.idle": "2022-02-14T01:42:25.757647Z",
     "shell.execute_reply": "2022-02-14T01:42:25.758086Z",
     "shell.execute_reply.started": "2021-12-24T14:39:22.894574Z"
    },
    "papermill": {
     "duration": 0.277099,
     "end_time": "2022-02-14T01:42:25.758228",
     "exception": false,
     "start_time": "2022-02-14T01:42:25.481129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c35a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:42:26.317256Z",
     "iopub.status.busy": "2022-02-14T01:42:26.316205Z",
     "iopub.status.idle": "2022-02-14T01:43:32.042714Z",
     "shell.execute_reply": "2022-02-14T01:43:32.043172Z",
     "shell.execute_reply.started": "2021-12-24T14:39:22.905747Z"
    },
    "papermill": {
     "duration": 66.019848,
     "end_time": "2022-02-14T01:43:32.043333",
     "exception": false,
     "start_time": "2022-02-14T01:42:26.023485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapper_org = umap.UMAP().fit(x_train_flat)\n",
    "umap.plot.points(mapper_org, labels=y_train['class'], theme='fire')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068477a",
   "metadata": {
    "papermill": {
     "duration": 0.311967,
     "end_time": "2022-02-14T01:43:32.649913",
     "exception": false,
     "start_time": "2022-02-14T01:43:32.337946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When looking at the two-dimensionally scaled-down pictures, the difference is not very visible. However, if you look at the picture on the upper right, you can see that the distribution of the blue dots is slightly different. Also, the distribution of purple has changed.\n",
    "In any case, the visually large noise does not show much difference after dimensionality reduction.\n",
    "\n",
    "The image observed with our eyes may appear to be noisy, but from the model's point of view the noise may not be so great!\n",
    "\n",
    "Now let's do some modeling and training with this noisy dateset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8b387ad",
   "metadata": {
    "papermill": {
     "duration": 0.273034,
     "end_time": "2022-02-14T01:43:33.204745",
     "exception": false,
     "start_time": "2022-02-14T01:43:32.931711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b409af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:43:33.768089Z",
     "iopub.status.busy": "2022-02-14T01:43:33.767145Z",
     "iopub.status.idle": "2022-02-14T01:43:33.804741Z",
     "shell.execute_reply": "2022-02-14T01:43:33.804281Z",
     "shell.execute_reply.started": "2021-12-24T14:40:41.276446Z"
    },
    "papermill": {
     "duration": 0.326832,
     "end_time": "2022-02-14T01:43:33.804888",
     "exception": false,
     "start_time": "2022-02-14T01:43:33.478056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Denoise(Model):\n",
    "  def __init__(self):\n",
    "    super(Denoise, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Input(shape=(28, 28, 1)), \n",
    "      layers.Conv2D(16, (3,3), activation='relu', padding='same', strides=2),\n",
    "      layers.Conv2D(8, (3,3), activation='relu', padding='same', strides=2)])\n",
    "    \n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2D(1, kernel_size=(3,3), activation='sigmoid', padding='same')])\n",
    "    \n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = Denoise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025dfaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:43:34.395756Z",
     "iopub.status.busy": "2022-02-14T01:43:34.394940Z",
     "iopub.status.idle": "2022-02-14T01:43:34.399721Z",
     "shell.execute_reply": "2022-02-14T01:43:34.399298Z",
     "shell.execute_reply.started": "2021-12-24T14:40:41.334381Z"
    },
    "papermill": {
     "duration": 0.296221,
     "end_time": "2022-02-14T01:43:34.399868",
     "exception": false,
     "start_time": "2022-02-14T01:43:34.103647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31646f09",
   "metadata": {
    "papermill": {
     "duration": 0.273906,
     "end_time": "2022-02-14T01:43:34.947170",
     "exception": false,
     "start_time": "2022-02-14T01:43:34.673264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a2e5c",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-02-14T01:43:35.500142Z",
     "iopub.status.busy": "2022-02-14T01:43:35.499346Z",
     "iopub.status.idle": "2022-02-14T01:44:38.536757Z",
     "shell.execute_reply": "2022-02-14T01:44:38.536300Z",
     "shell.execute_reply.started": "2021-12-24T14:40:41.35025Z"
    },
    "papermill": {
     "duration": 63.314959,
     "end_time": "2022-02-14T01:44:38.536920",
     "exception": false,
     "start_time": "2022-02-14T01:43:35.221961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa00976",
   "metadata": {
    "papermill": {
     "duration": 0.526129,
     "end_time": "2022-02-14T01:44:39.619522",
     "exception": false,
     "start_time": "2022-02-14T01:44:39.093393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's take a look at the encoder summary. The image is downsampled from 28x28 to 7x7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab7884",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:44:40.760785Z",
     "iopub.status.busy": "2022-02-14T01:44:40.759379Z",
     "iopub.status.idle": "2022-02-14T01:44:40.764382Z",
     "shell.execute_reply": "2022-02-14T01:44:40.763966Z",
     "shell.execute_reply.started": "2021-12-24T14:42:14.928178Z"
    },
    "papermill": {
     "duration": 0.572635,
     "end_time": "2022-02-14T01:44:40.764518",
     "exception": false,
     "start_time": "2022-02-14T01:44:40.191883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder.encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b39b05",
   "metadata": {
    "papermill": {
     "duration": 0.557538,
     "end_time": "2022-02-14T01:44:41.850842",
     "exception": false,
     "start_time": "2022-02-14T01:44:41.293304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The decoder upsamples the image back from 7x7 to 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd70c7e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:44:42.926091Z",
     "iopub.status.busy": "2022-02-14T01:44:42.924213Z",
     "iopub.status.idle": "2022-02-14T01:44:42.931832Z",
     "shell.execute_reply": "2022-02-14T01:44:42.931213Z",
     "shell.execute_reply.started": "2021-12-24T14:42:14.943464Z"
    },
    "papermill": {
     "duration": 0.550538,
     "end_time": "2022-02-14T01:44:42.931989",
     "exception": false,
     "start_time": "2022-02-14T01:44:42.381451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f487fe29",
   "metadata": {
    "papermill": {
     "duration": 0.539726,
     "end_time": "2022-02-14T01:44:43.998928",
     "exception": false,
     "start_time": "2022-02-14T01:44:43.459202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Checking results\n",
    "\n",
    "Plots both the noisy and denoised images generated by the autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eefb472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:44:45.098298Z",
     "iopub.status.busy": "2022-02-14T01:44:45.097185Z",
     "iopub.status.idle": "2022-02-14T01:44:45.382919Z",
     "shell.execute_reply": "2022-02-14T01:44:45.382403Z",
     "shell.execute_reply.started": "2021-12-24T14:42:14.963441Z"
    },
    "papermill": {
     "duration": 0.842337,
     "end_time": "2022-02-14T01:44:45.383051",
     "exception": false,
     "start_time": "2022-02-14T01:44:44.540714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88271c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T01:44:46.663207Z",
     "iopub.status.busy": "2022-02-14T01:44:46.660759Z",
     "iopub.status.idle": "2022-02-14T01:44:47.267671Z",
     "shell.execute_reply": "2022-02-14T01:44:47.268131Z",
     "shell.execute_reply.started": "2021-12-24T14:44:19.926777Z"
    },
    "papermill": {
     "duration": 1.294568,
     "end_time": "2022-02-14T01:44:47.268287",
     "exception": false,
     "start_time": "2022-02-14T01:44:45.973719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(n):\n",
    "\n",
    "    # display original + noise\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.title(\"original + noise\",fontsize=20)\n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    bx = plt.subplot(2, n, i + n + 1)\n",
    "    plt.title(\"reconstructed\",fontsize=20)\n",
    "    plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
    "    plt.gray()\n",
    "    bx.get_xaxis().set_visible(False)\n",
    "    bx.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "385bba08",
   "metadata": {
    "papermill": {
     "duration": 0.590302,
     "end_time": "2022-02-14T01:44:48.455735",
     "exception": false,
     "start_time": "2022-02-14T01:44:47.865433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Acknowledgments\n",
    "\n",
    "Thanks to TOH SEOK KIM for creating the Kaggle open-source project [Base/Denoising Autoencoder + Dimension Reduction](https://www.kaggle.com/code/ohseokkim/base-denoising-autoencoder-dimension-reduction). It inspires the majority of the content in this chapter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 500.149377,
   "end_time": "2022-02-14T01:44:52.985746",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-14T01:36:32.836369",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
