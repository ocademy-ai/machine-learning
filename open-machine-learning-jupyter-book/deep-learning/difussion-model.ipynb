{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eQbVEk-ef2Sb",
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Install the necessary dependencies\n",
        "\n",
        "import os\n",
        "import sys\n",
        "!{sys.executable} -m pip install --quiet pandas scikit-learn numpy matplotlib jupyterlab_myst ipython tensorflow_addons opencv-python requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsposoggf2Sf",
        "tags": [
          "remove-cell"
        ]
      },
      "source": [
        "---\n",
        "license:\n",
        "    code: MIT\n",
        "    content: CC-BY-4.0\n",
        "github: https://github.com/ocademy-ai/machine-learning\n",
        "venue: By Ocademy\n",
        "open_access: true\n",
        "bibliography:\n",
        "  - https://raw.githubusercontent.com/ocademy-ai/machine-learning/main/open-machine-learning-jupyter-book/references.bib\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbY9A-fGf2Sg"
      },
      "source": [
        "# Diffusion Model\n",
        "\n",
        "Diffusion model in deep learning is a type of generative model. The core idea of this model is to generate data by gradually adding noise. Specifically, diffusion models achieve data generation through two processes: diffusion process and inverse diffusion process.\n",
        "\n",
        "Forward Diffusion Process: In this process, the model gradually adds noise to the data, making it increasingly random and unpredictable.\n",
        "Reverse Diffusion Process: This process attempts to gradually remove the added noise, gradually restoring the data to its original state.\n",
        "\n",
        "By alternately applying these two processes, diffusion models can generate high-quality data samples.\n",
        "\n",
        "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/04_frdiffusion.png\" width=\"90%\" class=\"bg-white mb-1\">\n",
        "\n",
        "## Background\n",
        "\n",
        "Before we learn the diffusion model, we have to know some background knowledge in statistics. Perhaps you already have a good mastery of them, let's review them together.\n",
        "\n",
        "### Expectation\n",
        "\n",
        "#### Definition\n",
        "\n",
        "In probability theory, expectation (also called expected value, mean, average) is a generalization of the weighted average.\n",
        "\n",
        "$E[X] = x_1 p_1 + x_2 p2 + ... +x_n p_n = \\sum_{i=1}^n x_i p_1$\n",
        "\n",
        "where $x_i$ and $p_i$ are i-th a possible outcome and its probability, respectively.\n",
        "\n",
        "#### Properties\n",
        "\n",
        "- $E[aX]=aE[X]$ where a is a constant value.\n",
        "- $E[X+b]=E[X]+b$ where b is a constant value.\n",
        "- $E[X+Y]=E[X]+E[Y]$.\n",
        "\n",
        "### Variance\n",
        "\n",
        "Variance is a measure of dispersion, meaning it is a measure of how far a set of numbers is spread out from their average value.\n",
        "\n",
        "#### Definition\n",
        "\n",
        "The variance of a random variable $X$ is the expected value of the squared deviation from the expectation of $X$.\n",
        "\n",
        "#### Properties\n",
        "\n",
        "- $Var[X]=E[X^2]−E[X]^2$.\n",
        "- $Var[aX]=a^2 Var[X]$ where a is a constant value.\n",
        "- $Var[X+b]=Var[X]$ where b is a constant value.\n",
        "- $Var[X+Y]=Var[X]+Var[Y]$.\n",
        "\n",
        "### Re-parameterization trick\n",
        "\n",
        "When we sample data from a probability distribution, backpropagation the gradient is not possible because it is a stochastic process. To make it trainable, the re-parameterization trick is useful.\n",
        "\n",
        "Let us assume that $z$ is sampled data from a gaussian distribution which the mean is $\\mu$ and the variance is $\\sigma^2$. Then, the mean and variance of $z$ would be $\\mu$ and $\\sigma^2$. Therefore, $z$ can be written as follows.\n",
        "\n",
        "$z = N(\\mu, \\sigma^2 I) = \\mu + \\sigma \\odot \\epsilon$, where $\\epsilon \\thicksim N(0, I)$\n",
        "\n",
        "where $\\odot$ refers to element-wise product.\n",
        "\n",
        "The mean and variance of $z$ correspond to $\\mu$ and $\\sigma^2$, respectively.\n",
        "\n",
        "#### Mean (Expectation)\n",
        "\n",
        "$E[z] = E[\\mu+\\sigma \\odot \\epsilon] = E[\\mu] + \\sigma E[\\epsilon] = \\mu$\n",
        "\n",
        "The expectation of $\\epsilon$ is 0 by definition.\n",
        "\n",
        "#### Variance\n",
        "\n",
        "$Var[z] = Var[\\mu + \\sigma \\odot \\epsilon] = Var[\\sigma \\odot \\epsilon] = \\sigma^2 Var[\\epsilon] = \\sigma^2$\n",
        "\n",
        "The variance of \\epsilon is 1 by definition.\n",
        "\n",
        "### KL Divergence\n",
        "\n",
        "In mathematical statistics, the Kullback–Leibler divergence (relative entropy), is a type of statistical distance.\n",
        "\n",
        "#### Definition\n",
        "\n",
        "1. Discrete probability distribution\n",
        "\n",
        "$D_{KL}(P||Q) = \\sum_{x \\in X} P(x) log \\frac{P(x)}{Q(x)}$,where $P$ and $Q$ are discrete probability distributions.\n",
        "\n",
        "2. Continuous probability distribution\n",
        "\n",
        "$D_{KL} (P||Q) = \\int _{− \\infty}^{\\infty} p(x) log \\frac{p(x)}{q(x)}dx$, where $p$ and $q$ denote the probability densities of $P$ and $Q$.\n",
        "\n",
        "#### Jensen's inequality\n",
        "\n",
        "In mathematics, Jensen's inequality relates the value of a convex (or concave) function of an integral to the integral of the function.\n",
        "\n",
        "- Convex function: $f(E[X]) \\leqq E[f(X)]$;\n",
        "- Concave function: $f(E[X]) \\geqq E[f(X)]$.\n",
        "\n",
        "#### Properties of KL Divergence\n",
        "\n",
        "- KL Divergence is always non-negative;\n",
        "- The cross-entropy is always larger than the entropy;\n",
        "- Two univariate normal distributions $P$ and $Q$ are simplified to $D_{KL}(P||Q) = log \\frac{\\sigma_q}{\\sigma_p} + \\frac{\\sigma^2_p + (\\mu_p − \\mu_q)^2}{2\\sigma^2_q} − \\frac{1}{2}$.\n",
        "\n",
        "### Evidence lower bound (ELBO)\n",
        "\n",
        "In variational Bayesian methods, the evidence lower bound (often abbreviated ELBO) is a useful lower bound on the log-likelihood of some observed data.\n",
        "\n",
        "#### Definition\n",
        "\n",
        "$ELBO := E_{z∼q_{\\phi}}[log \\frac{pθ(x,z)}{q_{\\phi}(z)}]$\n",
        "\n",
        "where $p_{\\theta}(x, z)$ is joint distribution of $x$ and $z$. $\\theta$ and $\\phi$ are parameters.\n",
        "\n",
        "ELBO is used to obtain the lower bound of the evidence (or log evidence). The evidence is the likelihood function evaluated at a fixed $\\theta$.\n",
        "\n",
        "$evidence := log p_{\\theta}(x)$\n",
        "\n",
        "#### Properties\n",
        "\n",
        "- The evidence is always larger than ELBO;\n",
        "- KL Divergence between $p_{\\theta}(z|x)$ and $q_{\\phi}(z)$ equals $evidence−ELBO$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiYgx4BcSMoR"
      },
      "source": [
        "# Forward and Reverse Process\n",
        "\n",
        "Diffusion models transform data into Gaussian noise (latent vector) and then restore it. The former is called the forward process, and the latter is called the reverse process.\n",
        "\n",
        "## Forward Diffusion Process\n",
        "\n",
        "In the forward process, we add a gaussian noise to the data step by step (usually hundreds of steps).\n",
        "\n",
        "The transform of an individual step is defined as follows.\n",
        "$x_t = q(x_t|x_{t−1}) = N(x_t, \\sqrt{1−\\beta_t}x_{t−1}, \\beta_t I)$\n",
        "\n",
        "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/05_forward.jpg\" width=\"90%\" class=\"bg-white mb-1\">\n",
        "\n",
        "The forward diffusion process progressively adds Gaussian noise to the input image $x_0$ over $T$ steps, producing a series of noisy image samples $x_1, \\ldots, x_T$.\n",
        "\n",
        "As $T \\rightarrow \\infty$, the final result will converge to an image fully corrupted by noise, akin to sampling from an isotropic Gaussian distribution.\n",
        "\n",
        "The inefficiency of Pythonic loops, particularly with large timestamps, can cause significant slowdowns. To address this, we employ a reparameterization trick, which uses an approximation method to generate noise at specific timestamps, avoiding the need for explicit iteration.\n",
        "\n",
        "$\\alpha_t := 1 - \\beta_t$,\n",
        "$\\bar{\\alpha}_t := \\prod_{s=1}^{t} \\alpha_s$,\n",
        "$q(x_t | x_0) = \\mathcal{N}\\left( x_t; \\sqrt{\\bar{\\alpha}_t} x_0, (1 - \\bar{\\alpha}_t) I \\right)$\n",
        "\n",
        "We've isolated the variance schedule and calculated the cumulative product of this variable $α_t$. This equation allows us to directly sample the noisy image at any time step using just the original image $( x_0 )$.\n",
        "\n",
        "## Reverse Diffusion Process\n",
        "\n",
        "In the reverse process, we restore image from a gaussian noise (a latent vector). If $\\beta_t$ is small enough, the reverse $q(x_{t-1}|x_t)$ will also be gaussian. It is noteworthy that the reverse process is tractable when conditioned on $x_0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8O6Ekanf2Sh"
      },
      "source": [
        "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/01_structure.png\" width=\"90%\" class=\"bg-white mb-1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i895jbFDSMoS"
      },
      "source": [
        "The forward process is different; we cannot use $q(x_{t-1}|x_t)$ to reverse the noise because it is difficult (or impossible) to compute. Therefore, we need to train a neural network $p_θ(xₜ₋₁|xₜ)$ to approximate $q(x_{t-1}|x_t)$.\n",
        "\n",
        "$p_{\\theta}(x_{t-1}|x_{t}) := \\mathcal{N}(x_{t-1}; \\mu(x_{t}, t), \\Sigma_{\\theta}(x_{t}, t))$\n",
        "\n",
        "$p_{\\theta}(x_{0:T}) = p_{\\theta}(x_{T}) \\prod_{t=1}^{T} p_{\\theta}(x_{t-1}|x_{t})$\n",
        "\n",
        "$p_{\\theta}(x_{0}) := \\int p_{\\theta}(x_{0:T}) dx_{1:T}$\n",
        "\n",
        "### Loss Function\n",
        "\n",
        "In a diffusion model, the goal of the reverse diffusion process is to infer the noise-free original image that generated the observed noisy image. To achieve this, we train a neural network to approximate the inverse of the noise process. The training of this neural network is accomplished by minimizing a loss function.\n",
        "\n",
        "First,We define loss function using negative log likelihood & ELBO:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\log p_{\\theta}(x_0) &= \\log p_{\\theta}(x_0 | x_{1:T}) + \\log p_{\\theta}(x_{1:T}) - \\log p_{\\theta}(x_{1:T} | x_0) \\\\\n",
        "\\mathbb{E}_{q}[ \\log p_{\\theta}(x_0) ] &= \\int q(x_{1:T} | x_0) \\log p_{\\theta}(x_0) dx_{1:T} \\\\\n",
        "&= \\int q(x_{1:T} | x_0) [ \\log p_{\\theta}(x_0 | x_{1:T}) + \\log p_{\\theta}(x_{1:T}) - \\log p_{\\theta}(x_{1:T} | x_0) ] dx_{1:T} \\\\\n",
        "&= \\mathbb{E}_{q}[ \\log p_{\\theta}(x_0 | x_{1:T}) ] + \\int q(x_{1:T} | x_0) \\log p_{\\theta}(x_{1:T}) dx_{1:T} \\\\\n",
        "&- \\int q(x_{1:T} | x_0) \\log p_{\\theta}(x_{1:T} | x_0) dx_{1:T}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Then,chenge to tractable form:\n",
        "\n",
        "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/06_lossformula.png\" width=\"90%\" class=\"bg-white mb-1\">\n",
        "\n",
        "Finally,simplify training objective:\n",
        "\n",
        "We will use $D_{KL}(q(x_{t-1} | x_t, x_0) || p_{\\theta}(x_{t-1} | x_t) )$ for simplifying the loss function. In the paper, the author trained the model using this part as a training objective.\n",
        "\n",
        "So, our challenge has been narrowed down to training the two distributions $ q(x_{t-1} | x_t, x_0) $ and $ p_{\\theta}(x_{t-1} | x_t) $ as equally as possible.\n",
        "\n",
        "$$ q(x_{t-1} | x_t, x_0) = N(x_{t-1}; \\hat{\\mu}(x_t, x_0), \\hat{\\beta}I),\n",
        " p_{\\theta}(x_{t-1} | x_t) = N(x_{t-1}; \\mu_{\\theta}(x_t, t), \\sigma_t^2 I) $$\n",
        "$$\n",
        "\\begin{aligned}\n",
        "D_{KL}(q(x_{t-1} | x_t, x_0) || p_{\\theta}(x_{t-1} | x_t)) &= E_{x_0, \\epsilon} \\left[ \\frac{{\\beta_t^2}}{{2\\sigma_t^2} \\alpha_t (1 - \\hat{\\alpha}_t)} || \\epsilon - \\epsilon_{\\theta}(\\sqrt{\\hat{\\alpha}_t}x_0 + \\sqrt{1 - \\hat{\\alpha}_t} \\epsilon, t) ||^2 \\right] \\\\\\frac{{\\beta_t^2}}{{2\\sigma_t^2} \\alpha_t (1 - \\hat{\\alpha}_t)} &\\text{ is considered as a constant in the paper}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Final Loss:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "E_{x_0, \\epsilon}[ || \\epsilon - \\epsilon_{\\theta}(\\sqrt{\\hat{\\alpha}_t}x_0 + \\sqrt{1 - \\hat{\\alpha}_t} \\epsilon, t) ||^2 ]\n",
        "\\end{aligned}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdRposdFf2Si"
      },
      "source": [
        "### Noise schedule\n",
        "\n",
        "In diffusion models, the noise schedule define the methodology for iteratively adding noise to an image or for updating a sample based on model outputs. I'll introduce two type of schedules which are linear schedule and cosine schedule. The linear and cosine schedule were introduced by [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) and [Improved Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239), respectively.\n",
        "\n",
        "#### Linear schedule\n",
        "\n",
        "In the linear schedule, $\\beta_t$ changes linearly.\n",
        "\n",
        "\n",
        "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/02_linear.png\" width=\"90%\" class=\"bg-white mb-1\">\n",
        "\n",
        "Illustration of linear schedule\n",
        "\n",
        "\n",
        "#### Cosine schedule\n",
        "\n",
        "Alex Nichol and Prafulla Dhariwal proposed the cosine schedule to prevent an image from turning into noise too quickly. They construct a different noise schedule in terms of $\\overline{\\alpha_t}$.\n",
        "\n",
        "$\\overline{\\alpha_t} = \\frac{f(t)}{f(0)}$, $f(t) = cos(\\frac{\\frac{t}{T} + s}{1+s} \\frac{\\pi}{2})^2$. By definition, the $\\beta_t$ equals $1 - \\frac{\\overline{\\alpha_t}}{\\overline{\\alpha_{t-1}}}$.\n",
        "\n",
        "\n",
        "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/diffusion-model/03_cosine.png\" width=\"90%\" class=\"bg-white mb-1\">\n",
        "\n",
        "Illustration of cosine schedule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMJAEw_Cf2Si"
      },
      "source": [
        "## Code\n",
        "\n",
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cz-yI6Kf2Sj",
        "outputId": "fcfb5535-5e55-40d6-ef3a-eaf21b9287f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (Reshape, Conv2DTranspose, Add, Conv2D, MaxPool2D, Dense,\n",
        "                                     Flatten, Input, BatchNormalization, Input, MultiHeadAttention)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oICkvh0lf2Sj"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "TIME_STEPS = 1000\n",
        "IM_SHAPE = (32,32,3)\n",
        "N_HEADS = 8\n",
        "ATTN_DIM = 256\n",
        "N_GROUPS = 8\n",
        "N_RESNETS = 2\n",
        "LEARNING_RATE = 2e-4\n",
        "EPOCHS = 10\n",
        "FACTOR = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku9fyewjf2Sk"
      },
      "source": [
        "### Data Loading\n",
        "The dataset can be downloaded from [here](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "umD3e18Wf2Sk"
      },
      "outputs": [],
      "source": [
        "url = 'https://static-1300131294.cos.ap-shanghai.myqcloud.com/data/deep-learning/diffusion-model/archive.zip'\n",
        "\n",
        "r = requests.get(url)\n",
        "with zipfile.ZipFile(io.BytesIO(r.content), 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcql7dBhf2Sk",
        "outputId": "e4715e72-5427-4e76-b9d3-cc82af37ed18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30000 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"t/celebA\", label_mode=None, image_size=(IM_SHAPE[0], IM_SHAPE[1]), batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksGR5RNuf2Sl"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s34mJ7TAf2Sl"
      },
      "outputs": [],
      "source": [
        "def preprocess(image):\n",
        "    return tf.cast(image, tf.float32) / 127.5 - 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYY2Me94f2Sl"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6p2RrotNf2Sl"
      },
      "outputs": [],
      "source": [
        "def augmentation(image):\n",
        "    return tf.image.random_flip_left_right(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2Fr-EWdf2Sl"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ucEBmDYIf2Sm"
      },
      "outputs": [],
      "source": [
        "train_dataset = (\n",
        "    ds_train\n",
        "    .map(preprocess)\n",
        "    .map(augmentation)\n",
        "    .unbatch()\n",
        "    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n",
        "    .batch(BATCH_SIZE,drop_remainder=True)\n",
        "    .prefetch(tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4L-JszOf2Sm"
      },
      "source": [
        "### Linear schedule-beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ihHFAYjaf2Sm"
      },
      "outputs": [],
      "source": [
        "def linear_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    return tf.linspace(beta_start, beta_end, timesteps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfHPiKjNf2Sm",
        "outputId": "07ad94e2-5706-434d-8db4-ee390ff790cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[9.99999975e-05 1.19919918e-04 1.39839831e-04 1.59759758e-04\n",
            " 1.79679686e-04 1.99599599e-04 2.19519512e-04 2.39439454e-04\n",
            " 2.59359367e-04 2.79279280e-04 2.99199193e-04 3.19119135e-04\n",
            " 3.39039048e-04 3.58958961e-04 3.78878904e-04 3.98798817e-04\n",
            " 4.18718730e-04 4.38638643e-04 4.58558556e-04 4.78478498e-04\n",
            " 4.98398382e-04 5.18318324e-04 5.38238266e-04 5.58158150e-04\n",
            " 5.78078092e-04 5.97998034e-04 6.17917918e-04 6.37837860e-04\n",
            " 6.57757802e-04 6.77677686e-04 6.97597628e-04 7.17517512e-04\n",
            " 7.37437455e-04 7.57357397e-04 7.77277281e-04 7.97197223e-04\n",
            " 8.17117107e-04 8.37037049e-04 8.56956991e-04 8.76876875e-04\n",
            " 8.96796817e-04 9.16716759e-04 9.36636643e-04 9.56556585e-04\n",
            " 9.76476527e-04 9.96396411e-04 1.01631635e-03 1.03623618e-03\n",
            " 1.05615612e-03 1.07607606e-03 1.09599601e-03 1.11591583e-03\n",
            " 1.13583577e-03 1.15575572e-03 1.17567566e-03 1.19559560e-03\n",
            " 1.21551554e-03 1.23543537e-03 1.25535531e-03 1.27527525e-03\n",
            " 1.29519519e-03 1.31511514e-03 1.33503496e-03 1.35495490e-03\n",
            " 1.37487485e-03 1.39479479e-03 1.41471473e-03 1.43463456e-03\n",
            " 1.45455450e-03 1.47447444e-03 1.49439438e-03 1.51431432e-03\n",
            " 1.53423415e-03 1.55415409e-03 1.57407403e-03 1.59399398e-03\n",
            " 1.61391392e-03 1.63383386e-03 1.65375369e-03 1.67367363e-03\n",
            " 1.69359357e-03 1.71351351e-03 1.73343346e-03 1.75335328e-03\n",
            " 1.77327322e-03 1.79319317e-03 1.81311311e-03 1.83303305e-03\n",
            " 1.85295299e-03 1.87287282e-03 1.89279276e-03 1.91271270e-03\n",
            " 1.93263264e-03 1.95255259e-03 1.97247253e-03 1.99239235e-03\n",
            " 2.01231241e-03 2.03223224e-03 2.05215230e-03 2.07207212e-03\n",
            " 2.09199218e-03 2.11191201e-03 2.13183183e-03 2.15175189e-03\n",
            " 2.17167172e-03 2.19159178e-03 2.21151160e-03 2.23143143e-03\n",
            " 2.25135149e-03 2.27127131e-03 2.29119137e-03 2.31111120e-03\n",
            " 2.33103125e-03 2.35095108e-03 2.37087090e-03 2.39079096e-03\n",
            " 2.41071079e-03 2.43063085e-03 2.45055067e-03 2.47047050e-03\n",
            " 2.49039056e-03 2.51031038e-03 2.53023044e-03 2.55015027e-03\n",
            " 2.57007009e-03 2.58999015e-03 2.60990998e-03 2.62983004e-03\n",
            " 2.64974986e-03 2.66966969e-03 2.68958975e-03 2.70950957e-03\n",
            " 2.72942963e-03 2.74934946e-03 2.76926928e-03 2.78918934e-03\n",
            " 2.80910917e-03 2.82902922e-03 2.84894905e-03 2.86886888e-03\n",
            " 2.88878893e-03 2.90870876e-03 2.92862882e-03 2.94854864e-03\n",
            " 2.96846847e-03 2.98838853e-03 3.00830835e-03 3.02822841e-03\n",
            " 3.04814824e-03 3.06806830e-03 3.08798812e-03 3.10790795e-03\n",
            " 3.12782801e-03 3.14774783e-03 3.16766789e-03 3.18758772e-03\n",
            " 3.20750754e-03 3.22742760e-03 3.24734743e-03 3.26726749e-03\n",
            " 3.28718731e-03 3.30710714e-03 3.32702720e-03 3.34694702e-03\n",
            " 3.36686708e-03 3.38678691e-03 3.40670673e-03 3.42662679e-03\n",
            " 3.44654662e-03 3.46646667e-03 3.48638650e-03 3.50630633e-03\n",
            " 3.52622638e-03 3.54614621e-03 3.56606627e-03 3.58598609e-03\n",
            " 3.60590615e-03 3.62582598e-03 3.64574580e-03 3.66566586e-03\n",
            " 3.68558569e-03 3.70550575e-03 3.72542557e-03 3.74534540e-03\n",
            " 3.76526546e-03 3.78518528e-03 3.80510534e-03 3.82502517e-03\n",
            " 3.84494499e-03 3.86486505e-03 3.88478488e-03 3.90470494e-03\n",
            " 3.92462453e-03 3.94454459e-03 3.96446465e-03 3.98438424e-03\n",
            " 4.00430430e-03 4.02422436e-03 4.04414395e-03 4.06406401e-03\n",
            " 4.08398407e-03 4.10390366e-03 4.12382372e-03 4.14374378e-03\n",
            " 4.16366337e-03 4.18358343e-03 4.20350349e-03 4.22342354e-03\n",
            " 4.24334314e-03 4.26326320e-03 4.28318325e-03 4.30310285e-03\n",
            " 4.32302291e-03 4.34294296e-03 4.36286256e-03 4.38278262e-03\n",
            " 4.40270267e-03 4.42262273e-03 4.44254233e-03 4.46246238e-03\n",
            " 4.48238244e-03 4.50230204e-03 4.52222209e-03 4.54214215e-03\n",
            " 4.56206221e-03 4.58198180e-03 4.60190186e-03 4.62182192e-03\n",
            " 4.64174151e-03 4.66166157e-03 4.68158163e-03 4.70150122e-03\n",
            " 4.72142128e-03 4.74134134e-03 4.76126140e-03 4.78118099e-03\n",
            " 4.80110105e-03 4.82102111e-03 4.84094070e-03 4.86086076e-03\n",
            " 4.88078082e-03 4.90070041e-03 4.92062047e-03 4.94054053e-03\n",
            " 4.96046059e-03 4.98038018e-03 5.00030024e-03 5.02022030e-03\n",
            " 5.04013989e-03 5.06005995e-03 5.07998001e-03 5.09989960e-03\n",
            " 5.11981966e-03 5.13973972e-03 5.15965978e-03 5.17957937e-03\n",
            " 5.19949943e-03 5.21941949e-03 5.23933908e-03 5.25925914e-03\n",
            " 5.27917920e-03 5.29909926e-03 5.31901885e-03 5.33893891e-03\n",
            " 5.35885897e-03 5.37877856e-03 5.39869862e-03 5.41861868e-03\n",
            " 5.43853827e-03 5.45845833e-03 5.47837839e-03 5.49829844e-03\n",
            " 5.51821804e-03 5.53813810e-03 5.55805815e-03 5.57797775e-03\n",
            " 5.59789781e-03 5.61781786e-03 5.63773746e-03 5.65765752e-03\n",
            " 5.67757757e-03 5.69749763e-03 5.71741723e-03 5.73733728e-03\n",
            " 5.75725734e-03 5.77717694e-03 5.79709699e-03 5.81701705e-03\n",
            " 5.83693665e-03 5.85685670e-03 5.87677676e-03 5.89669682e-03\n",
            " 5.91661641e-03 5.93653647e-03 5.95645653e-03 5.97637612e-03\n",
            " 5.99629618e-03 6.01621624e-03 6.03613630e-03 6.05605589e-03\n",
            " 6.07597595e-03 6.09589601e-03 6.11581560e-03 6.13573566e-03\n",
            " 6.15565572e-03 6.17557531e-03 6.19549537e-03 6.21541543e-03\n",
            " 6.23533549e-03 6.25525508e-03 6.27517514e-03 6.29509520e-03\n",
            " 6.31501479e-03 6.33493485e-03 6.35485491e-03 6.37477450e-03\n",
            " 6.39469456e-03 6.41461462e-03 6.43453468e-03 6.45445427e-03\n",
            " 6.47437433e-03 6.49429439e-03 6.51421398e-03 6.53413404e-03\n",
            " 6.55405410e-03 6.57397415e-03 6.59389375e-03 6.61381381e-03\n",
            " 6.63373386e-03 6.65365346e-03 6.67357352e-03 6.69349357e-03\n",
            " 6.71341317e-03 6.73333323e-03 6.75325328e-03 6.77317334e-03\n",
            " 6.79309294e-03 6.81301299e-03 6.83293305e-03 6.85285265e-03\n",
            " 6.87277270e-03 6.89269276e-03 6.91261236e-03 6.93253241e-03\n",
            " 6.95245247e-03 6.97237253e-03 6.99229212e-03 7.01221218e-03\n",
            " 7.03213224e-03 7.05205183e-03 7.07197189e-03 7.09189195e-03\n",
            " 7.11181201e-03 7.13173160e-03 7.15165166e-03 7.17157172e-03\n",
            " 7.19149131e-03 7.21141137e-03 7.23133143e-03 7.25125102e-03\n",
            " 7.27117108e-03 7.29109114e-03 7.31101120e-03 7.33093079e-03\n",
            " 7.35085085e-03 7.37077091e-03 7.39069050e-03 7.41061056e-03\n",
            " 7.43053062e-03 7.45045021e-03 7.47037027e-03 7.49029033e-03\n",
            " 7.51021039e-03 7.53012998e-03 7.55005004e-03 7.56997010e-03\n",
            " 7.58988969e-03 7.60980975e-03 7.62972981e-03 7.64964940e-03\n",
            " 7.66956946e-03 7.68948952e-03 7.70940958e-03 7.72932917e-03\n",
            " 7.74924923e-03 7.76916929e-03 7.78908888e-03 7.80900894e-03\n",
            " 7.82892946e-03 7.84884952e-03 7.86876865e-03 7.88868871e-03\n",
            " 7.90860876e-03 7.92852882e-03 7.94844888e-03 7.96836801e-03\n",
            " 7.98828807e-03 8.00820813e-03 8.02812818e-03 8.04804824e-03\n",
            " 8.06796830e-03 8.08788743e-03 8.10780749e-03 8.12772755e-03\n",
            " 8.14764760e-03 8.16756766e-03 8.18748772e-03 8.20740778e-03\n",
            " 8.22732691e-03 8.24724697e-03 8.26716702e-03 8.28708708e-03\n",
            " 8.30700714e-03 8.32692720e-03 8.34684726e-03 8.36676639e-03\n",
            " 8.38668644e-03 8.40660650e-03 8.42652656e-03 8.44644662e-03\n",
            " 8.46636668e-03 8.48628674e-03 8.50620586e-03 8.52612592e-03\n",
            " 8.54604598e-03 8.56596604e-03 8.58588610e-03 8.60580616e-03\n",
            " 8.62572528e-03 8.64564534e-03 8.66556540e-03 8.68548546e-03\n",
            " 8.70540552e-03 8.72532558e-03 8.74524564e-03 8.76516476e-03\n",
            " 8.78508482e-03 8.80500488e-03 8.82492494e-03 8.84484500e-03\n",
            " 8.86476506e-03 8.88468511e-03 8.90460424e-03 8.92452430e-03\n",
            " 8.94444436e-03 8.96436442e-03 8.98428448e-03 9.00420453e-03\n",
            " 9.02412459e-03 9.04404372e-03 9.06396378e-03 9.08388384e-03\n",
            " 9.10380390e-03 9.12372395e-03 9.14364401e-03 9.16356314e-03\n",
            " 9.18348320e-03 9.20340326e-03 9.22332332e-03 9.24324337e-03\n",
            " 9.26316343e-03 9.28308349e-03 9.30300262e-03 9.32292268e-03\n",
            " 9.34284274e-03 9.36276279e-03 9.38268285e-03 9.40260291e-03\n",
            " 9.42252297e-03 9.44244210e-03 9.46236216e-03 9.48228221e-03\n",
            " 9.50220227e-03 9.52212233e-03 9.54204239e-03 9.56196152e-03\n",
            " 9.58188158e-03 9.60180163e-03 9.62172169e-03 9.64164175e-03\n",
            " 9.66156181e-03 9.68148187e-03 9.70140100e-03 9.72132105e-03\n",
            " 9.74124111e-03 9.76116117e-03 9.78108123e-03 9.80100129e-03\n",
            " 9.82092135e-03 9.84084047e-03 9.86076053e-03 9.88068059e-03\n",
            " 9.90060065e-03 9.92052071e-03 9.94044077e-03 9.96036083e-03\n",
            " 9.98027995e-03 1.00002000e-02 1.00201201e-02 1.00400401e-02\n",
            " 1.00599602e-02 1.00798802e-02 1.00997994e-02 1.01197194e-02\n",
            " 1.01396395e-02 1.01595595e-02 1.01794796e-02 1.01993997e-02\n",
            " 1.02193197e-02 1.02392389e-02 1.02591589e-02 1.02790790e-02\n",
            " 1.02989990e-02 1.03189191e-02 1.03388391e-02 1.03587592e-02\n",
            " 1.03786783e-02 1.03985984e-02 1.04185184e-02 1.04384385e-02\n",
            " 1.04583586e-02 1.04782786e-02 1.04981987e-02 1.05181178e-02\n",
            " 1.05380379e-02 1.05579579e-02 1.05778780e-02 1.05977980e-02\n",
            " 1.06177181e-02 1.06376372e-02 1.06575573e-02 1.06774773e-02\n",
            " 1.06973974e-02 1.07173175e-02 1.07372375e-02 1.07571576e-02\n",
            " 1.07770767e-02 1.07969968e-02 1.08169168e-02 1.08368369e-02\n",
            " 1.08567569e-02 1.08766770e-02 1.08965971e-02 1.09165162e-02\n",
            " 1.09364362e-02 1.09563563e-02 1.09762764e-02 1.09961964e-02\n",
            " 1.10161165e-02 1.10360365e-02 1.10559557e-02 1.10758757e-02\n",
            " 1.10957958e-02 1.11157158e-02 1.11356359e-02 1.11555560e-02\n",
            " 1.11754751e-02 1.11953951e-02 1.12153152e-02 1.12352353e-02\n",
            " 1.12551553e-02 1.12750754e-02 1.12949954e-02 1.13149146e-02\n",
            " 1.13348346e-02 1.13547547e-02 1.13746747e-02 1.13945948e-02\n",
            " 1.14145149e-02 1.14344349e-02 1.14543540e-02 1.14742741e-02\n",
            " 1.14941942e-02 1.15141142e-02 1.15340343e-02 1.15539543e-02\n",
            " 1.15738735e-02 1.15937935e-02 1.16137136e-02 1.16336336e-02\n",
            " 1.16535537e-02 1.16734738e-02 1.16933938e-02 1.17133129e-02\n",
            " 1.17332330e-02 1.17531531e-02 1.17730731e-02 1.17929932e-02\n",
            " 1.18129132e-02 1.18328333e-02 1.18527524e-02 1.18726725e-02\n",
            " 1.18925925e-02 1.19125126e-02 1.19324327e-02 1.19523527e-02\n",
            " 1.19722728e-02 1.19921919e-02 1.20121120e-02 1.20320320e-02\n",
            " 1.20519521e-02 1.20718721e-02 1.20917922e-02 1.21117113e-02\n",
            " 1.21316314e-02 1.21515514e-02 1.21714715e-02 1.21913916e-02\n",
            " 1.22113116e-02 1.22312317e-02 1.22511508e-02 1.22710709e-02\n",
            " 1.22909909e-02 1.23109110e-02 1.23308310e-02 1.23507511e-02\n",
            " 1.23706711e-02 1.23905903e-02 1.24105103e-02 1.24304304e-02\n",
            " 1.24503504e-02 1.24702705e-02 1.24901906e-02 1.25101106e-02\n",
            " 1.25300298e-02 1.25499498e-02 1.25698699e-02 1.25897899e-02\n",
            " 1.26097100e-02 1.26296300e-02 1.26495492e-02 1.26694692e-02\n",
            " 1.26893893e-02 1.27093093e-02 1.27292294e-02 1.27491495e-02\n",
            " 1.27690695e-02 1.27889886e-02 1.28089087e-02 1.28288288e-02\n",
            " 1.28487488e-02 1.28686689e-02 1.28885889e-02 1.29085090e-02\n",
            " 1.29284281e-02 1.29483482e-02 1.29682682e-02 1.29881883e-02\n",
            " 1.30081084e-02 1.30280284e-02 1.30479485e-02 1.30678676e-02\n",
            " 1.30877877e-02 1.31077077e-02 1.31276278e-02 1.31475478e-02\n",
            " 1.31674679e-02 1.31873870e-02 1.32073071e-02 1.32272271e-02\n",
            " 1.32471472e-02 1.32670673e-02 1.32869873e-02 1.33069074e-02\n",
            " 1.33268265e-02 1.33467466e-02 1.33666666e-02 1.33865867e-02\n",
            " 1.34065067e-02 1.34264268e-02 1.34463469e-02 1.34662660e-02\n",
            " 1.34861860e-02 1.35061061e-02 1.35260262e-02 1.35459462e-02\n",
            " 1.35658663e-02 1.35857863e-02 1.36057055e-02 1.36256255e-02\n",
            " 1.36455456e-02 1.36654656e-02 1.36853857e-02 1.37053058e-02\n",
            " 1.37252249e-02 1.37451449e-02 1.37650650e-02 1.37849851e-02\n",
            " 1.38049051e-02 1.38248252e-02 1.38447452e-02 1.38646644e-02\n",
            " 1.38845844e-02 1.39045045e-02 1.39244245e-02 1.39443446e-02\n",
            " 1.39642647e-02 1.39841847e-02 1.40041038e-02 1.40240239e-02\n",
            " 1.40439440e-02 1.40638640e-02 1.40837841e-02 1.41037041e-02\n",
            " 1.41236242e-02 1.41435433e-02 1.41634634e-02 1.41833834e-02\n",
            " 1.42033035e-02 1.42232236e-02 1.42431436e-02 1.42630627e-02\n",
            " 1.42829828e-02 1.43029029e-02 1.43228229e-02 1.43427430e-02\n",
            " 1.43626630e-02 1.43825831e-02 1.44025022e-02 1.44224223e-02\n",
            " 1.44423423e-02 1.44622624e-02 1.44821825e-02 1.45021025e-02\n",
            " 1.45220226e-02 1.45419417e-02 1.45618618e-02 1.45817818e-02\n",
            " 1.46017019e-02 1.46216219e-02 1.46415420e-02 1.46614611e-02\n",
            " 1.46813812e-02 1.47013012e-02 1.47212213e-02 1.47411413e-02\n",
            " 1.47610614e-02 1.47809815e-02 1.48009006e-02 1.48208207e-02\n",
            " 1.48407407e-02 1.48606608e-02 1.48805808e-02 1.49005009e-02\n",
            " 1.49204209e-02 1.49403401e-02 1.49602601e-02 1.49801802e-02\n",
            " 1.50001002e-02 1.50200203e-02 1.50399404e-02 1.50598604e-02\n",
            " 1.50797796e-02 1.50996996e-02 1.51196197e-02 1.51395397e-02\n",
            " 1.51594598e-02 1.51793798e-02 1.51992990e-02 1.52192190e-02\n",
            " 1.52391391e-02 1.52590591e-02 1.52789792e-02 1.52988993e-02\n",
            " 1.53188193e-02 1.53387384e-02 1.53586585e-02 1.53785786e-02\n",
            " 1.53984986e-02 1.54184187e-02 1.54383387e-02 1.54582588e-02\n",
            " 1.54781779e-02 1.54980980e-02 1.55180180e-02 1.55379381e-02\n",
            " 1.55578582e-02 1.55777782e-02 1.55976983e-02 1.56176174e-02\n",
            " 1.56375375e-02 1.56574585e-02 1.56773776e-02 1.56972986e-02\n",
            " 1.57172177e-02 1.57371368e-02 1.57570578e-02 1.57769769e-02\n",
            " 1.57968979e-02 1.58168171e-02 1.58367362e-02 1.58566572e-02\n",
            " 1.58765763e-02 1.58964973e-02 1.59164164e-02 1.59363355e-02\n",
            " 1.59562565e-02 1.59761757e-02 1.59960967e-02 1.60160158e-02\n",
            " 1.60359368e-02 1.60558559e-02 1.60757750e-02 1.60956960e-02\n",
            " 1.61156151e-02 1.61355361e-02 1.61554553e-02 1.61753763e-02\n",
            " 1.61952954e-02 1.62152145e-02 1.62351355e-02 1.62550546e-02\n",
            " 1.62749756e-02 1.62948947e-02 1.63148157e-02 1.63347349e-02\n",
            " 1.63546540e-02 1.63745750e-02 1.63944941e-02 1.64144151e-02\n",
            " 1.64343342e-02 1.64542552e-02 1.64741743e-02 1.64940935e-02\n",
            " 1.65140145e-02 1.65339336e-02 1.65538546e-02 1.65737737e-02\n",
            " 1.65936947e-02 1.66136138e-02 1.66335329e-02 1.66534539e-02\n",
            " 1.66733731e-02 1.66932940e-02 1.67132132e-02 1.67331342e-02\n",
            " 1.67530533e-02 1.67729724e-02 1.67928934e-02 1.68128125e-02\n",
            " 1.68327335e-02 1.68526527e-02 1.68725736e-02 1.68924928e-02\n",
            " 1.69124119e-02 1.69323329e-02 1.69522520e-02 1.69721730e-02\n",
            " 1.69920921e-02 1.70120113e-02 1.70319322e-02 1.70518514e-02\n",
            " 1.70717724e-02 1.70916915e-02 1.71116125e-02 1.71315316e-02\n",
            " 1.71514507e-02 1.71713717e-02 1.71912909e-02 1.72112118e-02\n",
            " 1.72311310e-02 1.72510520e-02 1.72709711e-02 1.72908902e-02\n",
            " 1.73108112e-02 1.73307303e-02 1.73506513e-02 1.73705705e-02\n",
            " 1.73904914e-02 1.74104106e-02 1.74303297e-02 1.74502507e-02\n",
            " 1.74701698e-02 1.74900908e-02 1.75100099e-02 1.75299309e-02\n",
            " 1.75498500e-02 1.75697692e-02 1.75896902e-02 1.76096093e-02\n",
            " 1.76295303e-02 1.76494494e-02 1.76693704e-02 1.76892895e-02\n",
            " 1.77092087e-02 1.77291296e-02 1.77490488e-02 1.77689698e-02\n",
            " 1.77888889e-02 1.78088099e-02 1.78287290e-02 1.78486481e-02\n",
            " 1.78685691e-02 1.78884882e-02 1.79084092e-02 1.79283284e-02\n",
            " 1.79482494e-02 1.79681685e-02 1.79880876e-02 1.80080086e-02\n",
            " 1.80279277e-02 1.80478487e-02 1.80677678e-02 1.80876870e-02\n",
            " 1.81076080e-02 1.81275271e-02 1.81474481e-02 1.81673672e-02\n",
            " 1.81872882e-02 1.82072073e-02 1.82271264e-02 1.82470474e-02\n",
            " 1.82669666e-02 1.82868876e-02 1.83068067e-02 1.83267277e-02\n",
            " 1.83466468e-02 1.83665659e-02 1.83864869e-02 1.84064060e-02\n",
            " 1.84263270e-02 1.84462462e-02 1.84661672e-02 1.84860863e-02\n",
            " 1.85060054e-02 1.85259264e-02 1.85458455e-02 1.85657665e-02\n",
            " 1.85856856e-02 1.86056066e-02 1.86255258e-02 1.86454449e-02\n",
            " 1.86653659e-02 1.86852850e-02 1.87052060e-02 1.87251251e-02\n",
            " 1.87450461e-02 1.87649652e-02 1.87848844e-02 1.88048054e-02\n",
            " 1.88247245e-02 1.88446455e-02 1.88645646e-02 1.88844856e-02\n",
            " 1.89044047e-02 1.89243238e-02 1.89442448e-02 1.89641640e-02\n",
            " 1.89840849e-02 1.90040041e-02 1.90239232e-02 1.90438442e-02\n",
            " 1.90637633e-02 1.90836843e-02 1.91036034e-02 1.91235244e-02\n",
            " 1.91434436e-02 1.91633627e-02 1.91832837e-02 1.92032028e-02\n",
            " 1.92231238e-02 1.92430429e-02 1.92629639e-02 1.92828830e-02\n",
            " 1.93028022e-02 1.93227232e-02 1.93426423e-02 1.93625633e-02\n",
            " 1.93824824e-02 1.94024034e-02 1.94223225e-02 1.94422416e-02\n",
            " 1.94621626e-02 1.94820818e-02 1.95020027e-02 1.95219219e-02\n",
            " 1.95418429e-02 1.95617620e-02 1.95816811e-02 1.96016021e-02\n",
            " 1.96215212e-02 1.96414422e-02 1.96613614e-02 1.96812823e-02\n",
            " 1.97012015e-02 1.97211206e-02 1.97410416e-02 1.97609607e-02\n",
            " 1.97808817e-02 1.98008008e-02 1.98207218e-02 1.98406409e-02\n",
            " 1.98605601e-02 1.98804811e-02 1.99004002e-02 1.99203212e-02\n",
            " 1.99402403e-02 1.99601613e-02 1.99800804e-02 1.99999996e-02], shape=(1000,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "betas = linear_beta_schedule(TIME_STEPS)\n",
        "print(betas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pUlMpYl-f2Sm"
      },
      "outputs": [],
      "source": [
        "alphas = 1. - betas\n",
        "alphas_cumprod = tf.math.cumprod(alphas, axis=0)\n",
        "sqrt_alphas_cumprod = tf.math.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = tf.math.sqrt(1. - alphas_cumprod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TyngTgNmf2Sm"
      },
      "outputs": [],
      "source": [
        "def extract(a, t, x_shape):\n",
        "    b, *_ = t.shape\n",
        "    out = tf.gather(a,t)\n",
        "    output = tf.reshape(out, (b,*((1,) * (len(x_shape) - 1))))\n",
        "    return output\n",
        "\n",
        "def q_sample(x_start, t, noise):\n",
        "\n",
        "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n",
        "\n",
        "    out_sample = sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise### x_start=x_0, noise = z\n",
        "    return out_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3AWw7Zgf2Sm",
        "outputId": "47598d78-0cc2-4e53-fbd9-4cffd92c79de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"unet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " positional_embeddings (Pos  (None, 512)                  0         ['input_2[0][0]']             \n",
            " itionalEmbeddings)                                                                               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 512)                  262656    ['positional_embeddings[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " tf.nn.gelu (TFOpLambda)     (None, 512)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 512)                  262656    ['tf.nn.gelu[0][0]']          \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " tf.nn.silu (TFOpLambda)     (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)           896       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 32)                   16416     ['tf.nn.silu[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)           9248      ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (  (None, 1, 1, 32)             0         ['dense_2[0][0]']             \n",
            " SlicingOpLambda)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 32, 32, 32)           0         ['conv2d_1[0][0]',            \n",
            " Lambda)                                                             'tf.__operators__.getitem[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " group_normalization (Group  (None, 32, 32, 32)           64        ['tf.__operators__.add[0][0]']\n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " tf.nn.silu_1 (TFOpLambda)   (None, 32, 32, 32)           0         ['group_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 32)           9248      ['tf.nn.silu_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 32)           1056      ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " tf.nn.silu_2 (TFOpLambda)   (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 32, 32, 32)           0         ['conv2d_2[0][0]',            \n",
            "                                                                     'conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 32)                   16416     ['tf.nn.silu_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 32)           9248      ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, 1, 32)             0         ['dense_3[0][0]']             \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TF  (None, 32, 32, 32)           0         ['conv2d_4[0][0]',            \n",
            " OpLambda)                                                           'tf.__operators__.getitem_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " group_normalization_1 (Gro  (None, 32, 32, 32)           64        ['tf.__operators__.add_1[0][0]\n",
            " upNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " tf.nn.silu_3 (TFOpLambda)   (None, 32, 32, 32)           0         ['group_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 32)           9248      ['tf.nn.silu_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 32)           1056      ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 32, 32, 32)           0         ['conv2d_5[0][0]',            \n",
            "                                                                     'conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " tf.nn.silu_4 (TFOpLambda)   (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)           0         ['add_1[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 64)                   32832     ['tf.nn.silu_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 64)           18496     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2  (None, 1, 1, 64)             0         ['dense_4[0][0]']             \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TF  (None, 16, 16, 64)           0         ['conv2d_7[0][0]',            \n",
            " OpLambda)                                                           'tf.__operators__.getitem_2[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " group_normalization_2 (Gro  (None, 16, 16, 64)           128       ['tf.__operators__.add_2[0][0]\n",
            " upNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " tf.nn.silu_5 (TFOpLambda)   (None, 16, 16, 64)           0         ['group_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 64)           36928     ['tf.nn.silu_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 64)           2112      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 16, 16, 64)           0         ['conv2d_8[0][0]',            \n",
            "                                                                     'conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, 16, 16, 64)           530496    ['add_2[0][0]',               \n",
            " iHeadAttention)                                                     'add_2[0][0]']               \n",
            "                                                                                                  \n",
            " tf.nn.silu_6 (TFOpLambda)   (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_3 (Gro  (None, 16, 16, 64)           128       ['multi_head_attention[0][0]']\n",
            " upNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 64)                   32832     ['tf.nn.silu_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)           36928     ['group_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3  (None, 1, 1, 64)             0         ['dense_5[0][0]']             \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TF  (None, 16, 16, 64)           0         ['conv2d_10[0][0]',           \n",
            " OpLambda)                                                           'tf.__operators__.getitem_3[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " group_normalization_4 (Gro  (None, 16, 16, 64)           128       ['tf.__operators__.add_3[0][0]\n",
            " upNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " tf.nn.silu_7 (TFOpLambda)   (None, 16, 16, 64)           0         ['group_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['tf.nn.silu_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 16, 16, 64)           4160      ['group_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 16, 16, 64)           0         ['conv2d_11[0][0]',           \n",
            "                                                                     'conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 16, 16, 64)           530496    ['add_3[0][0]',               \n",
            " ltiHeadAttention)                                                   'add_3[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_5 (Gro  (None, 16, 16, 64)           128       ['multi_head_attention_1[0][0]\n",
            " upNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " tf.nn.silu_8 (TFOpLambda)   (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)             0         ['group_normalization_5[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 128)                  65664     ['tf.nn.silu_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 8, 8, 128)            73856     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4  (None, 1, 1, 128)            0         ['dense_6[0][0]']             \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TF  (None, 8, 8, 128)            0         ['conv2d_13[0][0]',           \n",
            " OpLambda)                                                           'tf.__operators__.getitem_4[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " group_normalization_6 (Gro  (None, 8, 8, 128)            256       ['tf.__operators__.add_4[0][0]\n",
            " upNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " tf.nn.silu_9 (TFOpLambda)   (None, 8, 8, 128)            0         ['group_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 8, 8, 128)            147584    ['tf.nn.silu_9[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 8, 8, 128)            8320      ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.nn.silu_10 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 8, 8, 128)            0         ['conv2d_14[0][0]',           \n",
            "                                                                     'conv2d_15[0][0]']           \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  65664     ['tf.nn.silu_10[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 8, 8, 128)            147584    ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_5  (None, 1, 1, 128)            0         ['dense_7[0][0]']             \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TF  (None, 8, 8, 128)            0         ['conv2d_16[0][0]',           \n",
            " OpLambda)                                                           'tf.__operators__.getitem_5[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " group_normalization_7 (Gro  (None, 8, 8, 128)            256       ['tf.__operators__.add_5[0][0]\n",
            " upNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " tf.nn.silu_11 (TFOpLambda)  (None, 8, 8, 128)            0         ['group_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['tf.nn.silu_11[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 8, 8, 128)            16512     ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 8, 8, 128)            0         ['conv2d_17[0][0]',           \n",
            "                                                                     'conv2d_18[0][0]']           \n",
            "                                                                                                  \n",
            " tf.nn.silu_12 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)            0         ['add_5[0][0]']               \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 256)                  131328    ['tf.nn.silu_12[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 4, 4, 256)            295168    ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_6  (None, 1, 1, 256)            0         ['dense_8[0][0]']             \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TF  (None, 4, 4, 256)            0         ['conv2d_19[0][0]',           \n",
            " OpLambda)                                                           'tf.__operators__.getitem_6[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " group_normalization_8 (Gro  (None, 4, 4, 256)            512       ['tf.__operators__.add_6[0][0]\n",
            " upNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " tf.nn.silu_13 (TFOpLambda)  (None, 4, 4, 256)            0         ['group_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 4, 4, 256)            590080    ['tf.nn.silu_13[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 4, 4, 256)            33024     ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " tf.nn.silu_14 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 4, 4, 256)            0         ['conv2d_20[0][0]',           \n",
            "                                                                     'conv2d_21[0][0]']           \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 256)                  131328    ['tf.nn.silu_14[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 4, 4, 256)            590080    ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7  (None, 1, 1, 256)            0         ['dense_9[0][0]']             \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TF  (None, 4, 4, 256)            0         ['conv2d_22[0][0]',           \n",
            " OpLambda)                                                           'tf.__operators__.getitem_7[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " group_normalization_9 (Gro  (None, 4, 4, 256)            512       ['tf.__operators__.add_7[0][0]\n",
            " upNormalization)                                                   ']                            \n",
            "                                                                                                  \n",
            " tf.nn.silu_15 (TFOpLambda)  (None, 4, 4, 256)            0         ['group_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 4, 4, 256)            590080    ['tf.nn.silu_15[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 4, 4, 256)            65792     ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 4, 4, 256)            0         ['conv2d_23[0][0]',           \n",
            "                                                                     'conv2d_24[0][0]']           \n",
            "                                                                                                  \n",
            " tf.nn.silu_16 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 256)            0         ['add_7[0][0]']               \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 256)                  131328    ['tf.nn.silu_16[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 2, 2, 256)            590080    ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_8  (None, 1, 1, 256)            0         ['dense_10[0][0]']            \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_8 (TF  (None, 2, 2, 256)            0         ['conv2d_25[0][0]',           \n",
            " OpLambda)                                                           'tf.__operators__.getitem_8[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " group_normalization_10 (Gr  (None, 2, 2, 256)            512       ['tf.__operators__.add_8[0][0]\n",
            " oupNormalization)                                                  ']                            \n",
            "                                                                                                  \n",
            " tf.nn.silu_17 (TFOpLambda)  (None, 2, 2, 256)            0         ['group_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 2, 2, 256)            590080    ['tf.nn.silu_17[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 2, 2, 256)            65792     ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 2, 2, 256)            0         ['conv2d_26[0][0]',           \n",
            "                                                                     'conv2d_27[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 2, 2, 256)            2103552   ['add_8[0][0]',               \n",
            " ltiHeadAttention)                                                   'add_8[0][0]']               \n",
            "                                                                                                  \n",
            " tf.nn.silu_18 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_11 (Gr  (None, 2, 2, 256)            512       ['multi_head_attention_2[0][0]\n",
            " oupNormalization)                                                  ']                            \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 256)                  131328    ['tf.nn.silu_18[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 2, 2, 256)            590080    ['group_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_9  (None, 1, 1, 256)            0         ['dense_11[0][0]']            \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_9 (TF  (None, 2, 2, 256)            0         ['conv2d_28[0][0]',           \n",
            " OpLambda)                                                           'tf.__operators__.getitem_9[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " group_normalization_12 (Gr  (None, 2, 2, 256)            512       ['tf.__operators__.add_9[0][0]\n",
            " oupNormalization)                                                  ']                            \n",
            "                                                                                                  \n",
            " tf.nn.silu_19 (TFOpLambda)  (None, 2, 2, 256)            0         ['group_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 2, 2, 256)            590080    ['tf.nn.silu_19[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 2, 2, 256)            65792     ['group_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 2, 2, 256)            0         ['conv2d_29[0][0]',           \n",
            "                                                                     'conv2d_30[0][0]']           \n",
            "                                                                                                  \n",
            " tf.image.resize_with_pad (  (None, 4, 4, 256)            0         ['add_9[0][0]']               \n",
            " TFOpLambda)                                                                                      \n",
            "                                                                                                  \n",
            " tf.nn.silu_20 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)      (None, 4, 4, 512)            0         ['tf.image.resize_with_pad[0][\n",
            "                                                                    0]',                          \n",
            "                                                                     'add_7[0][0]']               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 256)                  131328    ['tf.nn.silu_20[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 4, 4, 256)            1179904   ['tf.concat[0][0]']           \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, 1, 256)            0         ['dense_12[0][0]']            \n",
            " 0 (SlicingOpLambda)                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_10 (T  (None, 4, 4, 256)            0         ['conv2d_31[0][0]',           \n",
            " FOpLambda)                                                          'tf.__operators__.getitem_10[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " group_normalization_13 (Gr  (None, 4, 4, 256)            512       ['tf.__operators__.add_10[0][0\n",
            " oupNormalization)                                                  ]']                           \n",
            "                                                                                                  \n",
            " tf.nn.silu_21 (TFOpLambda)  (None, 4, 4, 256)            0         ['group_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 4, 4, 256)            590080    ['tf.nn.silu_21[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 4, 4, 256)            131328    ['tf.concat[0][0]']           \n",
            "                                                                                                  \n",
            " tf.nn.silu_22 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, 4, 4, 256)            0         ['conv2d_32[0][0]',           \n",
            "                                                                     'conv2d_33[0][0]']           \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 256)                  131328    ['tf.nn.silu_22[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 4, 4, 256)            590080    ['add_10[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, 1, 256)            0         ['dense_13[0][0]']            \n",
            " 1 (SlicingOpLambda)                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_11 (T  (None, 4, 4, 256)            0         ['conv2d_34[0][0]',           \n",
            " FOpLambda)                                                          'tf.__operators__.getitem_11[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " group_normalization_14 (Gr  (None, 4, 4, 256)            512       ['tf.__operators__.add_11[0][0\n",
            " oupNormalization)                                                  ]']                           \n",
            "                                                                                                  \n",
            " tf.nn.silu_23 (TFOpLambda)  (None, 4, 4, 256)            0         ['group_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 4, 4, 256)            590080    ['tf.nn.silu_23[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 4, 4, 256)            65792     ['add_10[0][0]']              \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, 4, 4, 256)            0         ['conv2d_35[0][0]',           \n",
            "                                                                     'conv2d_36[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 9, 9, 256)            590080    ['add_11[0][0]']              \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " tf.image.resize_with_pad_1  (None, 8, 8, 256)            0         ['conv2d_transpose[0][0]']    \n",
            "  (TFOpLambda)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_24 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " tf.concat_1 (TFOpLambda)    (None, 8, 8, 384)            0         ['tf.image.resize_with_pad_1[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'add_5[0][0]']               \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 128)                  65664     ['tf.nn.silu_24[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 8, 8, 128)            442496    ['tf.concat_1[0][0]']         \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, 1, 128)            0         ['dense_14[0][0]']            \n",
            " 2 (SlicingOpLambda)                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_12 (T  (None, 8, 8, 128)            0         ['conv2d_37[0][0]',           \n",
            " FOpLambda)                                                          'tf.__operators__.getitem_12[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " group_normalization_15 (Gr  (None, 8, 8, 128)            256       ['tf.__operators__.add_12[0][0\n",
            " oupNormalization)                                                  ]']                           \n",
            "                                                                                                  \n",
            " tf.nn.silu_25 (TFOpLambda)  (None, 8, 8, 128)            0         ['group_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 8, 8, 128)            147584    ['tf.nn.silu_25[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 8, 8, 128)            49280     ['tf.concat_1[0][0]']         \n",
            "                                                                                                  \n",
            " tf.nn.silu_26 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " add_12 (Add)                (None, 8, 8, 128)            0         ['conv2d_38[0][0]',           \n",
            "                                                                     'conv2d_39[0][0]']           \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 128)                  65664     ['tf.nn.silu_26[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 8, 8, 128)            147584    ['add_12[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, 1, 128)            0         ['dense_15[0][0]']            \n",
            " 3 (SlicingOpLambda)                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_13 (T  (None, 8, 8, 128)            0         ['conv2d_40[0][0]',           \n",
            " FOpLambda)                                                          'tf.__operators__.getitem_13[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " group_normalization_16 (Gr  (None, 8, 8, 128)            256       ['tf.__operators__.add_13[0][0\n",
            " oupNormalization)                                                  ]']                           \n",
            "                                                                                                  \n",
            " tf.nn.silu_27 (TFOpLambda)  (None, 8, 8, 128)            0         ['group_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 8, 8, 128)            147584    ['tf.nn.silu_27[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 8, 8, 128)            16512     ['add_12[0][0]']              \n",
            "                                                                                                  \n",
            " add_13 (Add)                (None, 8, 8, 128)            0         ['conv2d_41[0][0]',           \n",
            "                                                                     'conv2d_42[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 17, 17, 128)          147584    ['add_13[0][0]']              \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " tf.image.resize_with_pad_2  (None, 16, 16, 128)          0         ['conv2d_transpose_1[0][0]']  \n",
            "  (TFOpLambda)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_28 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " tf.concat_2 (TFOpLambda)    (None, 16, 16, 192)          0         ['tf.image.resize_with_pad_2[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'group_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 64)                   32832     ['tf.nn.silu_28[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 16, 16, 64)           110656    ['tf.concat_2[0][0]']         \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, 1, 64)             0         ['dense_16[0][0]']            \n",
            " 4 (SlicingOpLambda)                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_14 (T  (None, 16, 16, 64)           0         ['conv2d_43[0][0]',           \n",
            " FOpLambda)                                                          'tf.__operators__.getitem_14[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " group_normalization_17 (Gr  (None, 16, 16, 64)           128       ['tf.__operators__.add_14[0][0\n",
            " oupNormalization)                                                  ]']                           \n",
            "                                                                                                  \n",
            " tf.nn.silu_29 (TFOpLambda)  (None, 16, 16, 64)           0         ['group_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 16, 16, 64)           36928     ['tf.nn.silu_29[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 16, 16, 64)           12352     ['tf.concat_2[0][0]']         \n",
            "                                                                                                  \n",
            " add_14 (Add)                (None, 16, 16, 64)           0         ['conv2d_44[0][0]',           \n",
            "                                                                     'conv2d_45[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (Mu  (None, 16, 16, 64)           530496    ['add_14[0][0]',              \n",
            " ltiHeadAttention)                                                   'add_14[0][0]']              \n",
            "                                                                                                  \n",
            " tf.nn.silu_30 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " group_normalization_18 (Gr  (None, 16, 16, 64)           128       ['multi_head_attention_3[0][0]\n",
            " oupNormalization)                                                  ']                            \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, 64)                   32832     ['tf.nn.silu_30[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 16, 16, 64)           36928     ['group_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, 1, 64)             0         ['dense_17[0][0]']            \n",
            " 5 (SlicingOpLambda)                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_15 (T  (None, 16, 16, 64)           0         ['conv2d_46[0][0]',           \n",
            " FOpLambda)                                                          'tf.__operators__.getitem_15[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " group_normalization_19 (Gr  (None, 16, 16, 64)           128       ['tf.__operators__.add_15[0][0\n",
            " oupNormalization)                                                  ]']                           \n",
            "                                                                                                  \n",
            " tf.nn.silu_31 (TFOpLambda)  (None, 16, 16, 64)           0         ['group_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 16, 16, 64)           36928     ['tf.nn.silu_31[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 16, 16, 64)           4160      ['group_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_15 (Add)                (None, 16, 16, 64)           0         ['conv2d_47[0][0]',           \n",
            "                                                                     'conv2d_48[0][0]']           \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (Mu  (None, 16, 16, 64)           530496    ['add_15[0][0]',              \n",
            " ltiHeadAttention)                                                   'add_15[0][0]']              \n",
            "                                                                                                  \n",
            " group_normalization_20 (Gr  (None, 16, 16, 64)           128       ['multi_head_attention_4[0][0]\n",
            " oupNormalization)                                                  ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 33, 33, 64)           36928     ['group_normalization_20[0][0]\n",
            " Transpose)                                                         ']                            \n",
            "                                                                                                  \n",
            " tf.image.resize_with_pad_3  (None, 32, 32, 64)           0         ['conv2d_transpose_2[0][0]']  \n",
            "  (TFOpLambda)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.silu_32 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " tf.concat_3 (TFOpLambda)    (None, 32, 32, 96)           0         ['tf.image.resize_with_pad_3[0\n",
            "                                                                    ][0]',                        \n",
            "                                                                     'add_1[0][0]']               \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, 32)                   16416     ['tf.nn.silu_32[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 32, 32, 32)           27680     ['tf.concat_3[0][0]']         \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, 1, 32)             0         ['dense_18[0][0]']            \n",
            " 6 (SlicingOpLambda)                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_16 (T  (None, 32, 32, 32)           0         ['conv2d_49[0][0]',           \n",
            " FOpLambda)                                                          'tf.__operators__.getitem_16[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " group_normalization_21 (Gr  (None, 32, 32, 32)           64        ['tf.__operators__.add_16[0][0\n",
            " oupNormalization)                                                  ]']                           \n",
            "                                                                                                  \n",
            " tf.nn.silu_33 (TFOpLambda)  (None, 32, 32, 32)           0         ['group_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 32, 32, 32)           9248      ['tf.nn.silu_33[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 32, 32, 32)           3104      ['tf.concat_3[0][0]']         \n",
            "                                                                                                  \n",
            " tf.nn.silu_34 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " add_16 (Add)                (None, 32, 32, 32)           0         ['conv2d_50[0][0]',           \n",
            "                                                                     'conv2d_51[0][0]']           \n",
            "                                                                                                  \n",
            " dense_19 (Dense)            (None, 32)                   16416     ['tf.nn.silu_34[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)          (None, 32, 32, 32)           9248      ['add_16[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, 1, 32)             0         ['dense_19[0][0]']            \n",
            " 7 (SlicingOpLambda)                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_17 (T  (None, 32, 32, 32)           0         ['conv2d_52[0][0]',           \n",
            " FOpLambda)                                                          'tf.__operators__.getitem_17[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " group_normalization_22 (Gr  (None, 32, 32, 32)           64        ['tf.__operators__.add_17[0][0\n",
            " oupNormalization)                                                  ]']                           \n",
            "                                                                                                  \n",
            " tf.nn.silu_35 (TFOpLambda)  (None, 32, 32, 32)           0         ['group_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 32, 32, 32)           9248      ['tf.nn.silu_35[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 32, 32, 32)           1056      ['add_16[0][0]']              \n",
            "                                                                                                  \n",
            " tf.nn.silu_36 (TFOpLambda)  (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " add_17 (Add)                (None, 32, 32, 32)           0         ['conv2d_53[0][0]',           \n",
            "                                                                     'conv2d_54[0][0]']           \n",
            "                                                                                                  \n",
            " dense_20 (Dense)            (None, 32)                   16416     ['tf.nn.silu_36[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 32, 32, 32)           9248      ['add_17[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 1, 1, 32)             0         ['dense_20[0][0]']            \n",
            " 8 (SlicingOpLambda)                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_18 (T  (None, 32, 32, 32)           0         ['conv2d_55[0][0]',           \n",
            " FOpLambda)                                                          'tf.__operators__.getitem_18[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " group_normalization_23 (Gr  (None, 32, 32, 32)           64        ['tf.__operators__.add_18[0][0\n",
            " oupNormalization)                                                  ]']                           \n",
            "                                                                                                  \n",
            " tf.nn.silu_37 (TFOpLambda)  (None, 32, 32, 32)           0         ['group_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)          (None, 32, 32, 32)           9248      ['tf.nn.silu_37[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)          (None, 32, 32, 32)           1056      ['add_17[0][0]']              \n",
            "                                                                                                  \n",
            " add_18 (Add)                (None, 32, 32, 32)           0         ['conv2d_56[0][0]',           \n",
            "                                                                     'conv2d_57[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)          (None, 32, 32, 3)            867       ['add_18[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16584803 (63.27 MB)\n",
            "Trainable params: 16584803 (63.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "class PositionalEmbeddings(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = dim\n",
        "\n",
        "    def get_timestep_embedding(self, timesteps, embedding_dim: int):\n",
        "        \"\"\"\n",
        "        From Fairseq.\n",
        "        Build sinusoidal embeddings.\n",
        "        This matches the implementation in tensor2tensor, but differs slightly\n",
        "        from the description in Section 3.5 of \"Attention Is All You Need\".\n",
        "        \"\"\"\n",
        "        half_dim = self.embedding_dim // 2\n",
        "        emb = tf.math.log(10000.) / (half_dim - 1)\n",
        "        emb = tf.exp(tf.range(half_dim, dtype=tf.float32) * -emb)\n",
        "        emb = tf.cast(timesteps, dtype = tf.float32)[:, None] * emb[None, :]\n",
        "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=1)\n",
        "        if embedding_dim % 2 == 1:\n",
        "            emb = tf.pad(emb, [[0, 0], [0, 1]])\n",
        "        return emb\n",
        "\n",
        "    def call(self, time):\n",
        "        return self.get_timestep_embedding(time, self.embedding_dim)\n",
        "def res_block(x,filters,n_groups,temb):\n",
        "    previous = x\n",
        "    x = Conv2D(filters, 3, padding=\"same\",)(x) ### Convolution layer with padding same, so that the resolution remains the same\n",
        "\n",
        "    ### temb represents the time embedding.\n",
        "    ### It is passed into the silu activation function and a Dense Layer(Which can change the the embedding dimension )\n",
        "    ### We also reshape the time embedding to match the output of 2d convnets.\n",
        "    x += Dense(filters)(tf.nn.silu(temb))[:,None,None,:]\n",
        "\n",
        "    ### Group Normalization is used.\n",
        "    x = tf.nn.silu(tfa.layers.GroupNormalization(n_groups, axis = -1)(x))\n",
        "    x = Conv2D(filters, 3, padding=\"same\",)(x)\n",
        "\n",
        "    # Project residual\n",
        "    residual = Conv2D(filters, 1,padding=\"same\",)(previous)\n",
        "    x = tf.keras.layers.add([x, residual])  # Add back residual\n",
        "    return x\n",
        "\n",
        "def get_model(im_shape=(64,64,3),n_resnets=2,n_groups=8,attn_dim=32,n_heads=4,):\n",
        "    input_1 = Input(shape=im_shape)### image input\n",
        "    input_2 = Input(shape=())### time input\n",
        "    t_dim = im_shape[0]*16\n",
        "\n",
        "    # Entry block\n",
        "    x = Conv2D(32, 3, padding=\"same\")(input_1)\n",
        "    temb = PositionalEmbeddings(t_dim)(input_2)### Create embeddings from the time input_2\n",
        "    temb = Dense(t_dim)(tf.nn.gelu(Dense(t_dim)(temb)))### pass the embedding into the gelu activation function\n",
        "\n",
        "    hs = [x]### variable used for storing each resolution level output, in the downward path, to be concatenated to the inputs of the upward path.\n",
        "\n",
        "    ### Downward Path\n",
        "    for filters in [32, 64, 128, 256]:### for every resolution level (32,64,128,256), represent the depth they map to resolutions of (32,16,8,4)\n",
        "        for _ in range(n_resnets):### we go through each resnet block per resolution level\n",
        "            x = res_block(x,filters,n_groups,temb)### resblock\n",
        "            ### if the resolution=16 (coinciding with a depth=64), we make the resnet output features attend to each other.\n",
        "            ### Note how the attention axes = (1,2). This corresponds to the height and width dimensions.\n",
        "            ### Feel free to Check the documentation out :) https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention.\n",
        "            ### query = key = value = x.\n",
        "            ### We again use Group Normalization.\n",
        "            if filters == 64:\n",
        "                x = tfa.layers.GroupNormalization(groups=n_groups, axis = -1)(\n",
        "                    MultiHeadAttention(num_heads=n_heads, key_dim=attn_dim, attention_axes=(1,2), )(query = x, value = x))\n",
        "        hs.append(x)### append the output features to hs\n",
        "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)### Downsampling in order to move to the next resolution level\n",
        "\n",
        "\n",
        "    ### Bottleneck\n",
        "    x = res_block(x,256,n_groups,temb)\n",
        "    x = tfa.layers.GroupNormalization(groups=n_groups, axis = -1)(\n",
        "      MultiHeadAttention(num_heads=n_heads, key_dim=attn_dim, attention_axes=(1,2), )(query = x, value = x))\n",
        "    x = res_block(x,256,n_groups,temb)\n",
        "\n",
        "\n",
        "    ### Upward path\n",
        "    for filters in [256, 128, 64,32]:\n",
        "        ### we resize x, to match with the shape of feature outputs (hs) in the downward path\n",
        "        x = tf.image.resize_with_pad(x,hs[-1].shape[1],hs[-1].shape[2])\n",
        "        x = tf.concat([x,hs.pop()], axis=-1)\n",
        "\n",
        "        for _ in range(n_resnets):\n",
        "            x = res_block(x,filters,n_groups,temb)\n",
        "\n",
        "            if filters == 64:\n",
        "                x = tfa.layers.GroupNormalization(groups=n_groups, axis = -1)(\n",
        "                  MultiHeadAttention(num_heads=n_heads, key_dim=attn_dim, attention_axes=(1,2), )(query = x, value = x))\n",
        "\n",
        "        if filters != 32:\n",
        "            x = Conv2DTranspose(filters, 3, strides = (2,2),)(x)### Upsampling\n",
        "\n",
        "    x = res_block(x,32,n_groups,temb)\n",
        "    outputs = Conv2D(3, 3, padding=\"same\", )(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model([input_1,input_2], outputs,name='unet')\n",
        "    return model\n",
        "\n",
        "model= get_model(im_shape=IM_SHAPE,n_resnets=N_RESNETS,n_groups=N_GROUPS,attn_dim=ATTN_DIM,n_heads=N_HEADS,)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oejrIVvof2Sn",
        "outputId": "63c64abb-4945-4331-d552-bb5afa900779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/10: Training Loss-----> tf.Tensor(0.0851486, shape=(), dtype=float32)\n",
            "Time Elapsed: ---> 271.93567872047424 s\n",
            "2/10: Training Loss-----> tf.Tensor(0.03785207, shape=(), dtype=float32)\n",
            "Time Elapsed: ---> 225.90968680381775 s\n",
            "3/10: Training Loss-----> tf.Tensor(0.031987343, shape=(), dtype=float32)\n",
            "Time Elapsed: ---> 227.73545622825623 s\n",
            "4/10: Training Loss-----> tf.Tensor(0.028098105, shape=(), dtype=float32)\n",
            "Time Elapsed: ---> 225.87372756004333 s\n",
            "5/10: Training Loss-----> tf.Tensor(0.026988357, shape=(), dtype=float32)\n",
            "Time Elapsed: ---> 226.86771440505981 s\n",
            "6/10: Training Loss-----> tf.Tensor(0.026325967, shape=(), dtype=float32)\n",
            "Time Elapsed: ---> 226.94463539123535 s\n",
            "7/10: Training Loss-----> tf.Tensor(0.025573287, shape=(), dtype=float32)\n",
            "Time Elapsed: ---> 226.3922827243805 s\n",
            "8/10: Training Loss-----> tf.Tensor(0.025572365, shape=(), dtype=float32)\n",
            "Time Elapsed: ---> 227.60708856582642 s\n",
            "9/10: Training Loss-----> tf.Tensor(0.02489814, shape=(), dtype=float32)\n",
            "Time Elapsed: ---> 227.7055013179779 s\n",
            "10/10: Training Loss-----> tf.Tensor(0.023693103, shape=(), dtype=float32)\n",
            "Time Elapsed: ---> 228.3441195487976 s\n",
            "Training Complete!!!!\n"
          ]
        }
      ],
      "source": [
        "class LRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "    def __init__(self, init_lr):\n",
        "        self.init_lr = init_lr\n",
        "\n",
        "    def __call__(self, step):\n",
        "        return self.init_lr*(100000/(step+100000))\n",
        "\n",
        "OPTIMIZER = Adam(learning_rate=LRSchedule(1e-4))\n",
        "\n",
        "def custom_loss(denoise_model, x_start, t, noise=None):\n",
        "    ### Our custom loss function takes in the predicted noise and compares (using the Huber Loss) it with the actual noise\n",
        "    ### Huber Loss with a default value for delta as 1.0 Check out the documentation: https://www.tensorflow.org/api_docs/python/tf/keras/losses/Huber\n",
        "    h = tf.keras.losses.Huber()\n",
        "    noise = tf.random.normal(x_start.shape,mean=0,stddev=1)### noise=epsilon=z\n",
        "    x_noisy = q_sample(x_start,t,noise)### x_t using the q_sample method\n",
        "    predicted_noise = denoise_model([x_noisy, t])### model takes in the x_t and t and outputs noise\n",
        "    return h(noise,predicted_noise)\n",
        "\n",
        "### custom training block\n",
        "### You can use tf.function to make graphs out of your programs. It is a transformation tool that creates Python-independent dataflow graphs\n",
        "### out of your Python code. This will help you create performant and portable models.\n",
        "@tf.function\n",
        "def training_block(x_batch):\n",
        "    with tf.GradientTape() as recorder:\n",
        "        ### for every element in the batch, we generate t randomly\n",
        "        t = tf.random.uniform((BATCH_SIZE,),minval=0,maxval=TIME_STEPS,dtype=tf.int32)\n",
        "        loss = custom_loss(model,x_batch,t)\n",
        "\n",
        "    partial_derivatives = recorder.gradient(loss, model.trainable_weights)\n",
        "    OPTIMIZER.apply_gradients(zip(partial_derivatives, model.trainable_weights))### gradient descent\n",
        "    return loss\n",
        "\n",
        "def neuralearn(EPOCHS):\n",
        "    for epoch in range(EPOCHS):\n",
        "        init_time = time.time()\n",
        "        losses = []\n",
        "        for step, x_batch in enumerate(train_dataset):\n",
        "            loss = training_block(x_batch)\n",
        "            losses.append(loss)\n",
        "\n",
        "        print(str(epoch+1)+\"/\"+str(EPOCHS)+\": Training Loss----->\", sum(losses)/len(losses))\n",
        "        print('Time Elapsed: ---> '+str(time.time()-init_time)+' s')\n",
        "\n",
        "    print(\"Training Complete!!!!\")\n",
        "\n",
        "neuralearn(EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BS6NjWn3f2Sn",
        "outputId": "4150247f-4991-432c-c070-57325542e91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "999\n",
            "998\n",
            "997\n",
            "996\n",
            "995\n",
            "994\n",
            "993\n",
            "992\n",
            "991\n",
            "990\n",
            "989\n",
            "988\n",
            "987\n",
            "986\n",
            "985\n",
            "984\n",
            "983\n",
            "982\n",
            "981\n",
            "980\n",
            "979\n",
            "978\n",
            "977\n",
            "976\n",
            "975\n",
            "974\n",
            "973\n",
            "972\n",
            "971\n",
            "970\n",
            "969\n",
            "968\n",
            "967\n",
            "966\n",
            "965\n",
            "964\n",
            "963\n",
            "962\n",
            "961\n",
            "960\n",
            "959\n",
            "958\n",
            "957\n",
            "956\n",
            "955\n",
            "954\n",
            "953\n",
            "952\n",
            "951\n",
            "950\n",
            "949\n",
            "948\n",
            "947\n",
            "946\n",
            "945\n",
            "944\n",
            "943\n",
            "942\n",
            "941\n",
            "940\n",
            "939\n",
            "938\n",
            "937\n",
            "936\n",
            "935\n",
            "934\n",
            "933\n",
            "932\n",
            "931\n",
            "930\n",
            "929\n",
            "928\n",
            "927\n",
            "926\n",
            "925\n",
            "924\n",
            "923\n",
            "922\n",
            "921\n",
            "920\n",
            "919\n",
            "918\n",
            "917\n",
            "916\n",
            "915\n",
            "914\n",
            "913\n",
            "912\n",
            "911\n",
            "910\n",
            "909\n",
            "908\n",
            "907\n",
            "906\n",
            "905\n",
            "904\n",
            "903\n",
            "902\n",
            "901\n",
            "900\n",
            "899\n",
            "898\n",
            "897\n",
            "896\n",
            "895\n",
            "894\n",
            "893\n",
            "892\n",
            "891\n",
            "890\n",
            "889\n",
            "888\n",
            "887\n",
            "886\n",
            "885\n",
            "884\n",
            "883\n",
            "882\n",
            "881\n",
            "880\n",
            "879\n",
            "878\n",
            "877\n",
            "876\n",
            "875\n",
            "874\n",
            "873\n",
            "872\n",
            "871\n",
            "870\n",
            "869\n",
            "868\n",
            "867\n",
            "866\n",
            "865\n",
            "864\n",
            "863\n",
            "862\n",
            "861\n",
            "860\n",
            "859\n",
            "858\n",
            "857\n",
            "856\n",
            "855\n",
            "854\n",
            "853\n",
            "852\n",
            "851\n",
            "850\n",
            "849\n",
            "848\n",
            "847\n",
            "846\n",
            "845\n",
            "844\n",
            "843\n",
            "842\n",
            "841\n",
            "840\n",
            "839\n",
            "838\n",
            "837\n",
            "836\n",
            "835\n",
            "834\n",
            "833\n",
            "832\n",
            "831\n",
            "830\n",
            "829\n",
            "828\n",
            "827\n",
            "826\n",
            "825\n",
            "824\n",
            "823\n",
            "822\n",
            "821\n",
            "820\n",
            "819\n",
            "818\n",
            "817\n",
            "816\n",
            "815\n",
            "814\n",
            "813\n",
            "812\n",
            "811\n",
            "810\n",
            "809\n",
            "808\n",
            "807\n",
            "806\n",
            "805\n",
            "804\n",
            "803\n",
            "802\n",
            "801\n",
            "800\n",
            "799\n",
            "798\n",
            "797\n",
            "796\n",
            "795\n",
            "794\n",
            "793\n",
            "792\n",
            "791\n",
            "790\n",
            "789\n",
            "788\n",
            "787\n",
            "786\n",
            "785\n",
            "784\n",
            "783\n",
            "782\n",
            "781\n",
            "780\n",
            "779\n",
            "778\n",
            "777\n",
            "776\n",
            "775\n",
            "774\n",
            "773\n",
            "772\n",
            "771\n",
            "770\n",
            "769\n",
            "768\n",
            "767\n",
            "766\n",
            "765\n",
            "764\n",
            "763\n",
            "762\n",
            "761\n",
            "760\n",
            "759\n",
            "758\n",
            "757\n",
            "756\n",
            "755\n",
            "754\n",
            "753\n",
            "752\n",
            "751\n",
            "750\n",
            "749\n",
            "748\n",
            "747\n",
            "746\n",
            "745\n",
            "744\n",
            "743\n",
            "742\n",
            "741\n",
            "740\n",
            "739\n",
            "738\n",
            "737\n",
            "736\n",
            "735\n",
            "734\n",
            "733\n",
            "732\n",
            "731\n",
            "730\n",
            "729\n",
            "728\n",
            "727\n",
            "726\n",
            "725\n",
            "724\n",
            "723\n",
            "722\n",
            "721\n",
            "720\n",
            "719\n",
            "718\n",
            "717\n",
            "716\n",
            "715\n",
            "714\n",
            "713\n",
            "712\n",
            "711\n",
            "710\n",
            "709\n",
            "708\n",
            "707\n",
            "706\n",
            "705\n",
            "704\n",
            "703\n",
            "702\n",
            "701\n",
            "700\n",
            "699\n",
            "698\n",
            "697\n",
            "696\n",
            "695\n",
            "694\n",
            "693\n",
            "692\n",
            "691\n",
            "690\n",
            "689\n",
            "688\n",
            "687\n",
            "686\n",
            "685\n",
            "684\n",
            "683\n",
            "682\n",
            "681\n",
            "680\n",
            "679\n",
            "678\n",
            "677\n",
            "676\n",
            "675\n",
            "674\n",
            "673\n",
            "672\n",
            "671\n",
            "670\n",
            "669\n",
            "668\n",
            "667\n",
            "666\n",
            "665\n",
            "664\n",
            "663\n",
            "662\n",
            "661\n",
            "660\n",
            "659\n",
            "658\n",
            "657\n",
            "656\n",
            "655\n",
            "654\n",
            "653\n",
            "652\n",
            "651\n",
            "650\n",
            "649\n",
            "648\n",
            "647\n",
            "646\n",
            "645\n",
            "644\n",
            "643\n",
            "642\n",
            "641\n",
            "640\n",
            "639\n",
            "638\n",
            "637\n",
            "636\n",
            "635\n",
            "634\n",
            "633\n",
            "632\n",
            "631\n",
            "630\n",
            "629\n",
            "628\n",
            "627\n",
            "626\n",
            "625\n",
            "624\n",
            "623\n",
            "622\n",
            "621\n",
            "620\n",
            "619\n",
            "618\n",
            "617\n",
            "616\n",
            "615\n",
            "614\n",
            "613\n",
            "612\n",
            "611\n",
            "610\n",
            "609\n",
            "608\n",
            "607\n",
            "606\n",
            "605\n",
            "604\n",
            "603\n",
            "602\n",
            "601\n",
            "600\n",
            "599\n",
            "598\n",
            "597\n",
            "596\n",
            "595\n",
            "594\n",
            "593\n",
            "592\n",
            "591\n",
            "590\n",
            "589\n",
            "588\n",
            "587\n",
            "586\n",
            "585\n",
            "584\n",
            "583\n",
            "582\n",
            "581\n",
            "580\n",
            "579\n",
            "578\n",
            "577\n",
            "576\n",
            "575\n",
            "574\n",
            "573\n",
            "572\n",
            "571\n",
            "570\n",
            "569\n",
            "568\n",
            "567\n",
            "566\n",
            "565\n",
            "564\n",
            "563\n",
            "562\n",
            "561\n",
            "560\n",
            "559\n",
            "558\n",
            "557\n",
            "556\n",
            "555\n",
            "554\n",
            "553\n",
            "552\n",
            "551\n",
            "550\n",
            "549\n",
            "548\n",
            "547\n",
            "546\n",
            "545\n",
            "544\n",
            "543\n",
            "542\n",
            "541\n",
            "540\n",
            "539\n",
            "538\n",
            "537\n",
            "536\n",
            "535\n",
            "534\n",
            "533\n",
            "532\n",
            "531\n",
            "530\n",
            "529\n",
            "528\n",
            "527\n",
            "526\n",
            "525\n",
            "524\n",
            "523\n",
            "522\n",
            "521\n",
            "520\n",
            "519\n",
            "518\n",
            "517\n",
            "516\n",
            "515\n",
            "514\n",
            "513\n",
            "512\n",
            "511\n",
            "510\n",
            "509\n",
            "508\n",
            "507\n",
            "506\n",
            "505\n",
            "504\n",
            "503\n",
            "502\n",
            "501\n",
            "500\n",
            "499\n",
            "498\n",
            "497\n",
            "496\n",
            "495\n",
            "494\n",
            "493\n",
            "492\n",
            "491\n",
            "490\n",
            "489\n",
            "488\n",
            "487\n",
            "486\n",
            "485\n",
            "484\n",
            "483\n",
            "482\n",
            "481\n",
            "480\n",
            "479\n",
            "478\n",
            "477\n",
            "476\n",
            "475\n",
            "474\n",
            "473\n",
            "472\n",
            "471\n",
            "470\n",
            "469\n",
            "468\n",
            "467\n",
            "466\n",
            "465\n",
            "464\n",
            "463\n",
            "462\n",
            "461\n",
            "460\n",
            "459\n",
            "458\n",
            "457\n",
            "456\n",
            "455\n",
            "454\n",
            "453\n",
            "452\n",
            "451\n",
            "450\n",
            "449\n",
            "448\n",
            "447\n",
            "446\n",
            "445\n",
            "444\n",
            "443\n",
            "442\n",
            "441\n",
            "440\n",
            "439\n",
            "438\n",
            "437\n",
            "436\n",
            "435\n",
            "434\n",
            "433\n",
            "432\n",
            "431\n",
            "430\n",
            "429\n",
            "428\n",
            "427\n",
            "426\n",
            "425\n",
            "424\n",
            "423\n",
            "422\n",
            "421\n",
            "420\n",
            "419\n",
            "418\n",
            "417\n",
            "416\n",
            "415\n",
            "414\n",
            "413\n",
            "412\n",
            "411\n",
            "410\n",
            "409\n",
            "408\n",
            "407\n",
            "406\n",
            "405\n",
            "404\n",
            "403\n",
            "402\n",
            "401\n",
            "400\n",
            "399\n",
            "398\n",
            "397\n",
            "396\n",
            "395\n",
            "394\n",
            "393\n",
            "392\n",
            "391\n",
            "390\n",
            "389\n",
            "388\n",
            "387\n",
            "386\n",
            "385\n",
            "384\n",
            "383\n",
            "382\n",
            "381\n",
            "380\n",
            "379\n",
            "378\n",
            "377\n",
            "376\n",
            "375\n",
            "374\n",
            "373\n",
            "372\n",
            "371\n",
            "370\n",
            "369\n",
            "368\n",
            "367\n",
            "366\n",
            "365\n",
            "364\n",
            "363\n",
            "362\n",
            "361\n",
            "360\n",
            "359\n",
            "358\n",
            "357\n",
            "356\n",
            "355\n",
            "354\n",
            "353\n",
            "352\n",
            "351\n",
            "350\n",
            "349\n",
            "348\n",
            "347\n",
            "346\n",
            "345\n",
            "344\n",
            "343\n",
            "342\n",
            "341\n",
            "340\n",
            "339\n",
            "338\n",
            "337\n",
            "336\n",
            "335\n",
            "334\n",
            "333\n",
            "332\n",
            "331\n",
            "330\n",
            "329\n",
            "328\n",
            "327\n",
            "326\n",
            "325\n",
            "324\n",
            "323\n",
            "322\n",
            "321\n",
            "320\n",
            "319\n",
            "318\n",
            "317\n",
            "316\n",
            "315\n",
            "314\n",
            "313\n",
            "312\n",
            "311\n",
            "310\n",
            "309\n",
            "308\n",
            "307\n",
            "306\n",
            "305\n",
            "304\n",
            "303\n",
            "302\n",
            "301\n",
            "300\n",
            "299\n",
            "298\n",
            "297\n",
            "296\n",
            "295\n",
            "294\n",
            "293\n",
            "292\n",
            "291\n",
            "290\n",
            "289\n",
            "288\n",
            "287\n",
            "286\n",
            "285\n",
            "284\n",
            "283\n",
            "282\n",
            "281\n",
            "280\n",
            "279\n",
            "278\n",
            "277\n",
            "276\n",
            "275\n",
            "274\n",
            "273\n",
            "272\n",
            "271\n",
            "270\n",
            "269\n",
            "268\n",
            "267\n",
            "266\n",
            "265\n",
            "264\n",
            "263\n",
            "262\n",
            "261\n",
            "260\n",
            "259\n",
            "258\n",
            "257\n",
            "256\n",
            "255\n",
            "254\n",
            "253\n",
            "252\n",
            "251\n",
            "250\n",
            "249\n",
            "248\n",
            "247\n",
            "246\n",
            "245\n",
            "244\n",
            "243\n",
            "242\n",
            "241\n",
            "240\n",
            "239\n",
            "238\n",
            "237\n",
            "236\n",
            "235\n",
            "234\n",
            "233\n",
            "232\n",
            "231\n",
            "230\n",
            "229\n",
            "228\n",
            "227\n",
            "226\n",
            "225\n",
            "224\n",
            "223\n",
            "222\n",
            "221\n",
            "220\n",
            "219\n",
            "218\n",
            "217\n",
            "216\n",
            "215\n",
            "214\n",
            "213\n",
            "212\n",
            "211\n",
            "210\n",
            "209\n",
            "208\n",
            "207\n",
            "206\n",
            "205\n",
            "204\n",
            "203\n",
            "202\n",
            "201\n",
            "200\n",
            "199\n",
            "198\n",
            "197\n",
            "196\n",
            "195\n",
            "194\n",
            "193\n",
            "192\n",
            "191\n",
            "190\n",
            "189\n",
            "188\n",
            "187\n",
            "186\n",
            "185\n",
            "184\n",
            "183\n",
            "182\n",
            "181\n",
            "180\n",
            "179\n",
            "178\n",
            "177\n",
            "176\n",
            "175\n",
            "174\n",
            "173\n",
            "172\n",
            "171\n",
            "170\n",
            "169\n",
            "168\n",
            "167\n",
            "166\n",
            "165\n",
            "164\n",
            "163\n",
            "162\n",
            "161\n",
            "160\n",
            "159\n",
            "158\n",
            "157\n",
            "156\n",
            "155\n",
            "154\n",
            "153\n",
            "152\n",
            "151\n",
            "150\n",
            "149\n",
            "148\n",
            "147\n",
            "146\n",
            "145\n",
            "144\n",
            "143\n",
            "142\n",
            "141\n",
            "140\n",
            "139\n",
            "138\n",
            "137\n",
            "136\n",
            "135\n",
            "134\n",
            "133\n",
            "132\n",
            "131\n",
            "130\n",
            "129\n",
            "128\n",
            "127\n",
            "126\n",
            "125\n",
            "124\n",
            "123\n",
            "122\n",
            "121\n",
            "120\n",
            "119\n",
            "118\n",
            "117\n",
            "116\n",
            "115\n",
            "114\n",
            "113\n",
            "112\n",
            "111\n",
            "110\n",
            "109\n",
            "108\n",
            "107\n",
            "106\n",
            "105\n",
            "104\n",
            "103\n",
            "102\n",
            "101\n",
            "100\n",
            "99\n",
            "98\n",
            "97\n",
            "96\n",
            "95\n",
            "94\n",
            "93\n",
            "92\n",
            "91\n",
            "90\n",
            "89\n",
            "88\n",
            "87\n",
            "86\n",
            "85\n",
            "84\n",
            "83\n",
            "82\n",
            "81\n",
            "80\n",
            "79\n",
            "78\n",
            "77\n",
            "76\n",
            "75\n",
            "74\n",
            "73\n",
            "72\n",
            "71\n",
            "70\n",
            "69\n",
            "68\n",
            "67\n",
            "66\n",
            "65\n",
            "64\n",
            "63\n",
            "62\n",
            "61\n",
            "60\n",
            "59\n",
            "58\n",
            "57\n",
            "56\n",
            "55\n",
            "54\n",
            "53\n",
            "52\n",
            "51\n",
            "50\n",
            "49\n",
            "48\n",
            "47\n",
            "46\n",
            "45\n",
            "44\n",
            "43\n",
            "42\n",
            "41\n",
            "40\n",
            "39\n",
            "38\n",
            "37\n",
            "36\n",
            "35\n",
            "34\n",
            "33\n",
            "32\n",
            "31\n",
            "30\n",
            "29\n",
            "28\n",
            "27\n",
            "26\n",
            "25\n",
            "24\n",
            "23\n",
            "22\n",
            "21\n",
            "20\n",
            "19\n",
            "18\n",
            "17\n",
            "16\n",
            "15\n",
            "14\n",
            "13\n",
            "12\n",
            "11\n",
            "10\n",
            "9\n",
            "8\n",
            "7\n",
            "6\n",
            "5\n",
            "4\n",
            "3\n",
            "2\n",
            "1\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x1600 with 32 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sqrt_recip_alphas = tf.math.sqrt(1.0 / alphas)\n",
        "alphas_cumprod_prev = tf.concat([tf.ones((1,)),alphas_cumprod[:-1]],axis = 0)### alpha_t-1_bar = alphas_cumprod_prev\n",
        "\n",
        "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
        "\n",
        "def p_sample(model, x, t, t_index):\n",
        "\n",
        "    betas_t = extract(betas, t, x.shape)### betas_t = 1-alphas_t\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(sqrt_one_minus_alphas_cumprod, t, x.shape)### square root of 1-alpha_t_bar\n",
        "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)### 1/square root of alpha_t\n",
        "\n",
        "    model_mean = sqrt_recip_alphas_t * (x - betas_t * model([x, t]) / sqrt_one_minus_alphas_cumprod_t)### equation 4 of algorithm 2 above\n",
        "\n",
        "    if t_index == 0:\n",
        "        return model_mean\n",
        "    else:\n",
        "        posterior_variance_t = extract(posterior_variance, t, x.shape)### sigma_t\n",
        "        noise = tf.random.normal(x.shape)\n",
        "        return model_mean + tf.math.sqrt(posterior_variance_t) * noise\n",
        "\n",
        "imgs = []\n",
        "img = tf.random.normal((64,IM_SHAPE[0],IM_SHAPE[1],IM_SHAPE[2]))\n",
        "for i in reversed(range(0, TIME_STEPS)):### we go backwards from t = 1000 to t = 0\n",
        "    print(i)\n",
        "    img = p_sample(model,img,tf.fill((1,),i,), i)\n",
        "    imgs.append(img)\n",
        "\n",
        "plt.figure(figsize = (16,16))\n",
        "\n",
        "for i in range(32):\n",
        "    ax = plt.subplot(4,8, i+1)\n",
        "    plt.imshow(np.array(imgs[999])[i])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bZ7YU-LNf2Sn",
        "outputId": "05506760-81dc-4018-d431-2efd618d87d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "random_index = 0\n",
        "\n",
        "fig = plt.figure()\n",
        "ims = []\n",
        "for i in range(TIME_STEPS):\n",
        "    im = plt.imshow(np.array(imgs[i])[random_index], animated=True)\n",
        "    ims.append([im])\n",
        "    ims.append([im])\n",
        "\n",
        "animate = animation.ArtistAnimation(fig, ims, interval=5, blit=True, repeat_delay=1000)\n",
        "animate.save('diffusion.gif')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJabZ9MEf2Sn"
      },
      "source": [
        "## Your turn! 🚀\n",
        "\n",
        "Assignment - [Denoising difussion model](../assignments/deep-learning/difussion-model/denoising-difussion-model.ipynb)\n",
        "\n",
        "## Acknowledgments\n",
        "\n",
        "Thanks to [Kwangnam Yu](https://github.com/phykn) for creating the open-source project [diffusion_models_tutorial](https://github.com/phykn/diffusion_models_tutorial) and [kaggle](https://www.kaggle.com/) for creating the open-source courses [Denoising Diffusion Models with TensorFlow](https://www.kaggle.com/code/folefac/denoising-diffusion-models-with-tensorflow#3.-The-Celeb-A-Dataset-%F0%9F%92%BE)[Exploring Diffusion Models with JAX](https://www.kaggle.com/code/darshan1504/exploring-diffusion-models-with-jax)[Denoising Diffusion Probabilistic Model with TF](https://www.kaggle.com/code/junhyeok99/denoising-diffusion-probabilistic-model-with-tf#Mathematics-&-Workflow). They inspire the majority of the content in this chapter."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}