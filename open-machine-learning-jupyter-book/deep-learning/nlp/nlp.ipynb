{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab54879",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Install the necessary dependencies\n",
    "\n",
    "import os\n",
    "import sys\n",
    "!{sys.executable} -m pip install --quiet pandas scikit-learn numpy matplotlib jupyterlab_myst ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb5b28",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "---\n",
    "license:\n",
    "    code: MIT\n",
    "    content: CC-BY-4.0\n",
    "github: https://github.com/ocademy-ai/machine-learning\n",
    "venue: By Ocademy\n",
    "open_access: true\n",
    "bibliography:\n",
    "  - https://raw.githubusercontent.com/ocademy-ai/machine-learning/main/open-machine-learning-jupyter-book/references.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d451b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8de74f-c812-42b6-b1a2-19cd68319b46",
   "metadata": {},
   "source": [
    "Natural Language Processing (NLP) stands as a pivotal technology in the realm of artificial intelligence, bridging the gap between human communication and computer understanding. It is a multidisciplinary domain that empowers computers to interpret, analyze, and generate human language, enabling seamless interaction between humans and machines. The significance of NLP is evident in its widespread applications, ranging from automated customer support to real-time language translation.\n",
    "\n",
    "This section aims to provide newcomers with a comprehensive overview of NLP, its workings, applications, challenges, and future outlook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f74082-4a44-4cda-955a-c9c11b16f5a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What is Natural Language Processing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94e3a1-edcf-4af8-8be3-bff488b8dbe0",
   "metadata": {},
   "source": [
    "<center><img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/NLP/nlp.gif\" width=\"80%\" class=\"bg-white mb-1\" ><br> Image: Natural Language Processing</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd7b95-1a5f-4bd2-b8a3-f627ccb4903b",
   "metadata": {},
   "source": [
    "Natural Language Processing (NLP) is a branch of artificial intelligence that focuses on the interaction between computers and humans through natural language. The objective is to program computers to process and analyze large amounts of natural language data.\n",
    "\n",
    "NLP involves enabling machines to understand, interpret, and produce human language in a way that is both valuable and meaningful. OpenAI, known for developing advanced language models like ChatGPT, highlights the importance of NLP in creating intelligent systems that can understand, respond to, and generate text, making technology more user-friendly and accessible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ee092-520b-4064-b14d-183661e6a049",
   "metadata": {},
   "source": [
    "## Components of NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a850eac7-8b33-4ca0-bd0b-e27fa2b427f4",
   "metadata": {},
   "source": [
    "Natural Language Processing is not a monolithic, singular approach, but rather, it is composed of several components, each contributing to the overall understanding of language. The main components that NLP strives to understand are **Syntax**, **Semantics**, **Pragmatics**, and **Discourse**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0b8220-7d49-4c84-9338-d01d5555d664",
   "metadata": {},
   "source": [
    "### Syntax\n",
    "- Definition: Syntax pertains to the arrangement of words and phrases to create well-structured sentences in a language.\n",
    "- Example: Consider the sentence \"The cat sat on the mat.\" Syntax involves analyzing the grammatical structure of this sentence, ensuring that it adheres to the grammatical rules of English, such as subject-verb agreement and proper word order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7364e95d-a57e-4b70-9f5f-37d22cd17984",
   "metadata": {},
   "source": [
    "### Semantics\n",
    "- Definition: Semantics is concerned with understanding the meaning of words and how they create meaning when combined in sentences.\n",
    "- Example: In the sentence \"The panda eats shoots and leaves,\" semantics helps distinguish whether the panda eats plants (shoots and leaves) or is involved in a violent act (shoots) and then departs (leaves), based on the meaning of the words and the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30472be6-c81f-4d78-8a03-53bdaf647392",
   "metadata": {},
   "source": [
    "<center><img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/NLP/semantics.gif\" width=\"80%\" class=\"bg-white mb-1\" ><br> Image: Semantics in NLP</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bbe334-dc25-46b8-a2b8-61dc28e266ad",
   "metadata": {},
   "source": [
    "### Pragmatics\n",
    "- Definition: Pragmatics deals with understanding language in various contexts, ensuring that the intended meaning is derived based on the situation, speaker‚Äôs intent, and shared knowledge.\n",
    "- Example: If someone says, \"Can you pass the salt?\" Pragmatics involves understanding that this is a request rather than a question about one's ability to pass the salt, interpreting the speaker‚Äôs intent based on the dining context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb2293-2ea7-491e-80a1-aee4259d8c3f",
   "metadata": {},
   "source": [
    "### Discourse\n",
    "- Definition: Discourse focuses on the analysis and interpretation of language beyond the sentence level, considering how sentences relate to each other in texts and conversations.\n",
    "- Example: In a conversation where one person says, \"I‚Äôm freezing,\" and another responds, \"I‚Äôll close the window,\" discourse involves understanding the coherence between the two statements, recognizing that the second statement is a response to the implied request in the first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d96e4-f700-44a8-9cbf-ea1fa5943701",
   "metadata": {},
   "source": [
    "Understanding these components is crucial for anyone delving into NLP, as they form the backbone of how NLP models interpret and generate human langua"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926e7a2-cc7f-4459-9925-9fa78f73f471",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What is NLP Used For?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f80c6a-ca54-4966-b8fb-1cb4f0bd7555",
   "metadata": {},
   "source": [
    "Natural Language Processing has found extensive applications across various industries, revolutionizing the way businesses operate and interact with users. Here are some of the key industry applications of NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6223d-dc4b-4346-8770-79944090b8f1",
   "metadata": {},
   "source": [
    "### Healthcare\n",
    "NLP assists in transcribing and organizing clinical notes, ensuring accurate and efficient documentation of patient information. For instance, a physician might dictate their notes, which NLP systems transcribe into text. Advanced NLP models can further categorize the information, identifying symptoms, diagnoses, and prescribed treatments, thereby streamlining the documentation process, minimizing manual data entry, and enhancing the accuracy of electronic health records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9566b06-e7a8-419a-b167-5acfc4db9eef",
   "metadata": {},
   "source": [
    "### Finance\n",
    "Financial institutions leverage NLP to perform sentiment analysis on various text data like news articles, financial reports, and social media posts to gauge market sentiment regarding specific stocks or the market in general. Algorithms analyze the frequency of positive or negative words, and through machine learning models, predict potential impacts on stock prices or market movements, aiding traders and investors in making informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10313fe3-856c-41b6-a2e8-ffaa098edace",
   "metadata": {},
   "source": [
    "### Customer Service\n",
    "NLP-powered chatbots have revolutionized customer support by providing instant, 24/7 responses to customer inquiries. These chatbots understand customer queries through text or voice, interpret the underlying intent, and provide accurate responses or solutions. For instance, a customer might inquire about their order status, and the chatbot, integrating with the order management system, retrieves and delivers the real-time status, enhancing customer experience and reducing support workload."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201bf7e7-8cbb-43bf-b9e5-825805017370",
   "metadata": {},
   "source": [
    "### E-Commerce\n",
    "NLP significantly enhances on-site search functionality in e-commerce platforms by understanding and interpreting user queries, even if they are phrased in a conversational manner or contain typos. For example, if a user searches for ‚Äúblu jeens,‚Äù NLP algorithms correct the typos and understand the intent, providing relevant results for ‚Äúblue jeans,‚Äù thereby ensuring that users find what they are looking for, even with imprecise queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7742bc9d-0251-455c-9020-4c64535cb652",
   "metadata": {},
   "source": [
    "### Legal\n",
    "In the legal sector, NLP is utilized to automate document review processes, significantly reducing the manual effort involved in sifting through vast volumes of legal documents. For instance, during litigation, legal professionals need to review numerous documents to identify relevant information. NLP algorithms can scan through these documents, identify and highlight pertinent information, such as specific terms, dates, or clauses, thereby expediting the review process and ensuring that no critical information is overlooked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02287309-d1d0-47e1-b7f1-2c1b497795ea",
   "metadata": {},
   "source": [
    "### Everyday applications\n",
    "Beyond industry-specific applications, NLP is ingrained in our daily lives, making technology more accessible and user-friendly. Here are some everyday applications of NLP:\n",
    "\n",
    "- Search engines. NLP is fundamental to the functioning of search engines, enabling them to understand user queries and provide relevant results.\n",
    "- Virtual assistants. Siri, Alexa, and Google Assistant are examples of virtual assistants that use NLP to understand and respond to user commands.\n",
    "- Translation services. Services like Google Translate employ NLP to provide real-time language translation, breaking down language barriers and fostering communication.\n",
    "- Email filtering. NLP is used in email services to filter out spam and categorize emails, helping users manage their inboxes more effectively.\n",
    "- Social media monitoring. NLP enables the analysis of social media content to gauge public opinion, track trends, and manage online reputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa4dd22-587a-468a-826c-6dd2e8ea9d5e",
   "metadata": {},
   "source": [
    "The applications of NLP are diverse and pervasive, impacting various industries and our daily interactions with technology. Understanding these applications provides a glimpse into the transformative potential of NLP in shaping the future of technology and human interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342c9eb-0094-4d9f-b182-d386cab51fe8",
   "metadata": {},
   "source": [
    "## Overcoming NLP challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047fb13-474e-4777-8d4b-3a096fd6cb0e",
   "metadata": {},
   "source": [
    "Natural Language Processing, despite its advancements, faces several challenges due to the inherent complexities and nuances of human language. Here are some of the challenges in NLP:\n",
    "\n",
    "- Ambiguity. Human language is often ambiguous, with words having multiple meanings, making it challenging for NLP models to interpret the correct meaning in different contexts.\n",
    "- Context. Understanding the context in which words are used is crucial for accurate interpretation, and it remains a significant challenge for NLP.\n",
    "- Sarcasm and irony. Detecting sarcasm and irony is particularly challenging as it requires understanding the intended meaning, which may be opposite to the literal meaning.\n",
    "- Cultural nuances. Language is deeply intertwined with culture, and understanding cultural nuances and idioms is essential for effective NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3693a86e-4a8b-4430-9e83-2a031b25de51",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f573c7-c98e-4117-a5a7-4f1421bb9e49",
   "metadata": {},
   "source": [
    "Now that we have a preliminary understanding of natural language processing, let‚Äôs train a model about disaster tweets to help you better understand.\n",
    "\n",
    "First, let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2562bf2-abfc-4c2f-abbe-93477ca13bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b483de7-84e1-43fd-bf93-24ef610ceaf2",
   "metadata": {},
   "source": [
    "Let's now import the dataset which contains numerous tweet texts. Each tweet is labeled as either related to a real disaster or not. Our task is to utilize Natural Language Processing (NLP) techniques to process and analyze these tweet texts. We aim to build a model that can automatically identify whether a tweet is related to a disaster or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95cdd27e-5a99-4f35-957c-f9ebc6f7d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/data/deep-learning/nlp/disaster_tweets_train.csv\")\n",
    "test_df = pd.read_csv(\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/data/deep-learning/nlp/disaster_tweets_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f0de8-9bfd-483a-93a3-cf288fc6d14e",
   "metadata": {},
   "source": [
    "Let's take a quick look at our data... first, an example of what is NOT a disaster tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d10c92a-b319-420b-bde4-c7f7a63ef20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love fruits'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"] == 0][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a075c8-70ab-4b2a-8939-b732b79cc521",
   "metadata": {},
   "source": [
    "Then an example of what is a disaster tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f6f259-30a3-4813-b330-3abe891980f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"] == 1][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b7887-58f8-4846-a9c1-23a0e5574a32",
   "metadata": {},
   "source": [
    "### Building vectors\n",
    "The theory behind the model we'll build in this section is pretty simple: the words contained in each tweet are a good indicator of whether they're about a real disaster or not (this is not entirely correct, but it's a great place to start).\n",
    "\n",
    "We'll use scikit-learn's CountVectorizer to count the words in each tweet and turn them into data our machine learning model can process.\n",
    "\n",
    "Note: a vector is, in this context, a set of numbers that a machine learning model can work with. We'll look at one in just a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abab526e-7f49-4cc1-a950-6c9d43f2df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "## let's get counts for the first 5 tweets in the data\n",
    "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebbedb15-f7c8-4d7c-acb3-75fdeac73121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c8dd03e-58cb-4e12-9aac-8115ad413223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 54)\n",
      "[[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "## we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\n",
    "print(example_train_vectors[0].todense().shape)\n",
    "print(example_train_vectors[0].todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faaa87f-ddba-4d6d-8c7e-14e0ea31c778",
   "metadata": {},
   "source": [
    "The above tells us that:\n",
    "\n",
    "- There are 54 unique words (or \"tokens\") in the first five tweets.\n",
    "- The first tweet contains only some of those unique tokens - all of the non-zero counts above are the tokens that exist in the first tweet.\n",
    "\n",
    "Now let's create vectors for all of our tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "222595c4-935b-45ff-b416-7161a399cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba418f26-b38e-4a64-95f9-7522adcbe906",
   "metadata": {},
   "source": [
    "### Model\n",
    "As we mentioned above, we think the words contained in each tweet are a good indicator of whether they're about a real disaster or not. The presence of particular word (or set of words) in a tweet might link directly to whether or not that tweet is real.\n",
    "\n",
    "What we're assuming here is a linear connection. So let's build a linear model and see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dee6994b-5bb6-439a-a94f-79c1d0eeb965",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Our vectors are really big, so we want to push our model's weights toward 0 without completely discounting different words - ridge regression is a good way to do this.\n",
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c19a26-8af1-4a10-97c5-ac94d9682b89",
   "metadata": {},
   "source": [
    "Let's test our model and see how well it does on the training data. For this we'll use cross-validation - where we train on a portion of the known data, then validate it with the rest. If we do this several times (with different portions) we can get a good idea for how a particular model or method performs.\n",
    "\n",
    "Here, we are using F1 score as the performance evaluation metric for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e29ce553-c784-4d3f-b8fb-9635433378e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59421842, 0.56498283, 0.64082434])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b96f46-1b19-4c74-87d4-23cea834039a",
   "metadata": {},
   "source": [
    "The above scores aren't terrible! It indicates that our hypothesis is approximately 65% likely. Let's continue moving forward, fit the model and predict the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38e0711d-7155-45dd-8f8b-1a3e802c8b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_vectors, train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28eaf0fa-7fa7-42d8-8b70-7f43d74a0ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  \n",
       "3       0  \n",
       "4       1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/data/deep-learning/nlp/disaster_tweets_test.csv\")\n",
    "sample_submission[\"target\"] = clf.predict(test_vectors)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd30ff84-a649-4e3b-a462-ee716ef72877",
   "metadata": {},
   "source": [
    "The above is the result of the model. Because only the linear regression model is used, the effect is not ideal, but for beginners, it is a good opportunity to understand natural language processing technology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b2eb8-aae3-45d7-9258-fc1af8930d7f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Your turn! üöÄ\n",
    "\n",
    "You can practice your nlp skills by following the assignment [getting start nlp with classification task](../../assignments/deep-learning/nlp/getting-start-nlp-with-classification-task.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c783b46-8b21-4094-a3e8-d793ad73dd3c",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "Thanks to [Matt Crabtree](https://www.datacamp.com/portfolio/mattcrabtree) and [Phil Culliton](https://www.kaggle.com/philculliton) for creating the open-source course [What is Natural Language Processing (NLP)?](https://www.datacamp.com/blog/what-is-natural-language-processing) and [NLP Getting Started Tutorial](https://www.kaggle.com/code/philculliton/nlp-getting-started-tutorial). It inspires the majority of the content in this chapter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f25b14",
   "metadata": {},
   "source": [
    "```{tableofcontents}\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-machine-learning-jupyter-book",
   "language": "python",
   "name": "open-machine-learning-jupyter-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
