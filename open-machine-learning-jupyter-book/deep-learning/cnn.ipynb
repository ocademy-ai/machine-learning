{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Install the necessary dependencies\n",
    "\n",
    "import os\n",
    "import sys \n",
    "!{sys.executable} -m pip install --quiet pandas scikit-learn numpy matplotlib jupyterlab_myst ipython imageio scikit-image requests\n",
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "---\n",
    "license:\n",
    "    code: MIT\n",
    "    content: CC-BY-4.0\n",
    "github: https://github.com/ocademy-ai/machine-learning\n",
    "venue: By Ocademy\n",
    "open_access: true\n",
    "bibliography:\n",
    "  - https://raw.githubusercontent.com/ocademy-ai/machine-learning/main/open-machine-learning-jupyter-book/references.bib\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs) are responsible for the latest major breakthroughs in image recognition in the past few years.\n",
    "\n",
    "In mathematics, a convolution is a function that is applied over the output of another function. In our case, we will consider applying a matrix multiplication (filter) across an image. See the below diagram for an example of how this may work.\n",
    "\n",
    "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/CNN/01_intro_cnn.png\" width=\"90%\" class=\"bg-white mb-1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "display(HTML(\"\"\"\n",
    "<p style=\"text-align: center;\">\n",
    "<iframe src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/html/conv-demo/index.html\" width=\"105%\" height=\"800px;\"\n",
    "style=\"border:none;\" scrolling=\"auto\"></iframe>\n",
    "A demo of convolution function. <a\n",
    "href=\"https://cs231n.github.io/convolutional-networks/\"> [source]</a>\n",
    "</p>\n",
    "\"\"\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs generally follow a structure. The main convolutional setup is (input array) -> (convolutional filter layer) -> (Pooling) -> (Activation layer). The above diagram depicts how a convolutional layer may create one feature. Generally, filters are multidimensional and end up creating many features. It is also common to have a completely separate filter-feature creator of different sizes acting on the same layer. After this convolutional filter, it is common to apply a pooling layer. This pooling may be a max-pooling or an average pooling or another aggregation. One of the key concepts here is that the pooling layer has no parameters while decreasing the layer size. See the below diagram for an example of max-pooling.\n",
    "\n",
    "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/CNN/01_intro_cnn2.png\" width=\"90%\" class=\"bg-white mb-1\">\n",
    "\n",
    "After the max pooling, there is generally an activation layer. One of the more common activation layers is the ReLU (Rectified Linear Unit)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST handwritten digits\n",
    "\n",
    "Here we illustrate how to use a simple CNN with three convolutional units to predict the MNIST handwritten digits. \n",
    "\n",
    "```{note}\n",
    "There is good reason why this dataset is used like the 'hello world' of image recognition, it is fairly compact while having a decent amount of training, test, and validation data. It only has one channel (black and white) and only ten possible outputs (0-9).\n",
    "```\n",
    "\n",
    "When the script is done training the model, you should see similar output to the following graphs.\n",
    "\n",
    "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/CNN/02_cnn1_loss_acc.png\" width=\"90%\" class=\"bg-white mb-1\">\n",
    "\n",
    "Training and test loss (left) and test batch accuracy (right).\n",
    "\n",
    "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/CNN/02_cnn1_mnist_output.png\" width=\"90%\" class=\"bg-white mb-1\">\n",
    "\n",
    "A random set of 6 digits with actual and predicted labels. You can see a prediction failure in the lower right box.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "display(HTML(\"\"\"\n",
    "<p style=\"text-align: center;\">\n",
    "<iframe src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/html/cnn-vis/cnn.html\" width=\"105%\" height=\"800px;\"\n",
    "style=\"border:none;\" scrolling=\"auto\"></iframe>\n",
    "A demo of CNN. <a\n",
    "href=\"https://adamharley.com/nn_vis/cnn/3d.html\"> [source]</a>\n",
    "</p>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "display(HTML(\"\"\"\n",
    "<p style=\"text-align: center;\">\n",
    "<iframe src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/html/cnn-vis-2/index.html\" width=\"105%\" height=\"600px;\"\n",
    "style=\"border:none;\" scrolling=\"auto\"></iframe>\n",
    "A demo of CNN. <a\n",
    "href=\"https://poloclub.github.io/cnn-explainer/\"> [source]</a>\n",
    "</p>\n",
    "\"\"\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Data preprocessing\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Build model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiler model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# Test model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Visualizing the training process\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Convert images to 4D tensors (batch_size, height, width, channels)\n",
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "\n",
    "# Set model parameters\n",
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "evaluation_size = 500\n",
    "image_width = train_images.shape[1]\n",
    "image_height = train_images.shape[2]\n",
    "target_size = np.max(train_labels) + 1\n",
    "num_channels = 1  # greyscale = 1 channel\n",
    "generations = 500\n",
    "eval_every = 5\n",
    "conv1_features = 25\n",
    "conv2_features = 50\n",
    "max_pool_size1 = 2  # NxN window for 1st max pool layer\n",
    "max_pool_size2 = 2  # NxN window for 2nd max pool layer\n",
    "fully_connected_size1 = 100\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(conv1_features, (4, 4), activation='relu', input_shape=(image_width, image_height, num_channels)),\n",
    "    tf.keras.layers.MaxPooling2D((max_pool_size1, max_pool_size1)),\n",
    "    tf.keras.layers.Conv2D(conv2_features, (4, 4), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((max_pool_size2, max_pool_size2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(fully_connected_size1, activation='relu'),\n",
    "    tf.keras.layers.Dense(target_size)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for i in range(generations):\n",
    "    rand_index = np.random.choice(len(train_images), size=batch_size)\n",
    "    rand_x = train_images[rand_index]\n",
    "    rand_y = train_labels[rand_index]\n",
    "    \n",
    "    history = model.train_on_batch(rand_x, rand_y)\n",
    "    temp_train_loss, temp_train_acc = history[0], history[1]\n",
    "    \n",
    "    if (i+1) % eval_every == 0:\n",
    "        eval_index = np.random.choice(len(test_images), size=evaluation_size)\n",
    "        eval_x = test_images[eval_index]\n",
    "        eval_y = test_labels[eval_index]\n",
    "        \n",
    "        test_loss, temp_test_acc = model.evaluate(eval_x, eval_y, verbose=0)\n",
    "        \n",
    "        # Record and print results\n",
    "        train_loss.append(temp_train_loss)\n",
    "        train_acc.append(temp_train_acc)\n",
    "        test_acc.append(temp_test_acc)\n",
    "        acc_and_loss = [(i+1), temp_train_loss, temp_train_acc * 100, temp_test_acc * 100]\n",
    "        acc_and_loss = [np.round(x, 2) for x in acc_and_loss]\n",
    "        print('Generation # {}. Train Loss: {:.2f}. Train Acc (Test Acc): {:.2f}% ({:.2f}%)'.format(*acc_and_loss))\n",
    "\n",
    "# Plot loss over time\n",
    "plt.plot(range(0, generations, eval_every), train_loss, 'k-')\n",
    "plt.title('Softmax Loss per Generation')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Softmax Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot train and test accuracy\n",
    "plt.plot(range(0, generations, eval_every), train_acc, 'k-', label='Train Set Accuracy')\n",
    "plt.plot(range(0, generations, eval_every), test_acc, 'r--', label='Test Set Accuracy')\n",
    "plt.title('Train and Test Accuracy')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot some samples\n",
    "# Plot the 6 of the last batch results:\n",
    "predictions = model.predict(train_images[:6])\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "images = np.squeeze(train_images[:6])\n",
    "\n",
    "Nrows = 2\n",
    "Ncols = 3\n",
    "for i in range(6):\n",
    "    plt.subplot(Nrows, Ncols, i+1)\n",
    "    plt.imshow(np.reshape(images[i], [28, 28]), cmap='Greys_r')\n",
    "    plt.title('Pred: ' + str(predictions[i]), fontsize=10)\n",
    "    frame = plt.gca()\n",
    "    frame.axes.get_xaxis().set_visible(False)\n",
    "    frame.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "Here we will build a convolutional neural network to predict the `CIFAR-10` data.\n",
    "\n",
    "The script provided will download and unzip the `CIFAR-10` data. Then it will start training a CNN from scratch. You should see similar output at the end of the following two graphs.\n",
    "\n",
    "<img src=\"https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/deep-learning/CNN/03_cnn2_loss_acc.png\" width=\"90%\" class=\"bg-white mb-1\">\n",
    "\n",
    "Here we see the training loss (left) and the test batch accuracy (right)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# Set model parameters\n",
    "batch_size = 128\n",
    "data_dir = 'temp'\n",
    "output_every = 50\n",
    "generations = 20000\n",
    "eval_every = 500\n",
    "image_height = 32\n",
    "image_width = 32\n",
    "crop_height = 24\n",
    "crop_width = 24\n",
    "num_channels = 3\n",
    "num_targets = 10\n",
    "extract_folder = 'cifar-10-batches-bin'\n",
    "\n",
    "# Load data\n",
    "data_dir = 'temp'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "cifar10_url = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "\n",
    "# Check if file exists, otherwise download it\n",
    "data_file = os.path.join(data_dir, 'cifar-10-binary.tar.gz')\n",
    "if os.path.isfile(data_file):\n",
    "    pass\n",
    "else:\n",
    "    # Download file\n",
    "    def progress(block_num, block_size, total_size):\n",
    "        progress_info = [cifar10_url, float(block_num * block_size) / float(total_size) * 100.0]\n",
    "        print('\\r Downloading {} - {:.2f}%'.format(*progress_info), end=\"\")\n",
    "    filepath, _ = urllib.request.urlretrieve(cifar10_url, data_file, progress)\n",
    "    # Extract file\n",
    "    tarfile.open(filepath, 'r:gz').extractall(data_dir)\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Crop images\n",
    "train_images = tf.image.crop_to_bounding_box(train_images, 4, 4, 24, 24)\n",
    "test_images = tf.image.crop_to_bounding_box(test_images, 4, 4, 24, 24)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to integers\n",
    "train_labels = train_labels.flatten()\n",
    "test_labels = test_labels.flatten()\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (5, 5), activation='relu', input_shape=(crop_height, crop_width, num_channels)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (5, 5), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(384, activation='relu'),\n",
    "    tf.keras.layers.Dense(192, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_targets)\n",
    "])\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Create accuracy metric\n",
    "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[accuracy_metric])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, batch_size=batch_size, epochs=generations, \n",
    "                    validation_data=(test_images, test_labels), verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "# Print loss and accuracy\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "\n",
    "# Plot loss over time\n",
    "plt.plot(history.history['loss'], 'k-')\n",
    "plt.title('Softmax Loss per Generation')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Softmax Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy over time\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], 'k-')\n",
    "plt.title('Test Accuracy')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to fine-tune current CNN architectures?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the script provided in this section is to download the CIFAR-10 data and sort it out in the proper folder structure for running it through the TensorFlow fine-tuning tutorial. The script should create the following folder structure.\n",
    "\n",
    "-train_dir\n",
    "  |--airplane\n",
    "  |--automobile\n",
    "  |--bird\n",
    "  |--cat\n",
    "  |--deer\n",
    "  |--dog\n",
    "  |--frog\n",
    "  |--horse\n",
    "  |--ship\n",
    "  |--truck\n",
    "-validation_dir\n",
    "  |--airplane\n",
    "  |--automobile\n",
    "  |--bird\n",
    "  |--cat\n",
    "  |--deer\n",
    "  |--dog\n",
    "  |--frog\n",
    "  |--horse\n",
    "  |--ship\n",
    "  |--truck\n",
    "\n",
    "  ### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this script, we download the CIFAR-10 images and\n",
    "# transform/save them in the Inception Retraining Format\n",
    "#\n",
    "# The end purpose of the files is for re-training the\n",
    "# Google Inception tensorflow model to work on the CIFAR-10.\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import pickle as cPickle\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import imageio\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "cifar_link = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "data_dir = 'temp'\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Download tar file\n",
    "target_file = os.path.join(data_dir, 'cifar-10-python.tar.gz')\n",
    "if not os.path.isfile(target_file):\n",
    "    print('CIFAR-10 file not found. Downloading CIFAR data (Size = 163MB)')\n",
    "    print('This may take a few minutes, please wait.')\n",
    "    filename, headers = urllib.request.urlretrieve(cifar_link, target_file)\n",
    "\n",
    "# Extract into memory\n",
    "tar = tarfile.open(target_file)\n",
    "tar.extractall(path=data_dir)\n",
    "tar.close()\n",
    "objects = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Create train image folders\n",
    "train_folder = 'train_dir'\n",
    "if not os.path.isdir(os.path.join(data_dir, train_folder)):\n",
    "    for i in range(10):\n",
    "        folder = os.path.join(data_dir, train_folder, objects[i])\n",
    "        os.makedirs(folder)\n",
    "# Create test image folders\n",
    "test_folder = 'validation_dir'\n",
    "if not os.path.isdir(os.path.join(data_dir, test_folder)):\n",
    "    for i in range(10):\n",
    "        folder = os.path.join(data_dir, test_folder, objects[i])\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# Extract images accordingly\n",
    "data_location = os.path.join(data_dir, 'cifar-10-batches-py')\n",
    "train_names = ['data_batch_' + str(x) for x in range(1,6)]\n",
    "test_names = ['test_batch']\n",
    "\n",
    "\n",
    "def load_batch_from_file(file):\n",
    "    file_conn = open(file, 'rb')\n",
    "    image_dictionary = cPickle.load(file_conn, encoding='latin1')\n",
    "    file_conn.close()\n",
    "    return image_dictionary\n",
    "\n",
    "\n",
    "def save_images_from_dict(image_dict, folder='data_dir'):\n",
    "    # image_dict.keys() = 'labels', 'filenames', 'data', 'batch_label'\n",
    "    for ix, label in enumerate(image_dict['labels']):\n",
    "        folder_path = os.path.join(data_dir, folder, objects[label])\n",
    "        filename = image_dict['filenames'][ix]\n",
    "        # Transform image data\n",
    "        image_array = image_dict['data'][ix]\n",
    "        image_array.resize([3, 32, 32])\n",
    "        # Save image using imageio\n",
    "        output_location = os.path.join(folder_path, filename)\n",
    "        # Ensure the pixel values are in the range [0, 255]\n",
    "        image_array = np.clip(image_array, 0, 255).astype(np.uint8)\n",
    "        imageio.imwrite(output_location, image_array.transpose(1, 2, 0))\n",
    "\n",
    "# Sort train images\n",
    "for file in train_names:\n",
    "    print('Saving images from file: {}'.format(file))\n",
    "    file_location = os.path.join(data_dir, 'cifar-10-batches-py', file)\n",
    "    image_dict = load_batch_from_file(file_location)\n",
    "    save_images_from_dict(image_dict, folder=train_folder)\n",
    "\n",
    "# Sort test images\n",
    "for file in test_names:\n",
    "    print('Saving images from file: {}'.format(file))\n",
    "    file_location = os.path.join(data_dir, 'cifar-10-batches-py', file)\n",
    "    image_dict = load_batch_from_file(file_location)\n",
    "    save_images_from_dict(image_dict, folder=test_folder)\n",
    "    \n",
    "# Create labels file\n",
    "cifar_labels_file = os.path.join(data_dir,'cifar10_labels.txt')\n",
    "print('Writing labels file, {}'.format(cifar_labels_file))\n",
    "with open(cifar_labels_file, 'w') as labels_file:\n",
    "    for item in objects:\n",
    "        labels_file.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn! ðŸš€\n",
    "\n",
    "TBD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self study\n",
    "\n",
    "You can refer to those YouTube videos for further study:\n",
    "\n",
    "- [Convolutional Neural Networks (CNNs) explained, by deeplizard](https://www.youtube.com/watch?v=YRhxdVk_sIs)\n",
    "- [Convolutional Neural Networks Explained (CNN Visualized), by Futurology](https://www.youtube.com/watch?v=pj9-rr1wDhM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research trend\n",
    "\n",
    "State of the Art Convolutional Neural Networks (CNNs) Explained | Deep Learning in 2020:\n",
    "\n",
    "<div class=\"yt-container\">\n",
    "   <iframe src=\"https://www.youtube.com/embed/YUyec4eCEiY\" allowfullscreen></iframe>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "Thanks to [Nick](https://github.com/nfmcclure) for creating the open-source course [tensorflow_cookbook](https://github.com/nfmcclure/tensorflow_cookbook). It inspires the majority of the content in this chapter.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
