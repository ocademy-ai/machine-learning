
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>42. Implementing a GPT model from Scratch To Generate Text &#8212; Ocademy Open Machine Learning Book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/drawio.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/youtube.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "ocademy-ai/machine-learning-utterances");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "💬 comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"></script>
    <script>quizdown.init({"quizdown_js": "https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"});</script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="42.10. Pretraining on Unlabeled Data" href="pretraining-on-unlabeled-data.html" />
    <link rel="prev" title="41.3. Transformers for Language Modelling" href="../basic/language-modelling.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint">Learn AI together, for free! At <a color='lightblue' href='https://ocademy.cc'><u style='color:lightblue;'>Ocademy</u></a>.</div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo-long.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Ocademy Open Machine Learning Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PREREQUISITES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../prerequisites/python-programming-introduction.html">
   1. Python programming introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prerequisites/python-programming-basics.html">
   2. Python programming basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prerequisites/python-programming-advanced.html">
   3. Python programming advanced
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATA SCIENCE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data-science/introduction/introduction.html">
   4. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction/defining-data-science.html">
     4.1. Defining data science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction/data-science-ethics.html">
     4.2. Data Science ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction/defining-data.html">
     4.3. Defining data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/introduction/introduction-to-statistics-and-probability.html">
     4.4. Introduction to statistics and probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data-science/working-with-data/working-with-data.html">
   5. Working with data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/working-with-data/relational-databases.html">
     5.1. Relational databases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/working-with-data/non-relational-data.html">
     5.2. Non-relational data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/working-with-data/numpy.html">
     5.3. NumPy
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../data-science/working-with-data/pandas/pandas.html">
     5.4. Pandas
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../data-science/working-with-data/pandas/introduction-and-data-structures.html">
       5.4.1. Introduction and Data Structures
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../data-science/working-with-data/pandas/data-selection.html">
       5.4.2. Data Selection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../data-science/working-with-data/pandas/advanced-pandas-techniques.html">
       5.4.3. Advanced Pandas Techniques
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/working-with-data/data-preparation.html">
     5.5. Data preparation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data-science/data-visualization/data-visualization.html">
   6. Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-visualization/visualization-distributions.html">
     6.1. Visualizing distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-visualization/visualization-proportions.html">
     6.2. Visualizing proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-visualization/visualization-relationships.html">
     6.3. Visualizing relationships: all about honey 🍯
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-visualization/meaningful-visualizations.html">
     6.4. Making meaningful visualizations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data-science/data-science-lifecycle/data-science-lifecycle.html">
   7. Data Science lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-lifecycle/introduction.html">
     7.1. Introduction to the Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-lifecycle/analyzing.html">
     7.2. Analyzing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-lifecycle/communication.html">
     7.3. Communication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data-science/data-science-in-the-cloud/data-science-in-the-cloud.html">
   8. Data Science in the cloud
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-in-the-cloud/introduction.html">
     8.1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-in-the-cloud/the-low-code-no-code-way.html">
     8.2. The “low code/no code” way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data-science/data-science-in-the-cloud/the-azure-ml-sdk-way.html">
     8.3. Data Science in the cloud: The “Azure ML SDK” way
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data-science/data-science-in-the-wild.html">
   9. Data Science in the real world
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING BASICS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-fundamentals/ml-overview.html">
   10. Machine Learning overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-fundamentals/regression/regression-models-for-machine-learning.html">
   11. Regression models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression/tools-of-the-trade.html">
     11.1. Tools of the trade
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression/managing-data.html">
     11.2. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression/linear-and-polynomial-regression.html">
     11.3. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/regression/logistic-regression.html">
     11.4. Logistic regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-fundamentals/classification/getting-started-with-classification.html">
   12. Getting started with classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/classification/introduction-to-classification.html">
     12.1. Introduction to classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/classification/more-classifiers.html">
     12.2. More classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/classification/yet-other-classifiers.html">
     12.3. Yet other classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/build-a-web-app-to-use-a-machine-learning-model.html">
     12.4. Build a web app to use a Machine Learning model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-fundamentals/parameter-optimization/parameter-optimization.html">
   13. Parameter Optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/parameter-optimization/loss-function.html">
     13.1. Loss function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/parameter-optimization/gradient-descent.html">
     13.2. Gradient descent
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ADVANCED MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-advanced/clustering/clustering-models-for-machine-learning.html">
   14. Clustering models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/clustering/introduction-to-clustering.html">
     14.1. Introduction to clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/clustering/k-means-clustering.html">
     14.2. K-Means clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-advanced/ensemble-learning/getting-started-with-ensemble-learning.html">
   15. Getting started with ensemble learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/bagging.html">
     15.1. Bagging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/random-forest.html">
     15.2. Random forest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/ensemble-learning/feature-importance.html">
     15.3. Feature importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-advanced/gradient-boosting/introduction-to-gradient-boosting.html">
   16. Introduction to Gradient Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/gradient-boosting.html">
     16.1. Gradient Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/gradient-boosting-example.html">
     16.2. Gradient boosting example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/xgboost.html">
     16.3. XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-advanced/gradient-boosting/xgboost-k-fold-cv-feature-importance.html">
     16.4. XGBoost + k-fold CV + Feature Importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/unsupervised-learning.html">
   17. Unsupervised learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/kernel-method.html">
   18. Kernel method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/unsupervised-learning-pca-and-clustering.html">
   19. Unsupervised learning: PCA and clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/model-selection.html">
   20. Model selection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/dl-overview.html">
   21. Intro to Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/nn.html">
   22. Neural Networks
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../deep-learning/cnn/cnn.html">
   23. Convolutional Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/cnn-vgg.html">
     23.9. Stylenet / Neural-Style
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/cnn/cnn-deepdream.html">
     23.10. Deepdream in TensorFlow
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/rnn.html">
   24. Recurrent Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/lstm.html">
   25. Long-short term memory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/time-series.html">
   26. Time series
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/autoencoder.html">
   27. Autoencoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/object-detection.html">
   28. Object detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/image-classification.html">
   29. Image classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/image-segmentation.html">
   30. Image segmentation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../deep-learning/nlp/nlp.html">
   31. Natural Language Processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nlp/text-preprocessing.html">
     31.7.1. Text Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deep-learning/nlp/text-representation.html">
     31.7.2. Word embedding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/gan.html">
   32. Generative adversarial networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/difussion-model.html">
   33. Diffusion Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/dqn.html">
   34. Deep Q-learning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING OPERATIONS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/overview.html">
   35. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/problem-framing.html">
   36. Problem framing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/data-engineering.html">
   37. Data engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/model-training-and-evaluation.html">
   38. Model training &amp; evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/model-deployment.html">
   39. Model deployment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Large Language Models
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction.html">
   40. Introduction
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../basic/basic.html">
   41. Large Language Models Basic
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../basic/attention.html">
     41.1. Coding Attention Mechanisms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basic/transformer.html">
     41.2. Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basic/language-modelling.html">
     41.3. Transformers for Language Modelling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="current reference internal" href="#">
   42. Implementing a GPT model from Scratch To Generate Text
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="pretraining-on-unlabeled-data.html">
     42.10. Pretraining on Unlabeled Data
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OTHERS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../assignments/README.html">
   43. Self-paced assignments
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/set-up-env/first-assignment.html">
     43.3. First assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/set-up-env/second-assignment.html">
     43.4. Second assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/project-plan-template.html">
     43.5. Project Plan​ Template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/prerequisites/python-programming-introduction.html">
     43.6. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/prerequisites/python-programming-basics.html">
     43.7. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/prerequisites/python-programming-advanced.html">
     43.8. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/analyzing-text-about-data-science.html">
     43.9. Analyzing text about Data Science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/data-science-scenarios.html">
     43.10. Data Science scenarios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/write-a-data-ethics-case-study.html">
     43.11. Write a data ethics case study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/lines-scatters-and-bars.html">
     43.12. Lines, scatters and bars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/apply-your-skills.html">
     43.13. Apply your skills
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/try-it-in-excel.html">
     43.14. Try it in Excel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/dive-into-the-beehive.html">
     43.15. Dive into the beehive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/build-your-own-custom-vis.html">
     43.16. Build your own custom vis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/classifying-datasets.html">
     43.17. Classifying datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/small-diabetes-study.html">
     43.18. Small diabetes study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/introduction-to-statistics-and-probability.html">
     43.19. Introduction to probability and statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/displaying-airport-data.html">
     43.20. Displaying airport data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/soda-profits.html">
     43.21. Soda profits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/analyzing-COVID-19-papers.html">
     43.22. Analyzing COVID-19 papers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/estimation-of-COVID-19-pandemic.html">
     43.23. Estimation of COVID-19 pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/data-processing-in-python.html">
     43.24. Data processing in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/evaluating-data-from-a-form.html">
     43.25. Evaluating data from a form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/data-preparation.html">
     43.26. Data preparation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/analyzing-data.html">
     43.27. Analyzing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/nyc-taxi-data-in-winter-and-summer.html">
     43.28. NYC taxi data in winter and summer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/matplotlib-applied.html">
     43.29. Matplotlib applied
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/tell-a-story.html">
     43.35. Tell a story
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/explore-a-planetary-computer-dataset.html">
     43.36. Explore a planetary computer dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/exploring-for-anwser.html">
     43.37. Exploring for answers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/market-research.html">
     43.38. Market research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/low-code-no-code-data-science-project-on-azure-ml.html">
     43.39. Low code/no code Data Science project on Azure ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/data-science-project-using-azure-ml-sdk.html">
     43.40. Data Science project using Azure ML SDK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/data-science-in-the-cloud-the-azure-ml-sdk-way.html">
     43.41. Data Science in the cloud: The “Azure ML SDK” way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/ml-overview-iris.html">
     43.42. Machine Learning overview - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/ml-overview-mnist-digits.html">
     43.43. Machine Learning overview - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/regression-with-scikit-learn.html">
     43.44. Regression with Scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/linear-regression/california_housing.html">
     43.45. Linear regression - California Housing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/linear-regression/linear-regression-metrics.html">
     43.46. Linear Regression Metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/linear-regression/loss-function.html">
     43.47. Loss Function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/linear-regression/gradient-descent.html">
     43.48. Gradient descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/linear-regression/linear-regression-from-scratch.html">
     43.49. Linear Regression Implementation from Scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/ml-logistic-regression-1.html">
     43.50. ML logistic regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/ml-logistic-regression-2.html">
     43.51. ML logistic regression - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/ml-neural-network-1.html">
     43.52. ML neural network - Assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/build-ml-web-app-1.html">
     43.53. Build ML web app - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/build-ml-web-app-2.html">
     43.54. Build ML web app - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/regression-tools.html">
     43.55. Regression tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/managing-data.html">
     43.56. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/exploring-visualizations.html">
     43.57. Exploring visualizations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/try-a-different-model.html">
     43.58. Try a different model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/create-a-regression-model.html">
     43.59. Create a regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/linear-and-polynomial-regression.html">
     43.60. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/retrying-some-regression.html">
     43.61. Retrying some regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/pumpkin-varieties-and-color.html">
     43.62. Pumpkin varieties and color
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/delicious-asian-and-indian-cuisines.html">
     43.63. Delicious asian and indian cuisines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/explore-classification-methods.html">
     43.64. Explore classification methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/kernel-method/kernel-method-assignment-1.html">
     43.65. Kernel method assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/kernel-method/support_vector_machines_for_regression.html">
     43.66. Support Vector Machines (SVM) - Intro and SVM for Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/kernel-method/support_vector_machines_for_classification.html">
     43.67. Support Vector Machines (SVM) - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/kernel-method/decision_trees_for_regression.html">
     43.68. Decision Trees - Intro and Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/kernel-method/decision_trees_for_classification.html">
     43.69. Decision Trees - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/model-selection/model-selection-assignment-1.html">
     43.70. Model selection assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/model-selection/learning-curve-to-identify-overfit-underfit.html">
     43.71. Learning Curve To Identify Overfit &amp; Underfit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/model-selection/dropout-and-batch-normalization.html">
     43.72. Dropout and Batch Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/model-selection/lasso-and-ridge-regression.html">
     43.73. Lasso and Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/model-selection/regularized-linear-models.html">
     43.74. Regularized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/unsupervised-learning/customer-segmentation-clustering.html">
     43.75. Customer segmentation: clustering - assignment 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/ensemble-learning/random-forests-intro-and-regression.html">
     43.76. Random forests intro and regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/ensemble-learning/random-forests-for-classification.html">
     43.77. Random forests for classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.html">
     43.78. Beyond random forests: more ensemble models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/ensemble-learning/decision-trees.html">
     43.79. Decision trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/gradient-boosting/hyperparameter-tuning-gradient-boosting.html">
     43.80. Hyperparameter tuning gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/gradient-boosting/gradient-boosting-assignment.html">
     43.81. Gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/gradient-boosting/boosting-with-tuning.html">
     43.82. Boosting with tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-advanced/ensemble-learning/random-forest-classifier-feature-importance.html">
     43.83. Random Forest Classifier with Feature Importance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/machine-learning-productionization/data-engineering.html">
     43.85. Data engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/machine-learning-productionization/counterintuitive-challenges-in-ml-debugging.html">
     43.86. Counterintuitive Challenges in ML Debugging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/machine-learning-productionization/debugging-in-classification.html">
     43.87. Case Study: Debugging in Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/machine-learning-productionization/debugging-in-regression.html">
     43.88. Case Study: Debugging in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/machine-learning-productionization/random-forest-classifier.html">
     43.89. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/study-the-solvers.html">
     43.90. Study the solvers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/build-classification-models.html">
     43.91. Build classification models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/build-classification-model.html">
     43.92. Build Classification Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/ml-fundamentals/parameter-play.html">
     43.93. Parameter play
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/cnn/how-to-choose-cnn-architecture-mnist.html">
     43.94. How to choose cnn architecture mnist
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/cnn/sign-language-digits-classification-with-cnn.html">
     43.96. Sign Language Digits Classification with CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/cnn/object-recognition-in-images-using-cnn.html">
     43.98. Object Recognition in Images using CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/cnn/image-classification.html">
     43.99. Image classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/tensorflow/intro_to_tensorflow_for_deeplearning.html">
     43.100. Intro to TensorFlow for Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/lstm/bitcoin-lstm-model-with-tweet-volume-and-sentiment.html">
     43.102. Bitcoin LSTM Model with Tweet Volume and Sentiment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/rnn/google-stock-price-prediction-rnn.html">
     43.104. Google Stock Price Prediction RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/autoencoder/autoencoder.html">
     43.106. Intro to Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/autoencoder/base-denoising-autoencoder-dimension-reduction.html">
     43.107. Base/Denoising Autoencoder &amp; Dimension Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/autoencoder/variational-autoencoder-and-faces-generation.html">
     43.108. Fun with Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/time-series-forecasting-assignment.html">
     43.109. Time Series Forecasting Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/nn-for-classification-assignment.html">
     43.111. Neural Networks for Classification with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/nn-classify-15-fruits-assignment.html">
     43.112. NN Classify 15 Fruits Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/dqn/dqn-on-foreign-exchange-market.html">
     43.117. DQN On Foreign Exchange Market
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/gan/art-by-gan.html">
     43.118. Art by gan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/gan/gan-introduction.html">
     43.120. Generative Adversarial Networks (GANs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/image-segmentation/comparing-edge-based-and-region-based-segmentation.html">
     43.121. Comparing edge-based and region-based segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/difussion-model/denoising-difussion-model.html">
     43.122. Summary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/object-detection/car-object-detection.html">
     43.123. Car Object Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/overview/basic-classification-classify-images-of-clothing.html">
     43.125. Basic classification: Classify images of clothing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/nlp/getting-start-nlp-with-classification-task.html">
     43.126. Getting Start NLP with classification task
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/nlp/beginner-guide-to-text-preprocessing.html">
     43.128. Beginner’s Guide to Text Pre-Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/deep-learning/nlp/news-topic-classification-tasks.html">
     43.129. News topic classification tasks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/llm/basic/transformer-architecture.html">
     43.130. Complete the transformer architecture
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../slides/introduction.html">
   44. Slides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/python-programming/python-programming-introduction.html">
     44.1. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/python-programming/python-programming-basics.html">
     44.2. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/python-programming/python-programming-advanced.html">
     44.3. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/data-science-introduction.html">
     44.4. Data Science introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/relational-vs-non-relational-database.html">
     44.5. Relational vs. non-relational database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/numpy-and-pandas.html">
     44.6. NumPy and Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/data-visualization.html">
     44.7. Data visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/data-science-lifecycle.html">
     44.8. Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/data-science-in-the-cloud.html">
     44.9. Data Science in the cloud
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/data-science/data-science-in-real-world.html">
     44.10. Data Science in real world
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-fundamentals/ml-overview.html">
     44.11. Machine Learning overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-fundamentals/linear-regression.html">
     44.12. Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-fundamentals/logistic-regression.html">
     44.13. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-fundamentals/logistic-regression-condensed.html">
     44.14. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-fundamentals/neural-network.html">
     44.15. Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-fundamentals/build-an-ml-web-app.html">
     44.16. Build an machine learning web application
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-advanced/unsupervised-learning.html">
     44.17. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-advanced/kernel-method.html">
     44.18. Kernel method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/ml-advanced/model-selection.html">
     44.19. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/deep-learning/cnn.html">
     44.20. Convolutional Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/deep-learning/gan.html">
     44.21. Generative Adversarial Network
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ocademy-ai/machine-learning/release?urlpath=lab/tree/open-machine-learning-jupyter-book/llm/pretrained-model/implementing-a-GPT-model.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ocademy-ai/machine-learning/blob/release/open-machine-learning-jupyter-book/llm/pretrained-model/implementing-a-GPT-model.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning//issues/new?title=Issue%20on%20page%20%2Fllm/pretrained-model/implementing-a-GPT-model.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/edit/release/open-machine-learning-jupyter-book/llm/pretrained-model/implementing-a-GPT-model.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/llm/pretrained-model/implementing-a-GPT-model.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#coding-an-llm-architecture">
   42.1. Coding an LLM architecture
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normalizing-activations-with-layer-normalization">
   42.2. Normalizing activations with layer normalization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implementing-a-feed-forward-network-with-gelu-activations">
   42.3. Implementing a feed forward network with GELU activations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adding-shortcut-connections">
   42.4. Adding shortcut connections
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#connecting-attention-and-linear-layers-in-a-transformer-block">
   42.5. Connecting attention and linear layers in a transformer block
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#coding-the-gpt-model">
   42.6. Coding the GPT model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generating-text">
   42.7. Generating text
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-turn">
   42.8. Your turn! 🚀
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   42.9. Acknowledgments
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Implementing a GPT model from Scratch To Generate Text</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#coding-an-llm-architecture">
   42.1. Coding an LLM architecture
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normalizing-activations-with-layer-normalization">
   42.2. Normalizing activations with layer normalization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implementing-a-feed-forward-network-with-gelu-activations">
   42.3. Implementing a feed forward network with GELU activations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adding-shortcut-connections">
   42.4. Adding shortcut connections
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#connecting-attention-and-linear-layers-in-a-transformer-block">
   42.5. Connecting attention and linear layers in a transformer block
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#coding-the-gpt-model">
   42.6. Coding the GPT model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generating-text">
   42.7. Generating text
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-turn">
   42.8. Your turn! 🚀
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   42.9. Acknowledgments
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="implementing-a-gpt-model-from-scratch-to-generate-text">
<h1><span class="section-number">42. </span>Implementing a GPT model from Scratch To Generate Text<a class="headerlink" href="#implementing-a-gpt-model-from-scratch-to-generate-text" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">importlib.metadata</span> <span class="kn">import</span> <span class="n">version</span>

<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;matplotlib version:&quot;</span><span class="p">,</span> <span class="n">version</span><span class="p">(</span><span class="s2">&quot;matplotlib&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;torch version:&quot;</span><span class="p">,</span> <span class="n">version</span><span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;tiktoken version:&quot;</span><span class="p">,</span> <span class="n">version</span><span class="p">(</span><span class="s2">&quot;tiktoken&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>matplotlib version: 3.7.2
torch version: 2.2.1
tiktoken version: 0.5.1
</pre></div>
</div>
</div>
</div>
<p>In this chapter, we implement a GPT-like LLM architecture; the next chapter will focus on training this LLM</p>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034604.png" width="500px"><section id="coding-an-llm-architecture">
<h2><span class="section-number">42.1. </span>Coding an LLM architecture<a class="headerlink" href="#coding-an-llm-architecture" title="Permalink to this headline">#</a></h2>
<p>Models like GPT and Llama generate words sequentially and are based on the decoder part of the original transformer architecture
Therefore, these LLMs are often referred to as “decoder-like” LLMs
Compared to conventional deep learning models, LLMs are larger, mainly due to their vast number of parameters, not the amount of code
We’ll see that many elements are repeated in an LLM’s architecture</p>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034618.png" width="400px"><p>In this chapter, we consider embedding and model sizes akin to a small GPT-2 model
We’ll specifically code the architecture of the smallest GPT-2 model (124 million parameters), as outlined in Radford et al.’s <a class="reference external" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</a> (note that the initial report lists it as 117M parameters, but this was later corrected in the model weight repository)</p>
<p>Configuration details for the 124 million parameter GPT-2 model include:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GPT_CONFIG_124M</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;vocab_size&quot;</span><span class="p">:</span> <span class="mi">50257</span><span class="p">,</span>  <span class="c1"># Vocabulary size</span>
    <span class="s2">&quot;ctx_len&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>      <span class="c1"># Context length</span>
    <span class="s2">&quot;emb_dim&quot;</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span>       <span class="c1"># Embedding dimension</span>
    <span class="s2">&quot;n_heads&quot;</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span>        <span class="c1"># Number of attention heads</span>
    <span class="s2">&quot;n_layers&quot;</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span>       <span class="c1"># Number of layers</span>
    <span class="s2">&quot;drop_rate&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>     <span class="c1"># Dropout rate</span>
    <span class="s2">&quot;qkv_bias&quot;</span><span class="p">:</span> <span class="kc">False</span>     <span class="c1"># Query-Key-Value bias</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>We use short variable names to avoid long lines of code later
<code class="docutils literal notranslate"><span class="pre">&quot;vocab_size&quot;</span></code> indicates a vocabulary size of 50,257 words, supported by the BPE tokenizer discussed in Chapter 2
<code class="docutils literal notranslate"><span class="pre">&quot;ctx_len&quot;</span></code> represents the model’s maximum input token count, as enabled by positional embeddings covered in Chapter 2
<code class="docutils literal notranslate"><span class="pre">&quot;emb_dim&quot;</span></code> is the embedding size for token inputs, converting each input token into a 768-dimensional vector
<code class="docutils literal notranslate"><span class="pre">&quot;n_heads&quot;</span></code> is the number of attention heads in the multi-head attention mechanism implemented in Chapter 3
<code class="docutils literal notranslate"><span class="pre">&quot;n_layers&quot;</span></code> is the number of transformer blocks within the model, which we’ll implement in upcoming sections
<code class="docutils literal notranslate"><span class="pre">&quot;drop_rate&quot;</span></code> is the dropout mechanism’s intensity, discussed in Chapter 3; 0.1 means dropping 10% of hidden units during training to mitigate overfitting
<code class="docutils literal notranslate"><span class="pre">&quot;qkv_bias&quot;</span></code> decides if the <code class="docutils literal notranslate"><span class="pre">Linear</span></code> layers in the multi-head attention mechanism (from Chapter 3) should include a bias vector when computing query (Q), key (K), and value (V) tensors; we’ll disable this option, which is standard practice in modern LLMs; however, we’ll revisit this later when loading pretrained GPT-2 weights from OpenAI into our reimplementation in Chapter 6</p>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034632.png" width="500px"><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="k">class</span> <span class="nc">DummyGPTModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tok_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;ctx_len&quot;</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;drop_rate&quot;</span><span class="p">])</span>
        
        <span class="c1"># Use a placeholder for TransformerBlock</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trf_blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">DummyTransformerBlock</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])])</span>
        
        <span class="c1"># Use a placeholder for LayerNorm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_norm</span> <span class="o">=</span> <span class="n">DummyLayerNorm</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_idx</span><span class="p">):</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">in_idx</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">tok_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tok_emb</span><span class="p">(</span><span class="n">in_idx</span><span class="p">)</span>
        <span class="n">pos_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">in_idx</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tok_embeds</span> <span class="o">+</span> <span class="n">pos_embeds</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trf_blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>


<span class="k">class</span> <span class="nc">DummyTransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># A simple placeholder</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># This block does nothing and just returns its input.</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">DummyLayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># The parameters here are just to mimic the LayerNorm interface.</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># This layer does nothing and just returns its input.</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034650.png" width="500px"><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tiktoken</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>

<span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">txt1</span> <span class="o">=</span> <span class="s2">&quot;Every effort moves you&quot;</span>
<span class="n">txt2</span> <span class="o">=</span> <span class="s2">&quot;Every day holds a&quot;</span>

<span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">txt1</span><span class="p">)))</span>
<span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">txt2</span><span class="p">)))</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[6109, 3626, 6100,  345],
        [6109, 1110, 6622,  257]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DummyGPTModel</span><span class="p">(</span><span class="n">GPT_CONFIG_124M</span><span class="p">)</span>

<span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output shape:&quot;</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Output shape: torch.Size([2, 4, 50257])
tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],
         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],
         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],
         [ 0.0139,  1.6755, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],

        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],
         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],
         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],
         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],
       grad_fn=&lt;UnsafeViewBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="normalizing-activations-with-layer-normalization">
<h2><span class="section-number">42.2. </span>Normalizing activations with layer normalization<a class="headerlink" href="#normalizing-activations-with-layer-normalization" title="Permalink to this headline">#</a></h2>
<p>Layer normalization, also known as LayerNorm (<a class="reference external" href="https://arxiv.org/abs/1607.06450">Ba et al. 2016</a>), centers the activations of a neural network layer around a mean of 0 and normalizes their variance to 1
This stabilizes training and enables faster convergence to effective weights
Layer normalization is applied both before and after the multi-head attention module within the transformer block, which we will implement later; it’s also applied before the final output layer</p>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034706.png" width="400px"><p>Let’s see how layer normalization works by passing a small input sample through a simple neural network layer:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># create 2 training examples with 5 dimensions (features) each</span>
<span class="n">batch_example</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> 

<span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">batch_example</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],
        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],
       grad_fn=&lt;ReluBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>Let’s compute the mean and variance for each of the 2 inputs above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">var</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean:
 tensor([[0.1324],
        [0.2170]], grad_fn=&lt;MeanBackward1&gt;)
Variance:
 tensor([[0.0231],
        [0.0398]], grad_fn=&lt;VarBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>The normalization is applied to each of the two inputs (rows) independently; using dim=-1 applies the calculation across the last dimension (in this case, the feature dimension) instead of the row dimension</p>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034719.png" width="400px"><p>Subtracting the mean and dividing by the square-root of the variance (standard deviation) centers the inputs to have a mean of 0 and a variance of 1 across the column (feature) dimension:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">out</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Normalized layer outputs:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">out_norm</span><span class="p">)</span>

<span class="n">mean</span> <span class="o">=</span> <span class="n">out_norm</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">var</span> <span class="o">=</span> <span class="n">out_norm</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normalized layer outputs:
 tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],
        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],
       grad_fn=&lt;DivBackward0&gt;)
Mean:
 tensor([[2.9802e-08],
        [3.9736e-08]], grad_fn=&lt;MeanBackward1&gt;)
Variance:
 tensor([[1.],
        [1.]], grad_fn=&lt;VarBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>Each input is centered at 0 and has a unit variance of 1; to improve readability, we can disable PyTorch’s scientific notation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">sci_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean:
 tensor([[    0.0000],
        [    0.0000]], grad_fn=&lt;MeanBackward1&gt;)
Variance:
 tensor([[1.],
        [1.]], grad_fn=&lt;VarBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>Above, we normalized the features of each input
Now, using the same idea, we can implement a <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">norm_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">norm_x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Scale and shift</strong></p>
<p>Note that in addition to performing the normalization by subtracting the mean and dividing by the variance, we added two trainable parameters, a <code class="docutils literal notranslate"><span class="pre">scale</span></code> and a <code class="docutils literal notranslate"><span class="pre">shift</span></code> parameter
The initial <code class="docutils literal notranslate"><span class="pre">scale</span></code> (multiplying by 1) and <code class="docutils literal notranslate"><span class="pre">shift</span></code> (adding 0) values don’t have any effect; however, <code class="docutils literal notranslate"><span class="pre">scale</span></code> and <code class="docutils literal notranslate"><span class="pre">shift</span></code> are trainable parameters that the LLM automatically adjusts during training if it is determined that doing so would improve the model’s performance on its training task
This allows the model to learn appropriate scaling and shifting that best suit the data it is processing
Note that we also add a smaller value (<code class="docutils literal notranslate"><span class="pre">eps</span></code>) before computing the square root of the variance; this is to avoid division-by-zero errors if the variance is 0</p>
<p><strong>Biased variance</strong>
In the variance calculation above, setting <code class="docutils literal notranslate"><span class="pre">unbiased=False</span></code> means using the formula <span class="math notranslate nohighlight">\(\frac{\sum_i (x_i \bar{x})^2}{n}\)</span> to compute the variance where n is the sample size (here, the number of features or columns); this formula does not include Bessel’s correction (which uses <code class="docutils literal notranslate"><span class="pre">n-1</span></code> in the denominator), thus providing a biased estimate of the  variance
For LLMs, where the embedding dimension <code class="docutils literal notranslate"><span class="pre">n</span></code> is very large, the difference between using n and <code class="docutils literal notranslate"><span class="pre">n-1</span></code>
is negligible
However, GPT-2 was trained with a biased variance in the normalization layers, which is why we also adopted this setting for compatibility reasons with the pretrained weights that we will load in later chapters</p>
<p>Let’s now try out <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> in practice:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ln</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">emb_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">out_ln</span> <span class="o">=</span> <span class="n">ln</span><span class="p">(</span><span class="n">batch_example</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span> <span class="o">=</span> <span class="n">out_ln</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">var</span> <span class="o">=</span> <span class="n">out_ln</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean:
 tensor([[    -0.0000],
        [     0.0000]], grad_fn=&lt;MeanBackward1&gt;)
Variance:
 tensor([[1.0000],
        [1.0000]], grad_fn=&lt;VarBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034736.png" width="400px"></section>
<section id="implementing-a-feed-forward-network-with-gelu-activations">
<h2><span class="section-number">42.3. </span>Implementing a feed forward network with GELU activations<a class="headerlink" href="#implementing-a-feed-forward-network-with-gelu-activations" title="Permalink to this headline">#</a></h2>
<p>In this section, we implement a small neural network submodule that is used as part of the transformer block in LLMs
We start with the activation function
In deep learning, ReLU (Rectified Linear Unit) activation functions are commonly used due to their simplicity and effectiveness in various neural network architectures
In LLMs, various other types of activation functions are used beyond the traditional ReLU; two notable examples are GELU (Gaussian Error Linear Unit) and SwiGLU (Sigmoid-Weighted Linear Unit)
GELU and SwiGLU are more complex, smooth activation functions incorporating Gaussian and sigmoid-gated linear units, respectively, offering better performance for deep learning models, unlike the simpler, piecewise linear function of ReLU</p>
<p>GELU (<a class="reference external" href="https://arxiv.org/abs/1606.08415">Hendrycks and Gimpel 2016</a>) can be implemented in several ways; the exact version is defined as GELU(x)=x⋅Φ(x), where Φ(x) is the cumulative distribution function of the standard Gaussian distribution.
In practice, it’s common to implement a computationally cheaper approximation: <span class="math notranslate nohighlight">\(\text{GELU}(x) \approx 0.5 \cdot x \cdot \left(1 + \tanh\left[\sqrt{\frac{2}{\pi}} \cdot \left(x + 0.044715 \cdot x^3\right)\right]\right)
\)</span> (the original GPT-2 model was also trained with this approximation)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GELU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span> <span class="o">*</span> 
            <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.044715</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">gelu</span><span class="p">,</span> <span class="n">relu</span> <span class="o">=</span> <span class="n">GELU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

<span class="c1"># Some sample data</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y_gelu</span><span class="p">,</span> <span class="n">y_relu</span> <span class="o">=</span> <span class="n">gelu</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">([</span><span class="n">y_gelu</span><span class="p">,</span> <span class="n">y_relu</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;GELU&quot;</span><span class="p">,</span> <span class="s2">&quot;ReLU&quot;</span><span class="p">]),</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2"> activation function&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">(x)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/implementing-a-GPT-model_40_0.png" src="../../_images/implementing-a-GPT-model_40_0.png" />
</div>
</div>
<p>As we can see, ReLU is a piecewise linear function that outputs the input directly if it is positive; otherwise, it outputs zero
GELU is a smooth, non-linear function that approximates ReLU but with a non-zero gradient for negative values</p>
<p>Next, let’s implement the small neural network module, <code class="docutils literal notranslate"><span class="pre">FeedForward</span></code>, that we will be using in the LLM’s transformer block later:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">],</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">]),</span>
            <span class="n">GELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">]),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;drop_rate&quot;</span><span class="p">])</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">GPT_CONFIG_124M</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>768
</pre></div>
</div>
</div>
</div>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034801.png" width="400px"><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ffn</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">GPT_CONFIG_124M</span><span class="p">)</span>

<span class="c1"># input shape: [batch_size, num_token, emb_size]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span> 
<span class="n">out</span> <span class="o">=</span> <span class="n">ffn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 3, 768])
</pre></div>
</div>
</div>
</div>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034813.png" width="400px"><img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034827.png" width="400px"></section>
<section id="adding-shortcut-connections">
<h2><span class="section-number">42.4. </span>Adding shortcut connections<a class="headerlink" href="#adding-shortcut-connections" title="Permalink to this headline">#</a></h2>
<p>Next, let’s talk about the concept behind shortcut connections, also called skip or residual connections
Originally, shortcut connections were proposed in deep networks for computer vision (residual networks) to mitigate vanishing gradient problems
A shortcut connection creates an alternative shorter path for the gradient to flow through the network
This is achieved by adding the output of one layer to the output of a later layer, usually skipping one or more layers in between
Let’s illustrate this idea with a small example network:</p>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034841.png" width="400px"><p>In code, it looks like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ExampleDeepNeuralNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_sizes</span><span class="p">,</span> <span class="n">use_shortcut</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_shortcut</span> <span class="o">=</span> <span class="n">use_shortcut</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">GELU</span><span class="p">()),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="n">GELU</span><span class="p">()),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> <span class="n">GELU</span><span class="p">()),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">4</span><span class="p">]),</span> <span class="n">GELU</span><span class="p">()),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">5</span><span class="p">]),</span> <span class="n">GELU</span><span class="p">())</span>
        <span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="c1"># Compute the output of the current layer</span>
            <span class="n">layer_output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="c1"># Check if shortcut can be applied</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_shortcut</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">layer_output</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">layer_output</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">layer_output</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">print_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># Forward pass</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">]])</span>

    <span class="c1"># Calculate loss based on how close the target</span>
    <span class="c1"># and output are</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    
    <span class="c1"># Backward pass to calculate the gradients</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="s1">&#39;weight&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="c1"># Print the mean absolute gradient of the weights</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> has gradient mean of </span><span class="si">{</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s print the gradient values first <strong>without</strong> shortcut connections:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  

<span class="n">sample_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]])</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">model_without_shortcut</span> <span class="o">=</span> <span class="n">ExampleDeepNeuralNetwork</span><span class="p">(</span>
    <span class="n">layer_sizes</span><span class="p">,</span> <span class="n">use_shortcut</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">print_gradients</span><span class="p">(</span><span class="n">model_without_shortcut</span><span class="p">,</span> <span class="n">sample_input</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>layers.0.0.weight has gradient mean of 0.00020173587836325169
layers.1.0.weight has gradient mean of 0.0001201116101583466
layers.2.0.weight has gradient mean of 0.0007152041653171182
layers.3.0.weight has gradient mean of 0.001398873864673078
layers.4.0.weight has gradient mean of 0.005049646366387606
</pre></div>
</div>
</div>
</div>
<p>Next, let’s print the gradient values <strong>with</strong> shortcut connections:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">model_with_shortcut</span> <span class="o">=</span> <span class="n">ExampleDeepNeuralNetwork</span><span class="p">(</span>
    <span class="n">layer_sizes</span><span class="p">,</span> <span class="n">use_shortcut</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">print_gradients</span><span class="p">(</span><span class="n">model_with_shortcut</span><span class="p">,</span> <span class="n">sample_input</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>layers.0.0.weight has gradient mean of 0.22169792652130127
layers.1.0.weight has gradient mean of 0.20694105327129364
layers.2.0.weight has gradient mean of 0.32896995544433594
layers.3.0.weight has gradient mean of 0.2665732502937317
layers.4.0.weight has gradient mean of 1.3258541822433472
</pre></div>
</div>
</div>
</div>
<p>As we can see based on the output above, shortcut connections prevent the gradients from vanishing in the early layers (towards <code class="docutils literal notranslate"><span class="pre">layer.0</span></code>)
We will use this concept of a shortcut connection next when we implement a transformer block</p>
</section>
<section id="connecting-attention-and-linear-layers-in-a-transformer-block">
<h2><span class="section-number">42.5. </span>Connecting attention and linear layers in a transformer block<a class="headerlink" href="#connecting-attention-and-linear-layers-in-a-transformer-block" title="Permalink to this headline">#</a></h2>
<p>In this section, we now combine the previous concepts into a so-called transformer block
A transformer block combines the causal multi-head attention module with the linear layers, the feed forward neural network
In addition, the transformer block also uses dropout and shortcut connections</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Some necessary functions</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>


<span class="k">class</span> <span class="nc">GPTDatasetV1</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">txt</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_ids</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Tokenize the entire text</span>
        <span class="n">token_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>

        <span class="c1"># Use a sliding window to chunk the book into overlapping sequences of max_length</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span> <span class="o">-</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
            <span class="n">input_chunk</span> <span class="o">=</span> <span class="n">token_ids</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">max_length</span><span class="p">]</span>
            <span class="n">target_chunk</span> <span class="o">=</span> <span class="n">token_ids</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">max_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_chunk</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target_chunk</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">create_dataloader_v1</span><span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                         <span class="n">stride</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="c1"># Initialize the tokenizer</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>

    <span class="c1"># Create dataset</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">GPTDatasetV1</span><span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>

    <span class="c1"># Create dataloader</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">dataloader</span>


<span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">d_out</span> <span class="o">%</span> <span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;d_out must be divisible by num_heads&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">d_out</span> <span class="o">=</span> <span class="n">d_out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">=</span> <span class="n">d_out</span> <span class="o">//</span> <span class="n">num_heads</span>  <span class="c1"># Reduce the projection dim to match desired output dim</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">W_query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_out</span><span class="p">,</span> <span class="n">d_out</span><span class="p">)</span>  <span class="c1"># Linear layer to combine head outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;mask&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="n">block_size</span><span class="p">),</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="n">d_in</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Shape: (b, num_tokens, d_out)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># We implicitly split the matrix by adding a `num_heads` dimension</span>
        <span class="c1"># Unroll last dim: (b, num_tokens, d_out) -&gt; (b, num_tokens, num_heads, head_dim)</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">keys</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>

        <span class="c1"># Transpose: (b, num_tokens, num_heads, head_dim) -&gt; (b, num_heads, num_tokens, head_dim)</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Compute scaled dot-product attention (aka self-attention) with a causal mask</span>
        <span class="n">attn_scores</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">@</span> <span class="n">keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># Dot product for each head</span>

        <span class="c1"># Original mask truncated to the number of tokens and converted to boolean</span>
        <span class="n">mask_bool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()[:</span><span class="n">num_tokens</span><span class="p">,</span> <span class="p">:</span><span class="n">num_tokens</span><span class="p">]</span>

        <span class="c1"># Use the mask to fill attention scores</span>
        <span class="n">attn_scores</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask_bool</span><span class="p">,</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>

        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_scores</span> <span class="o">/</span> <span class="n">keys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span>

        <span class="c1"># Shape: (b, num_tokens, num_heads, head_dim)</span>
        <span class="n">context_vec</span> <span class="o">=</span> <span class="p">(</span><span class="n">attn_weights</span> <span class="o">@</span> <span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Combine heads, where self.d_out = self.num_heads * self.head_dim</span>
        <span class="n">context_vec</span> <span class="o">=</span> <span class="n">context_vec</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_out</span><span class="p">)</span>
        <span class="n">context_vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">context_vec</span><span class="p">)</span>  <span class="c1"># optional projection</span>

        <span class="k">return</span> <span class="n">context_vec</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">att</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span>
            <span class="n">d_in</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">],</span>
            <span class="n">d_out</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">],</span>
            <span class="n">block_size</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;ctx_len&quot;</span><span class="p">],</span>
            <span class="n">num_heads</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;n_heads&quot;</span><span class="p">],</span> 
            <span class="n">dropout</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;drop_rate&quot;</span><span class="p">],</span>
            <span class="n">qkv_bias</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;qkv_bias&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_resid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;drop_rate&quot;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Shortcut connection for attention block</span>
        <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Shape [batch_size, num_tokens, emb_size]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_resid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">shortcut</span>  <span class="c1"># Add the original input back</span>

        <span class="c1"># Shortcut connection for feed forward block</span>
        <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_resid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">shortcut</span>  <span class="c1"># Add the original input back</span>

        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034859.png" width="400px"><p>Suppose we have 2 input samples with 6 tokens each, where each token is a 768-dimensional embedding vector; then this transformer block applies self-attention, followed by linear layers, to produce an output of similar size
You can think of the output as an augmented version of the context vectors we discussed in the previous chapter</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, num_tokens, emb_dim]</span>
<span class="n">block</span> <span class="o">=</span> <span class="n">TransformerBlock</span><span class="p">(</span><span class="n">GPT_CONFIG_124M</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Input shape:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output shape:&quot;</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input shape: torch.Size([2, 4, 768])
Output shape: torch.Size([2, 4, 768])
</pre></div>
</div>
</div>
</div>
</section>
<section id="coding-the-gpt-model">
<h2><span class="section-number">42.6. </span>Coding the GPT model<a class="headerlink" href="#coding-the-gpt-model" title="Permalink to this headline">#</a></h2>
<p>We are almost there: now let’s plug in the transformer block into the architecture we coded at the very beginning of this chapter so that we obtain a useable GPT architecture
Note that the transformer block is repeated multiple times; in the case of the smallest 124M GPT-2 model, we repeat it 12 times:</p>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_034913.png" width="400px"><p>The corresponding code implementation, where <code class="docutils literal notranslate"><span class="pre">cfg[&quot;n_layers&quot;]</span> <span class="pre">=</span> <span class="pre">12</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GPTModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tok_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;ctx_len&quot;</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;drop_rate&quot;</span><span class="p">])</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">trf_blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])])</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">final_norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;emb_dim&quot;</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_idx</span><span class="p">):</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">in_idx</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">tok_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tok_emb</span><span class="p">(</span><span class="n">in_idx</span><span class="p">)</span>
        <span class="n">pos_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">in_idx</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tok_embeds</span> <span class="o">+</span> <span class="n">pos_embeds</span>  <span class="c1"># Shape [batch_size, num_tokens, emb_size]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trf_blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>
</pre></div>
</div>
</div>
</div>
<p>Using the configuration of the 124M parameter model, we can now instantiate this GPT model with random initial weights as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPTModel</span><span class="p">(</span><span class="n">GPT_CONFIG_124M</span><span class="p">)</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Input batch:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Output shape:&quot;</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input batch:
 tensor([[6109, 3626, 6100,  345],
        [6109, 1110, 6622,  257]])

Output shape: torch.Size([2, 4, 50257])
tensor([[[ 0.6525,  0.5753,  0.0174,  ...,  0.2988,  0.1441,  0.0032],
         [ 0.0839, -0.6789, -0.6605,  ..., -0.2912,  0.4267, -0.2696],
         [ 0.8440,  0.1894,  0.0708,  ...,  0.0982, -0.2183,  0.0920],
         [-0.7958,  0.5066,  0.0209,  ...,  0.7497,  0.3233, -0.1251]],

        [[ 0.0181,  0.2606, -0.3022,  ...,  0.2940,  0.1998, -0.6246],
         [ 0.0596,  0.3041, -0.0293,  ...,  0.6796, -0.1226,  0.1303],
         [ 1.1895,  1.0891,  0.0237,  ...,  0.8299,  0.1794, -0.2250],
         [ 0.5457,  0.1861,  0.3872,  ...,  1.3537, -0.4062, -0.0268]]],
       grad_fn=&lt;UnsafeViewBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>We will train this model in the next chapter
However, a quick note about its size: we previously referred to it as a 124M parameter model; we can double check this number as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total number of parameters: </span><span class="si">{</span><span class="n">total_params</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total number of parameters: 163,009,536
</pre></div>
</div>
</div>
</div>
<p>As we see above, this model has 163M, not 124M parameters; why?
In the original GPT-2 paper, the researchers applied weight tying, which means that they reused the token embedding layer (<code class="docutils literal notranslate"><span class="pre">tok_emb</span></code>) as the output layer, which means setting <code class="docutils literal notranslate"><span class="pre">self.out_head.weight</span> <span class="pre">=</span> <span class="pre">self.tok_emb.weight</span></code>
The token embedding layer projects the 50,257-dimensional one-hot encoded input tokens to a 768-dimensional embedding representation
The output layer projects 768-dimensional embeddings back into a 50,257-dimensional representation so that we can convert these back into words (more about that in the next section)
So, the embedding and output layer have the same number of weight parameters, as we can see based on the shape of their weight matrices: the next chapter
However, a quick note about its size: we previously referred to it as a 124M parameter model; we can double check this number as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Token embedding layer shape:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">tok_emb</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output layer shape:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">out_head</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Token embedding layer shape: torch.Size([50257, 768])
Output layer shape: torch.Size([50257, 768])
</pre></div>
</div>
</div>
</div>
<p>In the original GPT-2 paper, the researchers reused the token embedding matrix as an output matrix
Correspondingly, if we subtracted the number of parameters of the output layer, we’d get a 124M parameter model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">total_params_gpt2</span> <span class="o">=</span>  <span class="n">total_params</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">out_head</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of trainable parameters considering weight tying: </span><span class="si">{</span><span class="n">total_params_gpt2</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of trainable parameters considering weight tying: 124,412,160
</pre></div>
</div>
</div>
</div>
<p>In practice, I found it easier to train the model without weight-tying, which is why we didn’t implement it here
However, we will revisit and apply this weight-tying idea later when we load the pretrained weights in Chapter 6
Lastly, we can compute the memory requirements of the model as follows, which can be a helpful reference point:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate the total size in bytes (assuming float32, 4 bytes per parameter)</span>
<span class="n">total_size_bytes</span> <span class="o">=</span> <span class="n">total_params</span> <span class="o">*</span> <span class="mi">4</span>

<span class="c1"># Convert to megabytes</span>
<span class="n">total_size_mb</span> <span class="o">=</span> <span class="n">total_size_bytes</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total size of the model: </span><span class="si">{</span><span class="n">total_size_mb</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total size of the model: 621.83 MB
</pre></div>
</div>
</div>
</div>
<p>Exercise: you can try the following other configurations, which are referenced in the <a class="reference external" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2 paper</a>, as well.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>**GPT2-small** (the 124M configuration we already implemented):
    &quot;emb_dim&quot; = 768
    &quot;n_layers&quot; = 12
    &quot;n_heads&quot; = 12

**GPT2-medium:**
    &quot;emb_dim&quot; = 1024
    &quot;n_layers&quot; = 24
    &quot;n_heads&quot; = 16

**GPT2-large:**
    &quot;emb_dim&quot; = 1280
    &quot;n_layers&quot; = 36
    &quot;n_heads&quot; = 20

**GPT2-XL:**
    &quot;emb_dim&quot; = 1600
    &quot;n_layers&quot; = 48
    &quot;n_heads&quot; = 25
</pre></div>
</div>
</section>
<section id="generating-text">
<h2><span class="section-number">42.7. </span>Generating text<a class="headerlink" href="#generating-text" title="Permalink to this headline">#</a></h2>
<p>LLMs like the GPT model we implemented above are used to generate one word at a time</p>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_035139.png" width="400px"><p>The following <code class="docutils literal notranslate"><span class="pre">generate_text_simple</span></code> function implements greedy decoding, which is a simple and fast method to generate text
In greedy decoding, at each step, the model chooses the word (or token) with the highest probability as its next output (the highest logit corresponds to the highest probability, so we technically wouldn’t even have to compute the softmax function explicitly)
In the next chapter, we will implement a more advanced <code class="docutils literal notranslate"><span class="pre">generate_text</span></code> function
The figure below depicts how the GPT model, given an input context, generates the next word token</p>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_035151.png" width="600px"><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_text_simple</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="p">,</span> <span class="n">context_size</span><span class="p">):</span>
    <span class="c1"># idx is (batch, n_tokens) array of indices in the current context</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>
        
        <span class="c1"># Crop current context if it exceeds the supported context size</span>
        <span class="c1"># E.g., if LLM supports only 5 tokens, and the context size is 10</span>
        <span class="c1"># then only the last 5 tokens are used as context</span>
        <span class="n">idx_cond</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[:,</span> <span class="o">-</span><span class="n">context_size</span><span class="p">:]</span>
        
        <span class="c1"># Get the predictions</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">idx_cond</span><span class="p">)</span>
        
        <span class="c1"># Focus only on the last time step</span>
        <span class="c1"># (batch, n_tokens, vocab_size) becomes (batch, vocab_size)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>  

        <span class="c1"># Apply softmax to get probabilities</span>
        <span class="n">probas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch, vocab_size)</span>

        <span class="c1"># Get the idx of the vocab entry with the highest probability value</span>
        <span class="n">idx_next</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probas</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># (batch, 1)</span>

        <span class="c1"># Append sampled index to the running sequence</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">idx_next</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch, n_tokens+1)</span>

    <span class="k">return</span> <span class="n">idx</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">generate_text_simple</span></code> above implements an iterative process, where it creates one token at a time</p>
<img src="https://static-1300131294.cos.ap-shanghai.myqcloud.com/images/llm/clipboard_20240409_035205.png" width="600px"><p>Let’s prepare an input example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.4929</span>
<span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">4.4812</span>
<span class="n">b</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.6093</span>

<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([-1.4929,  4.4812, -1.6093], grad_fn=&lt;SliceBackward0&gt;)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([    0.0000,     0.0012,     0.0000,  ...,     0.0000,     0.0000,
            0.0000], grad_fn=&lt;SoftmaxBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">start_context</span> <span class="o">=</span> <span class="s2">&quot;Hello, I am&quot;</span>

<span class="n">encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">start_context</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;encoded:&quot;</span><span class="p">,</span> <span class="n">encoded</span><span class="p">)</span>

<span class="n">encoded_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;encoded_tensor.shape:&quot;</span><span class="p">,</span> <span class="n">encoded_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>encoded: [15496, 11, 314, 716]
encoded_tensor.shape: torch.Size([1, 4])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># disable dropout</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">generate_text_simple</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">idx</span><span class="o">=</span><span class="n">encoded_tensor</span><span class="p">,</span> 
    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> 
    <span class="n">context_size</span><span class="o">=</span><span class="n">GPT_CONFIG_124M</span><span class="p">[</span><span class="s2">&quot;ctx_len&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output:&quot;</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output length:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])
Output length: 10
</pre></div>
</div>
</div>
</div>
<p>Remove batch dimension and convert back into text:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">decoded_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">decoded_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hello, I am Featureiman Byeswickattribute argue
</pre></div>
</div>
</div>
</div>
</section>
<section id="your-turn">
<h2><span class="section-number">42.8. </span>Your turn! 🚀<a class="headerlink" href="#your-turn" title="Permalink to this headline">#</a></h2>
<p>tbd.</p>
</section>
<section id="acknowledgments">
<h2><span class="section-number">42.9. </span>Acknowledgments<a class="headerlink" href="#acknowledgments" title="Permalink to this headline">#</a></h2>
<p>Thanks to <a class="reference external" href="https://github.com/rasbt">Sebastian Raschka</a> for creating the open-source course <a class="reference external" href="https://github.com/rasbt/LLMs-from-scratch">Build a Large Language Model (From Scratch)</a>. It inspires the majority of the content in this chapter.</p>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ocademy-ai/machine-learning",
            ref: "release",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./llm/pretrained-model"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../basic/language-modelling.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">41.3. </span>Transformers for Language Modelling</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="pretraining-on-unlabeled-data.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">42.10. </span>Pretraining on Unlabeled Data</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ocademy<br/>
  
      &copy; Copyright 2022-2023.<br/>
    <div class="extra_footer">
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> Text content of this work is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>