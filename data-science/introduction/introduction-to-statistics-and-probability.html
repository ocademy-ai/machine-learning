
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>4.4. Introduction to statistics and probability &#8212; Machine Learning Open Course</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/drawio.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/youtube.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "open-academy/machine-learning-utterances");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "üí¨ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"></script>
    <script>quizdown.init({"quizdown_js": "https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"});</script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5. Working with data" href="../working-with-data/working-with-data.html" />
    <link rel="prev" title="4.3. Defining data" href="defining-data.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning Open Course</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PREREQUISITES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../prerequisites/python-programming-introduction.html">
   1. Python programming introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prerequisites/python-programming-basics.html">
   2. Python programming basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../prerequisites/python-programming-advanced.html">
   3. Python programming advanced
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATA SCIENCE
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="introduction.html">
   4. Introduction
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="defining-data-science.html">
     4.1. Defining data science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="data-science-ethics.html">
     4.2. Data Science ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="defining-data.html">
     4.3. Defining data
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     4.4. Introduction to statistics and probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../working-with-data/working-with-data.html">
   5. Working with data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../working-with-data/relational-databases.html">
     5.1. Relational databases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../working-with-data/non-relational-data.html">
     5.2. Non-relational data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../working-with-data/numpy.html">
     5.3. NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../working-with-data/pandas.html">
     5.4. Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../working-with-data/data-preparation.html">
     5.5. Data preparation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-visualization/data-visualization.html">
   6. Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-visualization/visualizing-quantities.html">
     6.1. Visualizing Quantities
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science-lifecycle/data-science-lifecycle.html">
   7. Data Science lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science-lifecycle/introduction.html">
     7.1. Introduction to the Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science-lifecycle/analyzing.html">
     7.2. Analyzing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science-lifecycle/communication.html">
     7.3. Communication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science-in-the-cloud/data-science-in-the-cloud.html">
   8. Data Science in the cloud
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science-in-the-cloud/introduction.html">
     8.1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science-in-the-cloud/the-low-code-no-code-way.html">
     8.2. The ‚Äúlow code/no code‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science-in-the-cloud/the-azure-ml-sdk-way.html">
     8.3. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-science-in-the-wild.html">
   9. Data Science in the real world
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  FUNDAMENTALS OF MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-fundamentals/ml-overview.html">
   10. Machine learning overview (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-fundamentals/linear-regression.html">
   11. Linear regression (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-fundamentals/logistic-regression.html">
   12. Logistic regression (TBD)
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-fundamentals/parameter-optimization/parameter-optimization.html">
   13. Parameter optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/parameter-optimization/gradient-descent.html">
     13.1. Gradient descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/parameter-optimization/loss-function.html">
     13.2. Loss function
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-fundamentals/neural-network/neural-network.html">
   14. Neural network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/neural-network/nn-basics.html">
     14.1. Neural network basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/neural-network/nn-hands-on.html">
     14.2. Hands on neural network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-fundamentals/neural-network/nn-implementation.html">
     14.3. Neural network implementation from scratch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-fundamentals/ml-summary.html">
   15. Summary of machine learning fundamentals
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ADVANCED MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/kernel-method.html">
   16. Kernel method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/model-selection.html">
   17. Model selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/ensemble-learning.html">
   18. Ensemble learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/unsupervised-learning.html">
   19. Unsupervised learning (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ml-advanced/generative-models.html">
   20. Generative models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/dl-overview.html">
   21. Deep learning overview (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/CNN.html">
   22. CNN (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/GAN.html">
   23. GAN (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/RNN.html">
   24. RNN (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/AutoEncoder.html">
   25. Autoencoder (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/LSTM.html">
   26. LSTM (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/NLP.html">
   27. NLP (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/time-series.html">
   28. Time series (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/DQN.html">
   29. DQN (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../deep-learning/dl-summary.html">
   30. Summary of deep learning (TBD)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING PRODUCTIONIZATION
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/overview.html">
   31. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/problem-framing.html">
   32. Problem framing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/data-engineering.html">
   33. Data engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/model-training-and-evaluation.html">
   34. Model training &amp; evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine-learning-productionization/model-deployment.html">
   35. Model deployment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  SUPPORTING MATERIALS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../supporting-materials/pytorch.html">
   36. PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../supporting-materials/bamboolib.html">
   37. Bamboolib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../supporting-materials/mito.html">
   38. Mito
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../supporting-materials/KNN.html">
   39. KNN (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../supporting-materials/semi-supervised-learning.html">
   40. Semi-supervised learning (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../supporting-materials/unbalanced-problems.html">
   41. Unbalanced problems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../supporting-materials/automl.html">
   42. AutoML (TBD)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OTHERS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../assignments/introduction.html">
   43. Assignments
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/get-started.html">
     43.1. Get started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/prerequisites/python-programming-introduction.html">
     43.2. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/prerequisites/python-programming-basics.html">
     43.3. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/prerequisites/python-programming-advanced.html">
     43.4. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/analyzing-text-about-data-science.html">
     43.5. Analyzing text about Data Science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/data-science-scenarios.html">
     43.6. Data Science scenarios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/write-a-data-ethics-case-study.html">
     43.7. Write a data ethics case study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/classifying-datasets.html">
     43.8. Classifying datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/small-diabetes-study.html">
     43.9. Small diabetes study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/introduction-to-statistics-and-probability.html">
     43.10. Introduction to probability and statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/displaying-airport-data.html">
     43.11. Displaying airport data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/soda-profits.html">
     43.12. Soda profits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/analyzing-COVID-19-papers.html">
     43.13. Analyzing COVID-19 papers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/estimation-of-COVID-19-pandemic.html">
     43.14. Estimation of COVID-19 pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/data-processing-in-python.html">
     43.15. Data processing in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/evaluating-data-from-a-form.html">
     43.16. Evaluating data from a form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/data-preparation.html">
     43.17. Data preparation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/analyzing-data.html">
     43.18. Analyzing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/nyc-taxi-data-in-winter-and-summer.html">
     43.19. NYC taxi data in winter and summer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/tell-a-story.html">
     43.20. Tell a story
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/explore-a-planetary-computer-dataset.html">
     43.21. Explore a planetary computer dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/exploring-for-anwser.html">
     43.22. Exploring for answers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/market-research.html">
     43.23. Market research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/low-code-no-code-data-science-project-on-azure-ml.html">
     43.24. Low code/no code Data Science project on Azure ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/data-science-project-using-azure-ml-sdk.html">
     43.25. Data Science project using Azure ML SDK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/data-science/data-science-in-the-cloud-the-azure-ml-sdk-way.html">
     43.26. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/project-plan-template.html">
     43.27. Project Plan‚Äã Template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/machine-learning-productionization/data-engineering.html">
     43.28. Data engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/machine-learning-productionization/counterintuitive-challenges-in-ml-debugging.html">
     43.29. Counterintuitive Challenges in ML Debugging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/machine-learning-productionization/debugging-in-classification.html">
     43.30. Case Study: Debugging in Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../assignments/machine-learning-productionization/debugging-in-regression.html">
     43.31. Case Study: Debugging in Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../slides/introduction.html">
   44. Slides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/python-programming-introduction.html">
     44.1. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../slides/python-programming-basics.html">
     44.2. Python programming basics
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/open-academy/machine-learning/main?urlpath=tree/open-machine-learning-jupyter-book/data-science/introduction/introduction-to-statistics-and-probability.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/open-academy/machine-learning/blob/main/open-machine-learning-jupyter-book/data-science/introduction/introduction-to-statistics-and-probability.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/open-academy/machine-learning/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/open-academy/machine-learning//issues/new?title=Issue%20on%20page%20%2Fdata-science/introduction/introduction-to-statistics-and-probability.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/open-academy/machine-learning/edit/main/open-machine-learning-jupyter-book/data-science/introduction/introduction-to-statistics-and-probability.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/data-science/introduction/introduction-to-statistics-and-probability.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="../../_sources/data-science/introduction/introduction-to-statistics-and-probability.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability-and-random-variables">
   4.4.1. Probability and random variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability-distribution">
   4.4.2. Probability distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mean-variance-and-standard-deviation">
   4.4.3. Mean, variance and standard deviation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mode-median-and-quartiles">
   4.4.4. Mode, median and quartiles
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#real-world-data">
   4.4.5. Real-world data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normal-distribution">
   4.4.6. Normal distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confidence-intervals">
   4.4.7. Confidence intervals
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypothesis-testing">
   4.4.8. Hypothesis testing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#law-of-large-numbers-and-central-limit-theorem">
   4.4.9. Law of large numbers and central limit theorem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#covariance-and-correlation">
   4.4.10. Covariance and correlation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   4.4.11. Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-turn">
   4.4.12. Your turn! üöÄ
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#self-study">
   4.4.13. Self study
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   4.4.14. Acknowledgments
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Introduction to statistics and probability</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability-and-random-variables">
   4.4.1. Probability and random variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability-distribution">
   4.4.2. Probability distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mean-variance-and-standard-deviation">
   4.4.3. Mean, variance and standard deviation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mode-median-and-quartiles">
   4.4.4. Mode, median and quartiles
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#real-world-data">
   4.4.5. Real-world data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normal-distribution">
   4.4.6. Normal distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confidence-intervals">
   4.4.7. Confidence intervals
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypothesis-testing">
   4.4.8. Hypothesis testing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#law-of-large-numbers-and-central-limit-theorem">
   4.4.9. Law of large numbers and central limit theorem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#covariance-and-correlation">
   4.4.10. Covariance and correlation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   4.4.11. Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-turn">
   4.4.12. Your turn! üöÄ
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#self-study">
   4.4.13. Self study
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   4.4.14. Acknowledgments
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="introduction-to-statistics-and-probability">
<h1><span class="section-number">4.4. </span>Introduction to statistics and probability<a class="headerlink" href="#introduction-to-statistics-and-probability" title="Permalink to this headline">#</a></h1>
<p>Statistics and Probability Theory are two highly related areas of Mathematics that are highly relevant to Data Science. It is possible to operate with data without deep knowledge of mathematics, but it is still better to know at least some basic concepts. Here we will present a short introduction that will help you get started.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<div class="yt-container">
   <iframe width="560" height="315" src="https://www.youtube.com/embed/Z5Zy85g4Yjw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
</div>
<section id="probability-and-random-variables">
<h2><span class="section-number">4.4.1. </span>Probability and random variables<a class="headerlink" href="#probability-and-random-variables" title="Permalink to this headline">#</a></h2>
<p><strong>Probability</strong> is a number between 0 and 1 that expresses how probable an <strong>event</strong> is. It is defined as a number of positive outcomes (that lead to the event), divided by a total number of outcomes, given that all outcomes are equally probable. For example, when we roll a dice, the probability that we get an even number is <span class="math notranslate nohighlight">\(3/6 = 0.5\)</span>.</p>
<p>When we talk about events, we use <strong>random variables</strong>. For example, the random variable that represents a number obtained when rolling a dice would take values from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(6\)</span>. A set of numbers from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(6\)</span> is called <strong>sample space</strong>. We can talk about the probability of a random variable taking a certain value, for example, <span class="math notranslate nohighlight">\(P(X=3)=1/6\)</span>.</p>
<p>The random variable in the previous example is called <strong>discrete</strong> because it has a countable sample space, i.e. there are separate values that can be enumerated. There are cases when sample space is a range of real numbers or the whole set of real numbers. Such variables are called <strong>continuous</strong>. A good example is a time when the bus arrives.</p>
</section>
<section id="probability-distribution">
<h2><span class="section-number">4.4.2. </span>Probability distribution<a class="headerlink" href="#probability-distribution" title="Permalink to this headline">#</a></h2>
<p>In the case of discrete random variables, it is easy to describe the probability of each event by a function <span class="math notranslate nohighlight">\(P(X)\)</span>. For each value <span class="math notranslate nohighlight">\(s\)</span> from sample space <span class="math notranslate nohighlight">\(S\)</span> it will give a number from <span class="math notranslate nohighlight">\(0\)</span> to <span class="math notranslate nohighlight">\(1\)</span>, such that the sum of all values of <span class="math notranslate nohighlight">\(P(X=s)\)</span> for all events would be <span class="math notranslate nohighlight">\(1\)</span>.</p>
<p>The most well-known discrete distribution is a <strong>uniform distribution</strong>, in which there is a sample space of <span class="math notranslate nohighlight">\(N\)</span> elements, with an equal probability of <span class="math notranslate nohighlight">\(1/N\)</span> for each of them.</p>
<p>It is more difficult to describe the probability distribution of a continuous variable, with values drawn from some interval <span class="math notranslate nohighlight">\([a,b]\)</span>, or the whole set of real numbers <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. Consider the case of bus arrival time. In fact, for each exact arrival time <span class="math notranslate nohighlight">\(t\)</span>, the probability of a bus arriving at exactly that time is <span class="math notranslate nohighlight">\(0\)</span>!</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Now you know that events with <span class="math notranslate nohighlight">\(0\)</span> probability happen, and very often! At least each time when the bus arrives!</p>
</div>
<p>We can only talk about the probability of a variable falling in a given interval of values, eg. <span class="math notranslate nohighlight">\(P(t_1 \le X &lt; t_2)\)</span>. In this case, the probability distribution is described by a <strong>probability density function</strong> p(x), such that</p>
<div class="math notranslate nohighlight">
\[P(t_1\le X&lt;t_2)=\int_{t_1}^{t_2}p(x)dx\]</div>
<p>A continuous analog of uniform distribution is called <strong>continuous uniform</strong>, which is defined on a finite interval. A probability that the value <span class="math notranslate nohighlight">\(X\)</span> falls into an interval of length <span class="math notranslate nohighlight">\(l\)</span> is proportional to <span class="math notranslate nohighlight">\(l\)</span>, and rises to <span class="math notranslate nohighlight">\(1\)</span>.</p>
<p>Another important distribution is <strong>normal distribution</strong>, which we will talk about in more detail below.</p>
</section>
<section id="mean-variance-and-standard-deviation">
<h2><span class="section-number">4.4.3. </span>Mean, variance and standard deviation<a class="headerlink" href="#mean-variance-and-standard-deviation" title="Permalink to this headline">#</a></h2>
<p>Suppose we draw a sequence of n samples of a random variable <span class="math notranslate nohighlight">\(X: x_1, x_2, ..., x_n\)</span>. We can define the <strong>mean</strong> (or <strong>arithmetic average</strong>) value of the sequence in the traditional way as <span class="math notranslate nohighlight">\((x_1+x_2+x_n)/n\)</span>. As we grow the size of the sample (i.e. take the limit with <span class="math notranslate nohighlight">\(n\to\infty\)</span>), we will obtain the mean (also called <strong>expectation</strong>) of the distribution. We will denote expectation by <span class="math notranslate nohighlight">\(E(x)\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It can be demonstrated that for any discrete distribution with values <span class="math notranslate nohighlight">\(\{x_1, x_2, ..., x_N\}\)</span> and corresponding probabilities <span class="math notranslate nohighlight">\(p_1, p_2, ..., p_N\)</span>, the expectation would equal to <span class="math notranslate nohighlight">\(E(X)=x_1p_1+x_2p_2+...+x_Np_N\)</span>.</p>
</div>
<p>To identify how far the values are spread, we can compute the variance <span class="math notranslate nohighlight">\(\sigma^2 = \sum(x_i - \mu;)^2/n\)</span>, where <span class="math notranslate nohighlight">\(\mu\)</span> is the mean of the sequence. The value <span class="math notranslate nohighlight">\(\sigma\)</span> is called <strong>standard deviation</strong>, and <span class="math notranslate nohighlight">\(\sigma^2\)</span> is called a <strong>variance</strong>.</p>
</section>
<section id="mode-median-and-quartiles">
<h2><span class="section-number">4.4.4. </span>Mode, median and quartiles<a class="headerlink" href="#mode-median-and-quartiles" title="Permalink to this headline">#</a></h2>
<p>Sometimes, the mean does not adequately represent the ‚Äútypical‚Äù value for data. For example, when there are a few extreme values that are completely out of range, they can affect the mean. Another good indication is a <strong>median</strong>, a value such that half of the data points are lower than it, and another half - higher.</p>
<p>To help us understand the distribution of data, it is helpful to talk about <strong>quartiles</strong>:</p>
<ul class="simple">
<li><p>the first quartile, or <span class="math notranslate nohighlight">\(Q1\)</span>, is a value, such that <span class="math notranslate nohighlight">\(25%\)</span> of the data fall below it,</p></li>
<li><p>the third quartile, or <span class="math notranslate nohighlight">\(Q3\)</span>, is a value that <span class="math notranslate nohighlight">\(75%\)</span> of the data falls below it.</p></li>
</ul>
<p>Graphically we can represent the relationship between median and quartiles in a diagram called the <strong>box plot</strong>:</p>
<p><img alt="" src="../../_images/boxplot_explanation.png" /></p>
<p>Here we also compute the <strong>inter-quartile range</strong> <span class="math notranslate nohighlight">\(IQR=Q3-Q1\)</span>, and so-called <strong>outliers</strong> - values, that lie outside the boundaries <span class="math notranslate nohighlight">\([Q1-1.5*IQR,Q3+1.5*IQR]\)</span>.</p>
<p>For the finite distribution that contains a small number of possible values, a good ‚Äútypical‚Äù value is the one that appears the most frequently, which is called <strong>mode</strong>. It is often applied to categorical data, such as colors. Consider a situation where we have two groups of people - some that strongly prefer red, and others who prefer blue. If we code colors by numbers, the mean value for a favorite color would be somewhere in the orange-green spectrum, which does not indicate the actual preference for either group. However, the mode would be either one of the colors, or both colors, if the number of people voting for them is equal (in this case we call the sample <strong>multimodal</strong>).</p>
</section>
<section id="real-world-data">
<h2><span class="section-number">4.4.5. </span>Real-world data<a class="headerlink" href="#real-world-data" title="Permalink to this headline">#</a></h2>
<p>When we analyze data from real life, they often are not random variables as such, in the sense that we do not perform experiments with unknown results. For example, consider a team of baseball players, and their body data, such as height, weight and age. Those numbers are not exactly random, but we can still apply the same mathematical concepts. For example, a sequence of people‚Äôs weights can be considered to be a sequence of values drawn from some random variable. Below is the sequence of weights of actual baseball players from <a class="reference external" href="http://mlb.mlb.com/index.jsp">Major League Baseball</a>, taken from <a class="reference external" href="http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights">this dataset</a> (for your convenience, only the first 20 values are shown):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mf">180.0</span><span class="p">,</span> <span class="mf">215.0</span><span class="p">,</span> <span class="mf">210.0</span><span class="p">,</span> <span class="mf">210.0</span><span class="p">,</span> <span class="mf">188.0</span><span class="p">,</span> <span class="mf">176.0</span><span class="p">,</span> <span class="mf">209.0</span><span class="p">,</span> <span class="mf">200.0</span><span class="p">,</span> <span class="mf">231.0</span><span class="p">,</span> <span class="mf">180.0</span><span class="p">,</span> <span class="mf">188.0</span><span class="p">,</span> <span class="mf">180.0</span><span class="p">,</span> <span class="mf">185.0</span><span class="p">,</span> <span class="mf">160.0</span><span class="p">,</span> <span class="mf">180.0</span><span class="p">,</span> <span class="mf">185.0</span><span class="p">,</span> <span class="mf">197.0</span><span class="p">,</span> <span class="mf">189.0</span><span class="p">,</span> <span class="mf">185.0</span><span class="p">,</span> <span class="mf">219.0</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To see the example of working with this dataset, have a look at the <a class="reference internal" href="../../assignments/data-science/introduction-to-statistics-and-probability.html"><span class="doc std std-doc">accompanying notebook</span></a>. There are also a number of challenges throughout this section, and you may complete them by adding some code to that notebook. If you are not sure how to operate on data, do not worry - we will come back to working with data using Python at a later time. If you do not know how to run code in Jupyter Notebook, have a look at <a class="reference external" href="https://soshnikov.com/education/how-to-execute-notebooks-from-github/">this article</a>.</p>
</div>
<p>Here is the box plot showing the mean, median, and quartiles for our data:</p>
<p><img alt="Weight Box Plot" src="../../_images/weight-boxplot.png" /></p>
<p>Since our data contains information about different player <strong>roles</strong>, we can also do the box plot by role - it will allow us to get an idea on how parameter values differ across roles. This time we will consider height:</p>
<p><img alt="Box plot by role" src="../../_images/boxplot_byrole.png" /></p>
<p>This diagram suggests that, on average, the height of first basemen is higher than the height of second basemen. Later in this section, we will learn how we can test this hypothesis more formally, and how to demonstrate that our data is statistically significant to show that.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When working with real-world data, we assume that all data points are samples drawn from some probability distribution. This assumption allows us to apply machine learning techniques and build working predictive models.</p>
</div>
<p>To see what the distribution of our data is, we can plot a graph called a <strong>histogram</strong>. The X-axis would contain a number of different weight intervals (so-called <strong>bins</strong>), and the vertical axis would show the number of times our random variable sample was inside a given interval.</p>
<p><img alt="Histogram of real-world data" src="../../_images/weight-histogram.png" /></p>
<p>From this histogram, you can see that all values are centered around a certain mean weight, and the further we go from that weight - the fewer weights of that value are encountered. I.e., it is very improbable that the weight of a baseball player would be very different from the mean weight. The variance of weights shows the extent to which weights are likely to differ from the mean.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If we take weights of other people, not from the baseball league, the distribution is likely to be different. However, the shape of the distribution will be the same, but mean and variance would change. So, if we train our model on baseball players, it is likely to give wrong results when applied to students of a university, because the underlying distribution is different.</p>
</div>
</section>
<section id="normal-distribution">
<h2><span class="section-number">4.4.6. </span>Normal distribution<a class="headerlink" href="#normal-distribution" title="Permalink to this headline">#</a></h2>
<p>The distribution of weights that we have seen above is very typical, and many measurements from the real world follow the same type of distribution, but with different mean and variance. This distribution is called <strong>normal distribution</strong>, and it plays a very important role in statistics.</p>
<p>Using normal distribution is the correct way to generate random weights of potential baseball players. Once we know the mean weight <code class="docutils literal notranslate"><span class="pre">mean``</span> <span class="pre">and</span> <span class="pre">standard</span> <span class="pre">deviation</span> </code>std`, we can generate 1000 weight samples in the following way:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
<p>If we plot the histogram of the generated samples we will see a picture very similar to the one shown above. And if we increase the number of samples and the number of bins, we can generate a picture of a normal distribution that is more close to ideal:</p>
<figure class="align-default" id="normal-distribution-with-mean-0-and-std-dev-1">
<img alt="../../_images/normal-histogram.png" src="../../_images/normal-histogram.png" />
<figcaption>
<p><span class="caption-number">Fig. 4.5 </span><span class="caption-text">Normal distribution with <span class="math notranslate nohighlight">\(mean=0\)</span> and <span class="math notranslate nohighlight">\(std.dev=1\)</span></span><a class="headerlink" href="#normal-distribution-with-mean-0-and-std-dev-1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="confidence-intervals">
<h2><span class="section-number">4.4.7. </span>Confidence intervals<a class="headerlink" href="#confidence-intervals" title="Permalink to this headline">#</a></h2>
<p>When we talk about the weights of baseball players, we assume that there is a certain <strong>random variable</strong> <span class="math notranslate nohighlight">\(W\)</span> that corresponds to the ideal probability distribution of weights of all baseball players (so-called <strong>population</strong>). Our sequence of weights corresponds to a subset of all baseball players that we call <strong>sample</strong>. An interesting question is, can we know the parameters of the distribution of <span class="math notranslate nohighlight">\(W\)</span>, i.e. mean and variance of the population?</p>
<p>The easiest answer would be to calculate the mean and variance of our sample. However, it could happen that our random sample does not accurately represent the complete population. Thus it makes sense to talk about <strong>confidence interval</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Confidence interval</strong> is the estimation of true mean of the population given our sample, which is accurate is a certain probability (or <strong>level of confidence</strong>).</p>
</div>
<p>Suppose we have a sample <span class="math notranslate nohighlight">\(X_1, ..., X_n\)</span> from our distribution. Each time we draw a sample from our distribution, we would end up with a different mean value <span class="math notranslate nohighlight">\(\mu\)</span>. Thus <span class="math notranslate nohighlight">\(\mu\)</span> can be considered to be a random variable. A <strong>confidence interval</strong> with confidence <span class="math notranslate nohighlight">\(p\)</span> is a pair of values <span class="math notranslate nohighlight">\((L_p,R_p)\)</span>, such that <span class="math notranslate nohighlight">\(P(L_p\le\mu\le R_p) = p\)</span>, i.e. a probability of the measured mean value falling within the interval equals <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p>It does beyond our short intro to discuss in detail how those confidence intervals are calculated. Some more details can be found on <a class="reference external" href="https://en.wikipedia.org/wiki/Confidence_interval">Wikipedia</a>. In short, we define the distribution of the computed sample mean relative to the true mean of the population, which is called <strong>student distribution</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Interesting fact</strong>: Student distribution is named after mathematician William Sealy Gosset, who published his paper under the pseudonym ‚ÄúStudent‚Äù. He worked in the Guinness brewery, and, according to one of the versions, his employer did not want general public to know that they were using statistical tests to determine the quality of raw materials.</p>
</div>
<p>If we want to estimate the mean <span class="math notranslate nohighlight">\(\mu\)</span>; of our population with confidence <span class="math notranslate nohighlight">\(p\)</span>, we need to take <span class="math notranslate nohighlight">\((1-p)/2\)</span>-th percentile of a student distribution <span class="math notranslate nohighlight">\(A\)</span>, which can either be taken from tables or computer using some built-in functions of statistical software (eg. Python, R, etc.). Then the interval for <span class="math notranslate nohighlight">\(\mu\)</span>; would be given by <span class="math notranslate nohighlight">\(X\pm A*D/\sqrt{n}\)</span>, where <span class="math notranslate nohighlight">\(X\)</span> is the obtained mean of the sample, and <span class="math notranslate nohighlight">\(D\)</span> is the standard deviation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We also omit the discussion of an important concept of <a class="reference external" href="https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)">degrees of freedom</a>, which is important in relation to student distribution. You can refer to more complete books on statistics to understand this concept deeper.</p>
</div>
<p>An example of calculating the confidence interval for weights and heights is given in the <a class="reference internal" href="../../assignments/data-science/introduction-to-statistics-and-probability.html"><span class="doc std std-doc">accompanying notebooks</span></a>.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>p</p></th>
<th class="head"><p>Weight mean</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0.85</p></td>
<td><p>201.73¬±0.94</p></td>
</tr>
<tr class="row-odd"><td><p>0.90</p></td>
<td><p>201.73¬±1.08</p></td>
</tr>
<tr class="row-even"><td><p>0.95</p></td>
<td><p>201.73¬±1.28</p></td>
</tr>
</tbody>
</table>
<p>Notice that the higher the confidence probability, the wider the confidence interval.</p>
</section>
<section id="hypothesis-testing">
<h2><span class="section-number">4.4.8. </span>Hypothesis testing<a class="headerlink" href="#hypothesis-testing" title="Permalink to this headline">#</a></h2>
<p>In our baseball players dataset, there are different player roles, that can be summarized below (look at the <a class="reference internal" href="../../assignments/data-science/introduction-to-statistics-and-probability.html"><span class="doc std std-doc">accompanying notebooks</span></a>) to see how this table can be calculated):</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Role</p></th>
<th class="head"><p>Height</p></th>
<th class="head"><p>Weight</p></th>
<th class="head"><p>Count</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Catcher</p></td>
<td><p>72.723684</p></td>
<td><p>204.328947</p></td>
<td><p>76</p></td>
</tr>
<tr class="row-odd"><td><p>Designated_Hitter</p></td>
<td><p>74.222222</p></td>
<td><p>220.888889</p></td>
<td><p>18</p></td>
</tr>
<tr class="row-even"><td><p>First_Baseman</p></td>
<td><p>74.000000</p></td>
<td><p>213.109091</p></td>
<td><p>55</p></td>
</tr>
<tr class="row-odd"><td><p>Outfielder</p></td>
<td><p>73.010309</p></td>
<td><p>199.113402</p></td>
<td><p>194</p></td>
</tr>
<tr class="row-even"><td><p>Relief_Pitcher</p></td>
<td><p>74.374603</p></td>
<td><p>203.517460</p></td>
<td><p>315</p></td>
</tr>
<tr class="row-odd"><td><p>Second_Baseman</p></td>
<td><p>71.362069</p></td>
<td><p>184.344828</p></td>
<td><p>58</p></td>
</tr>
<tr class="row-even"><td><p>Shortstop</p></td>
<td><p>71.903846</p></td>
<td><p>182.923077</p></td>
<td><p>52</p></td>
</tr>
<tr class="row-odd"><td><p>Starting_Pitcher</p></td>
<td><p>74.719457</p></td>
<td><p>205.163636</p></td>
<td><p>221</p></td>
</tr>
<tr class="row-even"><td><p>Third_Baseman</p></td>
<td><p>73.044444</p></td>
<td><p>200.955556</p></td>
<td><p>45</p></td>
</tr>
</tbody>
</table>
<p>We can notice that the mean heights of first basemen are higher than that of second basemen. Thus, we may be tempted to conclude that <strong>first basemen are higher than second basemen</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This statement is called <strong>a hypothesis</strong>, because we do not know whether the fact is actually true or not.</p>
</div>
<p>However, it is not always obvious whether we can make this conclusion. From the discussion above we know that each mean has an associated confidence interval, and thus this difference can just be a statistical error. We need a more formal way to test our hypothesis.</p>
<p>Let‚Äôs compute confidence intervals separately for heights of first and second basemen:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Confidence</p></th>
<th class="head"><p>First Basemen</p></th>
<th class="head"><p>Second Basemen</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0.85</p></td>
<td><p>73.62..74.38</p></td>
<td><p>71.04..71.69</p></td>
</tr>
<tr class="row-odd"><td><p>0.90</p></td>
<td><p>73.56..74.44</p></td>
<td><p>70.99..71.73</p></td>
</tr>
<tr class="row-even"><td><p>0.95</p></td>
<td><p>73.47..74.53</p></td>
<td><p>70.92..71.81</p></td>
</tr>
</tbody>
</table>
<p>We can see that under no confidence the intervals overlap. That proves our hypothesis that first basemen are higher than second basemen.</p>
<p>More formally, the problem we are solving is to see if <strong>two probability distributions are the same</strong> or at least have the same parameters. Depending on the distribution, we need to use different tests for that. If we know that our distributions are normal, we can apply the <strong><a class="reference external" href="https://en.wikipedia.org/wiki/Student%27s_t-test">student t-test</a></strong>.</p>
<p>In the student t-test, we compute the so-called <strong>t-value</strong>, which indicates the difference between means, taking into account the variance. It is demonstrated that the t-value follows <strong>student distribution</strong>, which allows us to get the threshold value for a given confidence level <span class="math notranslate nohighlight">\(p\)</span> (this can be computed, or looked up in the numerical tables). We then compare the t-value to this threshold to approve or reject the hypothesis.</p>
<p>In Python, we can use the <strong>SciPy</strong> package, which includes <code class="docutils literal notranslate"><span class="pre">ttest_ind</span></code> function (in addition to many other useful statistical functions!). It computes the t-value for us, and also does the reverse lookup of the confidence p-value, so that we can just look at the confidence to draw the conclusion.</p>
<p>For example, our comparison between the heights of first and second basemen gives us the following results:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">ttest_ind</span>

<span class="n">tval</span><span class="p">,</span> <span class="n">pval</span> <span class="o">=</span> <span class="n">ttest_ind</span><span class="p">(</span>
  <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Role&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;First_Baseman&#39;</span><span class="p">,</span> 
  <span class="p">[</span><span class="s1">&#39;Height&#39;</span><span class="p">]],</span> 
  <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Role&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Designated_Hitter&#39;</span><span class="p">,</span> 
  <span class="p">[</span><span class="s1">&#39;Height&#39;</span><span class="p">]],</span> 
  <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;T-value = </span><span class="si">{</span><span class="n">tval</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="se">\n</span><span class="s2">P-value: </span><span class="si">{</span><span class="n">pval</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">T</span><span class="o">-</span><span class="n">value</span> <span class="o">=</span> <span class="mf">7.65</span>
<span class="n">P</span><span class="o">-</span><span class="n">value</span><span class="p">:</span> <span class="mf">9.137321189738925e-12</span>
</pre></div>
</div>
<p>In our case, the p-value is very low, meaning that there is strong evidence supporting that the first basemen are taller.</p>
<p>There are also different other types of hypotheses that we might want to test, for example:</p>
<ul class="simple">
<li><p>To prove that a given sample follows some distribution. In our case, we have assumed that heights are normally distributed, but that needs formal statistical verification.</p></li>
<li><p>To prove that a mean value of a sample corresponds to some predefined value.</p></li>
<li><p>To compare means of a number of samples (eg. what is the difference in happiness levels among different age groups).</p></li>
</ul>
</section>
<section id="law-of-large-numbers-and-central-limit-theorem">
<h2><span class="section-number">4.4.9. </span>Law of large numbers and central limit theorem<a class="headerlink" href="#law-of-large-numbers-and-central-limit-theorem" title="Permalink to this headline">#</a></h2>
<p>One of the reasons why normal distribution is so important is the so-called <strong>central limit theorem</strong>. Suppose we have a large sample of independent <span class="math notranslate nohighlight">\(N\)</span> values <span class="math notranslate nohighlight">\(X_1, ..., X_N\)</span>, sampled from any distribution with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Then, for sufficiently large <span class="math notranslate nohighlight">\(N\)</span> (in other words, when <span class="math notranslate nohighlight">\(N\to\infty\)</span>), the mean <span class="math notranslate nohighlight">\(\Sigma_iX_i\)</span> would be normally distributed, with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2/N\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Another way to interpret the central limit theorem is to say that regardless of distribution, when you compute the mean of a sum of any random variable values you end up with normal distribution.</p>
</div>
<p>From the central limit theorem, it also follows that when <span class="math notranslate nohighlight">\(N\to\infty\)</span>, the probability of the sample mean to be equal to <span class="math notranslate nohighlight">\(\mu\)</span> becomes <span class="math notranslate nohighlight">\(1\)</span>. This is known as <strong>the law of large numbers</strong>.</p>
</section>
<section id="covariance-and-correlation">
<h2><span class="section-number">4.4.10. </span>Covariance and correlation<a class="headerlink" href="#covariance-and-correlation" title="Permalink to this headline">#</a></h2>
<p>One of the things Data Science does is find relations between data. We say that two sequences <strong>correlate</strong> when they exhibit similar behavior at the same time, i.e. they either rise/fall simultaneously, or one sequence rises when another one falls and vice versa. In other words, there seems to be some relation between the two sequences.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Correlation does not necessarily indicate causal relationship between two sequences; sometimes both variables can depend on some external cause, or it can be purely by chance the two sequences correlate. However, strong mathematical correlation is a good indication that two variables are somehow connected.</p>
</div>
<p>Mathematically, the main concept that shows the relation between two random variables is <strong>covariance</strong>, which is computed like this: <span class="math notranslate nohighlight">\(Cov(X, Y) = **E**\[(X-E(X))(Y-E(Y))\]\)</span>. We compute the deviation of both variables from their mean values, and then the product of those deviations. If both variables deviate together, the product would always be a positive value, which would add up to positive covariance. If both variables deviate out of sync (i.e. one falls below average when another one rises above average), we will always get negative numbers, which will add up to negative covariance. If the deviations are not dependent, they will add up to roughly zero.</p>
<p>The absolute value of covariance does not tell us much about how large the correlation is, because it depends on the magnitude of actual values. To normalize it, we can divide covariance by the standard deviation of both variables, to get a <strong>correlation</strong>. The good thing is that correlation is always in the range of <span class="math notranslate nohighlight">\([-1,1]\)</span>, where <span class="math notranslate nohighlight">\(1\)</span> indicates a strong positive correlation between values, <span class="math notranslate nohighlight">\(-1\)</span> - strong negative correlation, and <span class="math notranslate nohighlight">\(0\)</span> - no correlation at all (variables are independent).</p>
<p><strong>Example</strong>: we can compute the correlation between weights and heights of baseball players from the dataset mentioned above:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">heights</span><span class="p">))</span>
</pre></div>
</div>
<p>As a result, we get the <strong>correlation matrix</strong> like this one:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span>        <span class="p">,</span> <span class="mf">0.52959196</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.52959196</span><span class="p">,</span> <span class="mf">1.</span>        <span class="p">]])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Correlation matrix <span class="math notranslate nohighlight">\(C\)</span> can be computed for any number of input sequences <span class="math notranslate nohighlight">\(S_1, ..., S_n\)</span>. The value of <span class="math notranslate nohighlight">\(C_{ij}\)</span> is the correlation between <span class="math notranslate nohighlight">\(S_i\)</span> and <span class="math notranslate nohighlight">\(S_j\)</span>, and diagonal elements are always <span class="math notranslate nohighlight">\(1\)</span> (which is also self-correlation of <span class="math notranslate nohighlight">\(S_i\)</span>).</p>
</div>
<p>In our case, the value <span class="math notranslate nohighlight">\(0.53\)</span> indicates that there is some correlation between the weight and height of a person. We can also make the scatter plot of one value against the other to see the relationship visually:</p>
<p><img alt="Relationship between weight and height" src="../../_images/weight-height-relationship.png" /></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>More examples of correlation and covariance can be found in <a class="reference internal" href="../../assignments/data-science/introduction-to-statistics-and-probability.html"><span class="doc std std-doc">accompanying notebook</span></a>.</p>
</div>
</section>
<section id="conclusion">
<h2><span class="section-number">4.4.11. </span>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">#</a></h2>
<p>In this section, we have learned:</p>
<ul class="simple">
<li><p>basic statistical properties of data, such as mean, variance, mode, and quartiles,</p></li>
<li><p>different distributions of random variables, including normal distribution,</p></li>
<li><p>how to find the correlation between different properties,</p></li>
<li><p>how to use sound apparatus of math and statistics in order to prove some hypotheses,</p></li>
<li><p>how to compute confidence intervals for a random variable given data sample.</p></li>
</ul>
<p>While this is definitely not an exhaustive list of topics that exist within probability and statistics, it should be enough to give you a good start on this course.</p>
</section>
<section id="your-turn">
<h2><span class="section-number">4.4.12. </span>Your turn! üöÄ<a class="headerlink" href="#your-turn" title="Permalink to this headline">#</a></h2>
<p>Use the sample code in the notebook to test another hypothesis:</p>
<ol class="simple">
<li><p>First basemen are older than second basemen</p></li>
<li><p>First basemen are taller than third basemen</p></li>
<li><p>Shortstops are taller than second basemen</p></li>
</ol>
<p>Task - <a class="reference internal" href="../../assignments/data-science/small-diabetes-study.html"><span class="doc std std-doc">Small diabetes study</span></a>.</p>
</section>
<section id="self-study">
<h2><span class="section-number">4.4.13. </span>Self study<a class="headerlink" href="#self-study" title="Permalink to this headline">#</a></h2>
<p>Probability and statistics are such a broad topic that it deserves their own course. If you are interested to go deeper into theory, you may want to continue reading some of the following books:</p>
<ol class="simple">
<li><p><a class="reference external" href="https://cims.nyu.edu/~cfgranda/">Carlos Fernandez-Granda</a> from New York University has great lecture notes <a class="reference external" href="https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf">Probability and Statistics for Data Science</a> (available online)</p></li>
<li><p><a class="reference external" href="https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/">Peter and Andrew Bruce. Practical Statistics for Data Scientists.</a> [<a class="reference external" href="https://github.com/andrewgbruce/statistics-for-data-scientists">sample code in R</a>].</p></li>
<li><p><a class="reference external" href="https://www.packtpub.com/product/statistics-for-data-science/9781788290678">James D. Miller. Statistics for Data Science</a> [<a class="reference external" href="https://github.com/PacktPublishing/Statistics-for-Data-Science">sample code in R</a>]</p></li>
</ol>
</section>
<section id="acknowledgments">
<h2><span class="section-number">4.4.14. </span>Acknowledgments<a class="headerlink" href="#acknowledgments" title="Permalink to this headline">#</a></h2>
<p>Thanks to Microsoft for creating the open-source course <a class="reference external" href="https://github.com/microsoft/Data-Science-For-Beginners">Data Science for Beginners</a>. It inspires the majority of the content in this chapter.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "open-academy/machine-learning",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./data-science/introduction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="defining-data.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">4.3. </span>Defining data</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../working-with-data/working-with-data.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Working with data</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Open Academy<br/>
  
      &copy; Copyright 2022-2022.<br/>
    <div class="extra_footer">
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> Text content of this work is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>