
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>36. Model training &amp; evaluation &#8212; Ocademy Open Machine Learning Book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/drawio.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/youtube.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "ocademy-ai/machine-learning-utterances");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "üí¨ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script src="https://wavedrom.com/skins/default.js"></script>
    <script src="https://wavedrom.com/wavedrom.min.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"></script>
    <script>quizdown.init({"quizdown_js": "https://cdn.jsdelivr.net/gh/bonartm/quizdown-js@latest/public/build/quizdown.js"});</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="37. Model deployment" href="model-deployment.html" />
    <link rel="prev" title="35. Data engineering" href="data-engineering.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint">Learn AI together, for free! At <a color='lightblue' href='https://ocademy.cc'><u style='color:lightblue;'>Ocademy</u></a>.</div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo-long.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Ocademy Open Machine Learning Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PREREQUISITES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../prerequisites/python-programming-introduction.html">
   1. Python programming introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../prerequisites/python-programming-basics.html">
   2. Python programming basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../prerequisites/python-programming-advanced.html">
   3. Python programming advanced
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATA SCIENCE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science/introduction/introduction.html">
   4. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/introduction/defining-data-science.html">
     4.1. Defining data science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/introduction/data-science-ethics.html">
     4.2. Data Science ethics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/introduction/defining-data.html">
     4.3. Defining data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/introduction/introduction-to-statistics-and-probability.html">
     4.4. Introduction to statistics and probability
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science/working-with-data/working-with-data.html">
   5. Working with data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/working-with-data/relational-databases.html">
     5.1. Relational databases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/working-with-data/non-relational-data.html">
     5.2. Non-relational data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/working-with-data/numpy.html">
     5.3. NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/working-with-data/pandas.html">
     5.4. Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/working-with-data/data-preparation.html">
     5.5. Data preparation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science/data-visualization/data-visualization.html">
   6. Data visualization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-visualization/visualization-distributions.html">
     6.1. Visualizing distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-visualization/visualization-proportions.html">
     6.2. Visualizing proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-visualization/visualization-relationships.html">
     6.3. Visualizing relationships: all about honey üçØ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-visualization/meaningful-visualizations.html">
     6.4. Making meaningful visualizations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science/data-science-lifecycle/data-science-lifecycle.html">
   7. Data Science lifecycle
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-lifecycle/introduction.html">
     7.1. Introduction to the Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-lifecycle/analyzing.html">
     7.2. Analyzing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-lifecycle/communication.html">
     7.3. Communication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../data-science/data-science-in-the-cloud/data-science-in-the-cloud.html">
   8. Data Science in the cloud
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-in-the-cloud/introduction.html">
     8.1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-in-the-cloud/the-low-code-no-code-way.html">
     8.2. The ‚Äúlow code/no code‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../data-science/data-science-in-the-cloud/the-azure-ml-sdk-way.html">
     8.3. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-science/data-science-in-the-wild.html">
   9. Data Science in the real world
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING BASICS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ml-fundamentals/ml-overview.html">
   10. Machine Learning overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml-fundamentals/regression/regression-models-for-machine-learning.html">
   11. Regression models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/regression/tools-of-the-trade.html">
     11.1. Tools of the trade
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/regression/managing-data.html">
     11.2. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/regression/linear-and-polynomial-regression.html">
     11.3. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/regression/loss-function.html">
     11.4. Stock Market Prediction Hands-On: Training a Linear Regression Model (1/6)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/regression/logistic-regression.html">
     11.10. Logistic regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml-fundamentals/build-a-web-app-to-use-a-machine-learning-model.html">
   12. Build a web app to use a Machine Learning model
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml-fundamentals/classification/getting-started-with-classification.html">
   13. Getting started with classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/classification/introduction-to-classification.html">
     13.1. Introduction to classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/classification/more-classifiers.html">
     13.2. More classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/classification/yet-other-classifiers.html">
     13.3. Yet other classifiers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-fundamentals/classification/applied-ml-build-a-web-app.html">
     13.4. Applied Machine Learning : build a web app
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ADVANCED MACHINE LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml-advanced/clustering/clustering-models-for-machine-learning.html">
   14. Clustering models for Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/clustering/introduction-to-clustering.html">
     14.1. Introduction to clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/clustering/k-means-clustering.html">
     14.2. K-Means clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml-advanced/ensemble-learning/getting-started-with-ensemble-learning.html">
   15. Getting started with ensemble learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/ensemble-learning/bagging.html">
     15.1. Bagging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/ensemble-learning/random-forest.html">
     15.2. Random forest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/ensemble-learning/feature-importance.html">
     15.3. Feature importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml-advanced/gradient-boosting/introduction-to-gradient-boosting.html">
   16. Introduction to Gradient Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/gradient-boosting/gradient-boosting.html">
     16.1. Gradient Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/gradient-boosting/gradient-boosting-example.html">
     16.2. Gradient boosting example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/gradient-boosting/xgboost.html">
     16.3. XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-advanced/gradient-boosting/xgboost-k-fold-cv-feature-importance.html">
     16.4. XGBoost + k-fold CV + Feature Importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml-advanced/unsupervised-learning.html">
   17. Unsupervised learning (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml-advanced/kernel-method.html">
   18. Kernel method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml-advanced/model-selection.html">
   19. Model selection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/dl-overview.html">
   20. Deep learning overview (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/cnn.html">
   21. Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/gan.html">
   22. Generative adversarial networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/rnn.html">
   23. Recurrent Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/autoencoder.html">
   24. Autoencoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/lstm.html">
   25. Long-short term memory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/time-series.html">
   26. Time series
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/dqn.html">
   27. Deep Q-learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/dl-summary.html">
   28. Summary of deep learning (TBD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/image-classification.html">
   29. Image classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/image-segmentation.html">
   30. Image segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/difussion-model.html">
   31. Diffusion Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-learning/object-detection.html">
   32. Object detection
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MACHINE LEARNING OPERATIONS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="overview.html">
   33. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="problem-framing.html">
   34. Problem framing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data-engineering.html">
   35. Data engineering
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   36. Model training &amp; evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model-deployment.html">
   37. Model deployment
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OTHERS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../assignments/README.html">
   38. Self-paced assignments
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/set-up-env/first-assignment.html">
     38.3. First assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/set-up-env/second-assignment.html">
     38.4. Second assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/project-plan-template.html">
     38.5. Project Plan‚Äã Template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/prerequisites/python-programming-introduction.html">
     38.6. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/prerequisites/python-programming-basics.html">
     38.7. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/prerequisites/python-programming-advanced.html">
     38.8. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/analyzing-text-about-data-science.html">
     38.9. Analyzing text about Data Science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/data-science-scenarios.html">
     38.10. Data Science scenarios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/write-a-data-ethics-case-study.html">
     38.11. Write a data ethics case study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/lines-scatters-and-bars.html">
     38.12. Lines, scatters and bars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/apply-your-skills.html">
     38.13. Apply your skills
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/try-it-in-excel.html">
     38.14. Try it in Excel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/dive-into-the-beehive.html">
     38.15. Dive into the beehive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/build-your-own-custom-vis.html">
     38.16. Build your own custom vis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/classifying-datasets.html">
     38.17. Classifying datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/small-diabetes-study.html">
     38.18. Small diabetes study
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/introduction-to-statistics-and-probability.html">
     38.19. Introduction to probability and statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/displaying-airport-data.html">
     38.20. Displaying airport data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/soda-profits.html">
     38.21. Soda profits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/analyzing-COVID-19-papers.html">
     38.22. Analyzing COVID-19 papers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/estimation-of-COVID-19-pandemic.html">
     38.23. Estimation of COVID-19 pandemic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/data-processing-in-python.html">
     38.24. Data processing in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/evaluating-data-from-a-form.html">
     38.25. Evaluating data from a form
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/data-preparation.html">
     38.26. Data preparation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/analyzing-data.html">
     38.27. Analyzing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/nyc-taxi-data-in-winter-and-summer.html">
     38.28. NYC taxi data in winter and summer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/matplotlib-applied.html">
     38.29. Matplotlib applied
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/tell-a-story.html">
     38.35. Tell a story
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/explore-a-planetary-computer-dataset.html">
     38.36. Explore a planetary computer dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/exploring-for-anwser.html">
     38.37. Exploring for answers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/market-research.html">
     38.38. Market research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/low-code-no-code-data-science-project-on-azure-ml.html">
     38.39. Low code/no code Data Science project on Azure ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/data-science-project-using-azure-ml-sdk.html">
     38.40. Data Science project using Azure ML SDK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/data-science/data-science-in-the-cloud-the-azure-ml-sdk-way.html">
     38.41. Data Science in the cloud: The ‚ÄúAzure ML SDK‚Äù way
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-overview-iris.html">
     38.42. Machine Learning overview - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-overview-mnist-digits.html">
     38.43. Machine Learning overview - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/regression-with-scikit-learn.html">
     38.44. Regression with Scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-linear-regression-1.html">
     38.45. ML linear regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-linear-regression-2.html">
     38.46. ML linear regression - assignment 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-logistic-regression-1.html">
     38.47. ML logistic regression - assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/ml-neural-network-1.html">
     38.48. ML neural network - Assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/regression-tools.html">
     38.49. Regression tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/managing-data.html">
     38.50. Managing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/exploring-visualizations.html">
     38.51. Exploring visualizations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/try-a-different-model.html">
     38.52. Try a different model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/create-a-regression-model.html">
     38.53. Create a regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/linear-and-polynomial-regression.html">
     38.54. Linear and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/retrying-some-regression.html">
     38.55. Retrying some regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/pumpkin-varieties-and-color.html">
     38.56. Pumpkin varieties and color
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/delicious-asian-and-indian-cuisines.html">
     38.57. Delicious asian and indian cuisines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/explore-classification-methods.html">
     38.58. Explore classification methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/kernel-method/kernel-method-assignment-1.html">
     38.59. Kernel method assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/kernel-method/support_vector_machines_for_regression.html">
     38.60. Support Vector Machines (SVM) - Intro and SVM for Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/kernel-method/support_vector_machines_for_classification.html">
     38.61. Support Vector Machines (SVM) - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/kernel-method/decision_trees_for_regression.html">
     38.62. Decision Trees - Intro and Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/kernel-method/decision_trees_for_classification.html">
     38.63. Decision Trees - Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/model-selection/model-selection-assignment-1.html">
     38.64. Model selection assignment 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/model-selection/learning-curve-to-identify-overfit-underfit.html">
     38.65. Learning Curve To Identify Overfit &amp; Underfit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/model-selection/dropout-and-batch-normalization.html">
     38.66. Dropout and Batch Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/model-selection/lasso-and-ridge-regression.html">
     38.67. Lasso and Ridge Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/model-selection/regularized-linear-models.html">
     38.68. Regularized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/ensemble-learning/random-forests-intro-and-regression.html">
     38.69. Random forests intro and regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/ensemble-learning/random-forests-for-classification.html">
     38.70. Random forests for classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/ensemble-learning/beyond-random-forests-more-ensemble-models.html">
     38.71. Beyond random forests: more ensemble models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/ensemble-learning/decision-trees.html">
     38.72. Decision trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/gradient-boosting/hyperparameter-tuning-gradient-boosting.html">
     38.73. Hyperparameter tuning gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/gradient-boosting/gradient-boosting-assignment.html">
     38.74. Gradient boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/gradient-boosting/boosting-with-tuning.html">
     38.75. Boosting with tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-advanced/ensemble-learning/random-forest-classifier-feature-importance.html">
     38.76. Random Forest Classifier with Feature Importance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/machine-learning-productionization/data-engineering.html">
     38.78. Data engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/machine-learning-productionization/counterintuitive-challenges-in-ml-debugging.html">
     38.79. Counterintuitive Challenges in ML Debugging
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/machine-learning-productionization/debugging-in-classification.html">
     38.80. Case Study: Debugging in Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/machine-learning-productionization/debugging-in-regression.html">
     38.81. Case Study: Debugging in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/study-the-solvers.html">
     38.82. Study the solvers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/build-classification-models.html">
     38.83. Build classification models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/build-classification-model.html">
     38.84. Build Classification Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/ml-fundamentals/parameter-play.html">
     38.85. Parameter play
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/cnn/how-to-choose-cnn-architecture-mnist.html">
     38.86. How to choose cnn architecture mnist
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/cnn/sign-language-digits-classification-with-cnn.html">
     38.88. Sign Language Digits Classification with CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/cnn/object-recognition-in-images-using-cnn.html">
     38.90. Object Recognition in Images using CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/tensorflow/intro_to_tensorflow_for_deeplearning.html">
     38.91. Intro to TensorFlow for Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/lstm/bitcoin-lstm-model-with-tweet-volume-and-sentiment.html">
     38.93. Bitcoin LSTM Model with Tweet Volume and Sentiment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/rnn/google-stock-price-prediction-rnn.html">
     38.95. Google Stock Price Prediction RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/autoencoder/autoencoder.html">
     38.97. Intro to Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/autoencoder/base-denoising-autoencoder-dimension-reduction.html">
     38.98. Base/Denoising Autoencoder &amp; Dimension Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/autoencoder/variational-autoencoder-and-faces-generation.html">
     38.99. Fun with Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/time-series-forecasting-assignment.html">
     38.100. Time Series Forecasting Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/nn-for-classification-assignment.html">
     38.102. Neural Networks for Classification with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/nn-classify-15-fruits-assignment.html">
     38.103. NN Classify 15 Fruits Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/dqn/dqn-on-foreign-exchange-market.html">
     38.108. DQN On Foreign Exchange Market
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/gan/art-by-gan.html">
     38.109. Art by gan
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/gan/gan-introduction.html">
     38.111. Generative Adversarial Networks (GANs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/deep-learning/overview/basic-classification-classify-images-of-clothing.html">
     38.112. Basic classification: Classify images of clothing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../slides/introduction.html">
   39. Slides
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/python-programming/python-programming-introduction.html">
     39.1. Python programming introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/python-programming/python-programming-basics.html">
     39.2. Python programming basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/python-programming/python-programming-advanced.html">
     39.3. Python programming advanced
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/data-science-introduction.html">
     39.4. Data Science introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/relational-vs-non-relational-database.html">
     39.5. Relational vs. non-relational database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/numpy-and-pandas.html">
     39.6. NumPy and Pandas
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/data-visualization.html">
     39.7. Data visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/data-science-lifecycle.html">
     39.8. Data Science lifecycle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/data-science-in-the-cloud.html">
     39.9. Data Science in the cloud
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/data-science/data-science-in-real-world.html">
     39.10. Data Science in real world
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-fundamentals/ml-overview.html">
     39.11. Machine Learning overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-fundamentals/linear-regression.html">
     39.12. Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-fundamentals/logistic-regression.html">
     39.13. Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-fundamentals/neural-network.html">
     39.14. Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-fundamentals/build-an-ml-web-app.html">
     39.15. Build an machine learning web application
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-advanced/unsupervised-learning.html">
     39.16. Unsupervised learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-advanced/kernel-method.html">
     39.17. Kernel method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/ml-advanced/model-selection.html">
     39.18. Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/deep-learning/cnn.html">
     39.19. Convolutional Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../slides/deep-learning/gan.html">
     39.20. Generative Adversarial Network
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ocademy-ai/machine-learning/release?urlpath=lab/tree/open-machine-learning-jupyter-book/machine-learning-productionization/model-training-and-evaluation.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ocademy-ai/machine-learning/blob/release/open-machine-learning-jupyter-book/machine-learning-productionization/model-training-and-evaluation.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning//issues/new?title=Issue%20on%20page%20%2Fmachine-learning-productionization/model-training-and-evaluation.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ocademy-ai/machine-learning/edit/release/open-machine-learning-jupyter-book/machine-learning-productionization/model-training-and-evaluation.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/machine-learning-productionization/model-training-and-evaluation.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="../_sources/machine-learning-productionization/model-training-and-evaluation.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-selection">
   36.1. Model selection
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-simple">
     36.1.1. Start simple
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transfer-learning">
     36.1.2. Transfer learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automl">
     36.1.3. AutoML
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-evaluation">
   36.2. Model evaluation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluate-quality-using-model-metrics">
     36.2.1. Evaluate quality using model metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-metrics-for-important-data-slices">
     36.2.2. Check metrics for important data slices
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#use-real-world-metrics">
     36.2.3. Use real-world metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimizing-and-satisficing-metrics">
     36.2.4. Optimizing and satisficing metrics
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-debugging-improvement">
   36.3. Model debugging &amp; improvement
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-and-feature-debugging">
     36.3.1. Data and feature debugging
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-debugging">
     36.3.2. Model debugging
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpreting-loss-curves">
     36.3.3. Interpreting loss curves
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-optimization">
   36.4. Model optimization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#add-useful-features">
     36.4.1. Add useful features
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tune-hyperparameters">
     36.4.2. Tune hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tune-model-depth-and-width">
     36.4.3. Tune model depth and width
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-turn">
   36.5. Your turn! üöÄ
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#self-study">
   36.6. Self study
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   36.7. Acknowledgments
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Model training & evaluation</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-selection">
   36.1. Model selection
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#start-simple">
     36.1.1. Start simple
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transfer-learning">
     36.1.2. Transfer learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automl">
     36.1.3. AutoML
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-evaluation">
   36.2. Model evaluation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluate-quality-using-model-metrics">
     36.2.1. Evaluate quality using model metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-metrics-for-important-data-slices">
     36.2.2. Check metrics for important data slices
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#use-real-world-metrics">
     36.2.3. Use real-world metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimizing-and-satisficing-metrics">
     36.2.4. Optimizing and satisficing metrics
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-debugging-improvement">
   36.3. Model debugging &amp; improvement
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-and-feature-debugging">
     36.3.1. Data and feature debugging
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-debugging">
     36.3.2. Model debugging
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpreting-loss-curves">
     36.3.3. Interpreting loss curves
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-optimization">
   36.4. Model optimization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#add-useful-features">
     36.4.1. Add useful features
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tune-hyperparameters">
     36.4.2. Tune hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tune-model-depth-and-width">
     36.4.3. Tune model depth and width
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-turn">
   36.5. Your turn! üöÄ
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#self-study">
   36.6. Self study
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#acknowledgments">
   36.7. Acknowledgments
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="model-training-evaluation">
<h1><span class="section-number">36. </span>Model training &amp; evaluation<a class="headerlink" href="#model-training-evaluation" title="Permalink to this headline">#</a></h1>
<p>Machine Learning modeling, including model selection, training, evaluation and debugging, is very important, but only a small component of the entire Machine Learning pipeline. Some might even argue that it‚Äôs the easiest component. Details of specific algorithms won‚Äôt be discussed in this section. Instead, we will focus on giving an overview picture of how to choose the right model for the problem.</p>
<section id="model-selection">
<h2><span class="section-number">36.1. </span>Model selection<a class="headerlink" href="#model-selection" title="Permalink to this headline">#</a></h2>
<p>Once problems are framed as one of the common Machine Learning tasks, the typical approaches to solve them can usually be located correspondingly. You should first figure out the category of the problem. Is it supervised or unsupervised? Or regression vs. classification? Does it require generation or only prediction? If it is the former, the models will have to be much harder to learn the latent space of the data. As a quick reference, such a <a class="reference internal" href="problem-framing.html#what-models-to-use"><span class="std std-ref">cheat sheet</span></a> could be helpful.</p>
<p>Note that the model selection also highly depends on how the business problem is defined. For the same problem area, such as a house price prediction task, different targets may result in choosing different Machine Learning models. It can be regression if the required output is raw numbers. But if the goal is to quantize the income into different brackets and predict the bracket, it becomes a classification problem. Similarly, unsupervised learning could be used to learn labels for the data, which could be then used for supervised learning.</p>
<p>Keep in mind that there could be many ways to frame a problem, and the better one could only be known after the chosen models are trained and evaluated. Even though there are hundreds of ways to select and train a Machine Learning model, it is always a good practice to start with simple data, simple feature engineering, and simple model. Besides, transfer learning could be leveraged to reduce the training time in the context of the neural network. Furthermore,¬†AutoML¬†helps to further save time spent from feature engineering to HPO tuning. We will discuss these three useful tricks for selecting models in detail.</p>
<section id="start-simple">
<h3><span class="section-number">36.1.1. </span>Start simple<a class="headerlink" href="#start-simple" title="Permalink to this headline">#</a></h3>
<p>When searching for a solution, the first goal is to find an effective simple approach for the task. This serves three major purposes.</p>
<ul class="simple">
<li><p>Focus on resolving the confidence about if the model could solve the problem, as additional complexity and potential bugs are avoided.</p></li>
<li><p>Speed up the project iteration, and more complex components could be gradually added and verified step by step.</p></li>
<li><p>At last, it is important to leverage the simplest solution to build up a reasonable baseline for further comparison with the comprehensive model.</p></li>
</ul>
<blockquote class="epigraph">
<div><p>If you think that machine learning will give you a 100% boost, then a heuristic will get you 50% of the way there.</p>
<p class="attribution">‚ÄîMartin Zinkevich, research scientist at Google</p>
</div></blockquote>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>Martin, Z. (n.d.). <a class="reference external" href="https://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf">Rules of machine learning: Best practices for ml engineering</a>.</p>
</div>
<p>Start simple is about the architecture overall, which does a decent job on the problem. One or more aspects from below could be considered.</p>
<ol class="simple">
<li><p>Simple data ‚Äì start with the partial dataset if necessary, and easy-to-understand features which are easy to be captured by the model.</p></li>
<li><p>Simple processing - start with no regularization, normalization or other data processing as they may introduce bugs.</p></li>
<li><p>Simple model ‚Äì start with a less complex model with sensible defaults, prove the feasibility, get a baseline, iterate and improve it gradually.</p></li>
<li><p>Simple problem - simplify the problem itself if possible, or achieve it in multiple steps or through several sub-problems.</p></li>
</ol>
<p>For example, to simply start a house pricing prediction problem, firstly you could consider the most relevant features or a small portion of the data to build a simple linear regression model to get a baseline. Then you could add more features or data to extend the model to a nonlinear model. Or you could try other regressors such as decision trees, ensembles, shallow to deeper neural networks, etc, depending on the type and volume of data.</p>
<p>Overall, there is no need to pursue the state-of-the-art approach or the most optimized performance at the very beginning. But it is necessary to keep the eyes on the trap of increasingly complex heuristics.</p>
</section>
<section id="transfer-learning">
<h3><span class="section-number">36.1.2. </span>Transfer learning<a class="headerlink" href="#transfer-learning" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Transfer_learning">Transfer learning</a> is a research problem in Machine Learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.</p>
<p>Using a large amount of data and tackling a completely new Machine Learning problem can be very challenging sometimes. Transfer learning could be the starting point if the simplified solution does not work or perform well. It allows utilizing knowledge(model) acquired (trained) for one task to solve other similar tasks.</p>
<p>What‚Äôs more, transfer learning is very commonly adopted in hot areas such as computer vision and natural language processing. It usually gives significantly better performance than training a simple model. And it is even a rare case to train a model from scratch in such areas. Instead, researchers and data scientists prefer starting from a pre-trained model that already learned general features and how to classify objects.</p>
<figure class="align-default" id="id2">
<img alt="../_images/transfer-learning.jpeg" class="bg-primary mb-1" src="../_images/transfer-learning.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 36.1 </span><span class="caption-text">Transfer learning<span id="id1">[<a class="reference internal" href="#id30" title="Ml | introduction to transfer learning. November 2019. URL: https://www.geeksforgeeks.org/ml-introduction-to-transfer-learning/ (visited on 2022-07-31).">int19</a>]</span></span><a class="headerlink" href="#id2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Traditionally, there are three major categories of transfer learning strategies and techniques based on the characteristics of the problem and the data. <strong>Inductive transfer learning</strong> is used if the domains are the same between the source and target, but the exact tasks are not. If the problems‚Äô domains are even different, <strong>transductive transfer learning</strong> could be the choice. <strong>Unsupervised transfer learning</strong> is similar to inductive transfer learning, but for unsupervised tasks with unlabeled datasets both in the source and target.</p>
<figure class="align-default" id="transfer-learning-strategies">
<img alt="../_images/transfer-learning-strategies.png" class="bg-primary mb-1" src="../_images/transfer-learning-strategies.png" />
<figcaption>
<p><span class="caption-number">Fig. 36.2 </span><span class="caption-text">Transfer learning strategies<span id="id3">[<a class="reference internal" href="#id31" title="What is transfer learning? [examples &amp; newbie-friendly guide]. URL: https://www.v7labs.com/blog/transfer-learning-guide, https://www.v7labs.com/blog/transfer-learning-guide (visited on 2022-07-31).">wha</a>]</span></span><a class="headerlink" href="#transfer-learning-strategies" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Under the deep learning context, there are multiple levels of complexity in using a pre-trained model. The most straightforward way is to use the pre-trained model directly, but may not be applicable mostly. An idea here is to leverage the pre-trained model‚Äôs weighted layers to extract features while retraining the last layer. One step further, a more engaging technique is to fine-tune and train all layers after starting with only the feature layers. If it still does not work, fully training all the layers will be the fallback.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference external" href="https://www.v7labs.com/blog/transfer-learning-guide">What is transfer learning? [Examples &amp; newbie-friendly guide]</a>. (n.d.). Retrieved 27 July 2022.</p>
</div>
</section>
<section id="automl">
<h3><span class="section-number">36.1.3. </span>AutoML<a class="headerlink" href="#automl" title="Permalink to this headline">#</a></h3>
<p>Automated Machine Learning(AutoML) provides methods and processes to make Machine Learning available for non-Machine Learning experts, to improve the efficiency of Machine Learning and accelerate research on Machine Learning. Designing and tuning Machine Learning systems is a labor and time-intensive task, and also requires extensive expertise. AutoML is focused on automating the model selection and training process.</p>
<p>As it is named, AutoML helps automate many aspects of Machine Learning model developments and training. It consists of a broader group of methodologies listed here:</p>
<ul class="simple">
<li><p>Automated Data Clean (Auto Clean)</p></li>
<li><p>Automated Feature Engineering (Auto FE)</p></li>
<li><p>Hyperparameter Optimization (HPO)</p></li>
<li><p>Meta-Learning</p></li>
<li><p>Neural Architecture Search (NAS)</p></li>
</ul>
<p>Today, there are plenty of AutoML tools existing. It is important to understand the strengths and weaknesses of each other before going deep with any of them. <a class="reference external" href="https://openml.github.io/automlbenchmark/index.html">AMLB</a> provides an open and extensible benchmark to help compare and choose the right AutoML frameworks.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>Hutter, Frank, Lars Kotthoff, and Joaquin Vanschoren. <a class="reference external" href="https://www.automl.org/book/">Automated machine learning: methods, systems, challenges</a>). Springer Nature, 2019.</p>
</div>
</section>
</section>
<section id="model-evaluation">
<h2><span class="section-number">36.2. </span>Model evaluation<a class="headerlink" href="#model-evaluation" title="Permalink to this headline">#</a></h2>
<p>In practice, it is challenging to detect if the model is properly learning without underfitting or overfitting. Ideally, before moving to production, it is always necessary to evaluate the trained model to make sure that everything is working properly. A common approach is to divide the dataset into three parts - training set, validation set and test set.</p>
<p>The model is trained by using only the train set, and the validation set is used to track the progress and conclude to optimize the model. Then the test set is used to evaluate the performance of the model. Using completely new data allows us to get an unbiased opinion on how well the algorithm works.</p>
<figure class="align-default" id="recommended-method-of-deviding-the-dataset">
<img alt="../_images/recommended-method-of-deviding-the-dataset.png" class="bg-primary mb-1" src="../_images/recommended-method-of-deviding-the-dataset.png" />
<figcaption>
<p><span class="caption-number">Fig. 36.3 </span><span class="caption-text">Recommended method of dividing the data set<span id="id4">[<a class="reference internal" href="#id29" title="Piotr Skalski. Preventing deep neural network from overfitting. February 2020. URL: https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a (visited on 2022-07-31).">Ska20</a>]</span></span><a class="headerlink" href="#recommended-method-of-deviding-the-dataset" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>There is no strict heuristic about how to split the dataset, especially when working with big data. The split ratios depend greatly on the specific problem and data volume. Generally speaking, the train vs. validation vs. test split should allow for:</p>
<ul class="simple">
<li><p>large enough validation set to compare the difference between models,</p></li>
<li><p>large enough test set to be representative of overall performance.</p></li>
</ul>
<p>However, while evaluating a Machine Learning model can seem daunting, model metrics show where to start. The following sections discuss how to evaluate performance using metrics.</p>
<section id="evaluate-quality-using-model-metrics">
<h3><span class="section-number">36.2.1. </span>Evaluate quality using model metrics<a class="headerlink" href="#evaluate-quality-using-model-metrics" title="Permalink to this headline">#</a></h3>
<p>To evaluate your model‚Äôs quality, commonly-used metrics are:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss">loss</a></p></li>
<li><p><a class="reference external" href="https://developers.google.com/machine-learning/crash-course/classification/accuracy">accuracy</a></p></li>
<li><p><a class="reference external" href="https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall">precision &amp; recall</a></p></li>
<li><p><a class="reference external" href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc">area under the ROC curve (AUC)</a></p></li>
</ul>
<p>For guidance on interpreting these metrics, read the linked content from Machine Learning Crash Content. For additional guidance on specific problems, see the following table.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Problem</p></th>
<th class="head"><p>Evaluating Quality</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Regression</p></td>
<td><p>Besides reducing the absolute¬†<a class="reference external" href="https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss">Mean Square Error</a>¬†(MSE), reduce the MSE relative to the label values. For example, assume to predict prices of two items that have mean prices of 5 and 100. In both cases, assume the MSE is 5. In the first case, the MSE is 100% of your mean price, which is clearly a large error. In the second case, the MSE is 5% of the mean price, which is a reasonable error.</p></td>
</tr>
<tr class="row-odd"><td><p>Multiclass classification</p></td>
<td><p>To predict a small number of classes, look at per-class metrics individually. When predicting on many classes, the per-class metrics can be leveraged to track overall classification metrics. Alternatively, specific quality goals can be prioritized depending on the needs. For example, if to classify objects in images, then the classification quality may be prioritized for people over other objects.</p></td>
</tr>
<tr class="row-even"><td><p>Ranking metrics</p></td>
<td><p>MRR, MAR, ordered logit</p></td>
</tr>
<tr class="row-odd"><td><p>Computer vision</p></td>
<td><p>IoU, Pixel Accuracy</p></td>
</tr>
<tr class="row-even"><td><p>NLP</p></td>
<td><p>Perplexity, BLEU, ROUGE</p></td>
</tr>
</tbody>
</table>
<p>Ideally, choose one single metric to optimize at once; if the requirement is to¬†include multiple metrics, then consider a unified metric.</p>
<p>However, since the real world does not always go as what is imagined, it may be the case to try many metrics before finding one that could be satisfied with, and the metrics may change alongside the development, or even after getting the model into production.</p>
</section>
<section id="check-metrics-for-important-data-slices">
<h3><span class="section-number">36.2.2. </span>Check metrics for important data slices<a class="headerlink" href="#check-metrics-for-important-data-slices" title="Permalink to this headline">#</a></h3>
<p>After having a high-quality model, the model might still perform poorly on subsets of the data. For example, the unicorn predictor must predict well both in the Sahara desert and in New York City, and at all times of the day. However, there is less training data for the Sahara desert. Therefore, it is necessary to track model quality specifically for the Sahara desert. Such subsets of data, like the subset corresponding to the Sahara desert, are called¬†<strong>data slices</strong>. Data slices should be separately monitored where performance is especially important or where the model might perform poorly.</p>
<p>Use the understanding of the data to identify data slices of interest. Then compare model metrics for data slices against the metrics for the entire data set. Checking that the model performs across all data slices helps remove bias. For more, see¬†<a class="reference external" href="https://developers.google.com/machine-learning/crash-course/fairness/evaluating-for-bias">Fairness: Evaluating for Bias</a>.</p>
</section>
<section id="use-real-world-metrics">
<h3><span class="section-number">36.2.3. </span>Use real-world metrics<a class="headerlink" href="#use-real-world-metrics" title="Permalink to this headline">#</a></h3>
<p>Model metrics do not necessarily measure the real-world impact of the model. For example, the AUC could be increased by changing a hyperparameter, but how did the change affect the user experience? To measure real-world impact, separate metrics need to be defined. Measuring real-world impact helps compare the quality of different iterations of the model.</p>
</section>
<section id="optimizing-and-satisficing-metrics">
<h3><span class="section-number">36.2.4. </span>Optimizing and satisficing metrics<a class="headerlink" href="#optimizing-and-satisficing-metrics" title="Permalink to this headline">#</a></h3>
<p>As models are getting bigger and more resource-intensive, how to scale the mode training becomes more and more important. Thinking beyond the above model metrics, the model utilitarian performance should also be considered. It includes the training speed, inference speed, model size, model stability, etc.</p>
<p>To the given example<span id="id5">[<a class="reference internal" href="#id28" title="Andrew Ng. Machine Learning Yearning. Online Draft, 2017. URL: https://github.com/ajaymache/machine-learning-yearning.">Ng17</a>]</span> below, both model accuracy and running time are important to decide which is the best classifier. It may not be natural to derive a single metric from them. Instead, a more real-world thinking-based strategy could be applied. The running time is important, but mostly it could be acceptable once under a certain value, such as 100ms. Whenever this condition is satisfied and the running time is good enough for production, then accuracy needs to be optimized with the best effort. Here, the running time is the satisficing metric and the accuracy is the optimizing metric.</p>
<figure class="align-default">
<img alt="../_images/optimizing-and-satisficing-metrics.png" src="../_images/optimizing-and-satisficing-metrics.png" />
</figure>
<p>Optimizing and satisficing metrics could also be applied to evaluate the model among different model metrics. As a final example, to build a natural language processing powered smart speakers device like Alexa, the wake word detection module is the key to support using a microphone to listen for the user saying a particular ‚Äúwake-word‚Äù to wake up the system, such as the ‚ÄúAlexa‚Äù for Amazon Echo.</p>
<p>The false positive rate is one of the key metrics, which is about the frequency of the system waking up even when no one says the wake-word. While the false negative rate describes how often it fails to wake up when someone says the¬†wake-word. It is difficult to optimize both of them at the same time. Instead, one reasonable way is to have the false negative rate as the optimizing¬†metric which needs to be minimized. And the false positive could be treated as the satisficing¬†metric, which should happen no more than once every 24 hours of operation.</p>
</section>
</section>
<section id="model-debugging-improvement">
<h2><span class="section-number">36.3. </span>Model debugging &amp; improvement<a class="headerlink" href="#model-debugging-improvement" title="Permalink to this headline">#</a></h2>
<p>Once the model is working, the next step is to optimize the model‚Äôs quality for production readiness. Both debugging and optimizing are critical in the Machine Learning pipeline.</p>
<p><strong>How is Machine Learning debugging different?</strong> Before diving into any particular Machine Learning debugging method, it is important to understand what differentiates debugging Machine Learning models from traditional software programs. Unlike the latter, an Machine Learning model with poor quality usually does not imply the presence of a bug. Instead, There could be many reasons to cause a model not to perform well. So that to debug poor performance in a model, a broader range of potential causes need to be investigated compared to traditional programming.</p>
<p>For example, here are a few causes for poor model performance:</p>
<ul class="simple">
<li><p>Theoretical constraints, such as wrong assumptions, unsuccessful problem framing, and poor model/data fit.</p></li>
<li><p>Data contains errors and anomalies or is over-preprocessed.</p></li>
<li><p>Features lack predictive power.</p></li>
<li><p>Poor feature engineering code contains bugs.</p></li>
<li><p>Poor model implementation.</p></li>
<li><p>Hyperparameters are set to nonoptimal values.</p></li>
</ul>
<p>Debugging Machine Learning models is complicated by the time it takes to run your experiments. Given the longer iteration cycles, and the larger error space, debugging Machine Learning models is uniquely challenging.</p>
<section id="data-and-feature-debugging">
<h3><span class="section-number">36.3.1. </span>Data and feature debugging<a class="headerlink" href="#data-and-feature-debugging" title="Permalink to this headline">#</a></h3>
<p>Low-quality data will significantly affect your model‚Äôs performance. It‚Äôs much easier to detect low-quality data at input instead of guessing at its existence after the model predicts badly. Monitor the data by following the advice in this section.</p>
<p><strong>Validate input data using rules.</strong></p>
<p>To monitor the data, one approach is to write rules that the data must satisfy, and continuously check the data against the expected <a class="reference external" href="#data-quality">data quality</a>. This collection of rules is defined by following these steps:</p>
<ol class="simple">
<li><p>For the feature data, understand the range and distribution. For categorical features, understand the set of possible values.</p></li>
<li><p>Encode the understanding into rules. Examples of rules are:</p>
<ol class="simple">
<li><p>Ensure that user-submitted ratings are always between 1 and 5.</p></li>
<li><p>Check that ‚Äúthe‚Äù occurs most frequently (for an English text feature).</p></li>
<li><p>Check that categorical features have values from a fixed set.</p></li>
</ol>
</li>
<li><p>Test the data against the rules which should catch data errors such as:</p>
<ol class="simple">
<li><p>anomalies.</p></li>
<li><p>unexpected values of categorical variables.</p></li>
<li><p>unexpected data distributions.</p></li>
</ol>
</li>
</ol>
<p><strong>Ensure splits are good quality.</strong></p>
<p>The test and training splits must be equally representative of the input data. If the test and training splits are statistically different, then training data will not help predict the test data. It‚Äôs often a struggle to gather enough data for a machine learning project. Sometimes, however, there is too much data, and a subset of examples must be selected for training.</p>
<p>Monitor the statistical properties of the splits. If the properties diverge, raise a flag. Further, test that the ratio of examples in each split stays constant. For example, if the data is split 80:20, that ratio should not change.</p>
<p><strong>Test processed data.</strong></p>
<p>While the raw data might be valid, the model only sees processed feature data. Because processed data looks very different from raw input data, it is necessary to check processed data separately. Based on the understanding of the processed data, write unit tests to verify if the data quality assurance is successfully applied through the data engineering process. For example, unit tests could check the following conditions:</p>
<ol class="simple">
<li><p>All numeric features are scaled, for example, between 0 and 1.</p></li>
<li><p>One-hot encoded vectors only contain a single 1 and N-1 zeroes.</p></li>
<li><p>Missing data is replaced by mean or default values.</p></li>
<li><p>Data distributions after transformation conform to expectations. For example, if the data is normalized by using z-scores, the mean of the z-scores is 0.</p></li>
<li><p>Outliers are handled, such as by scaling or clipping.</p></li>
</ol>
</section>
<section id="model-debugging">
<h3><span class="section-number">36.3.2. </span>Model debugging<a class="headerlink" href="#model-debugging" title="Permalink to this headline">#</a></h3>
<p>After debugging the data, follow these steps to continue debugging the model.</p>
<p><strong>Check that the model can predict labels.</strong></p>
<p>Before debugging the model, try to determine whether the features encode predictive signals. Linear correlations could be found between individual features and labels by using correlation matrices.</p>
<p>However, correlation matrices will not detect nonlinear correlations between features and labels. Instead, choose 10 examples from the dataset that the model can easily learn from. Alternatively, use synthetic data that is easily learnable. For instance, a classifier can easily learn linearly-separable examples while a regressor can easily learn labels that correlate highly with a <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#feature_cross">feature cross</a>. Then, ensure the model can achieve a very small loss on these 10 easily-learnable examples.</p>
<p>Then using a few examples that are easily learnable simplifies debugging by reducing the opportunities for bugs. If it does not work well, consider to further simplifying the model by switching to the simpler gradient descent algorithm instead of a more advanced optimization algorithm.</p>
<p><strong>Establish a baseline.</strong></p>
<p>Comparing the model against a baseline is a quick test of the model‚Äôs quality. When developing a new model, define a baseline by using <a class="reference external" href="#start-simple">a simple heuristic</a> to predict the label. If the trained model performs worse than its baseline, it needs to be improved.</p>
<p>Examples of baselines are:</p>
<ul class="simple">
<li><p>Using a linear model trained solely on the most predictive feature.</p></li>
<li><p>In classification, always predict the most common label.</p></li>
<li><p>In regression, always predicting the mean value.</p></li>
</ul>
<p>Once a version of the model is validated in production, it could be used as a baseline for newer model versions. Therefore, there could be multiple baselines of different complexities. Testing against baselines helps justify adding complexity to the model. A more complex model should always perform better than a less complex model or baseline.</p>
<p><strong>Implement tests for Machine Learning code.</strong></p>
<p>The testing process to catch bugs in Machine Learning code is similar to the testing process in traditional debugging. Unit tests could be added to detect bugs. Examples of code bugs in Machine Learning are:</p>
<ul class="simple">
<li><p>Hidden layers that are configured incorrectly.</p></li>
<li><p>Data normalization code that returns NaNs.</p></li>
</ul>
<p>A sanity check for the presence of code bugs is to include the label in the features and train the model. If the model does not work, then it has a bug.</p>
<p><strong>Adjust hyperparameter values.</strong></p>
<p>The table below explains how to adjust values for the hyperparameters.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Hyperparameter</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Learning Rate</p></td>
<td><p>Typically, ML libraries will automatically set the learning rate. For example, in TensorFlow, most TF Estimators use the¬†<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer">AdagradOptimizer</a>, which sets the learning rate at 0.05 and then adaptively modifies the learning rate during training. The other popular optimizer,¬†<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer">AdamOptimizer</a>, uses an initial learning rate of 0.001. However, if your model does not converge with the default values, then manually choose a value between 0.0001 and 1.0, and increase or decrease the value on a logarithmic scale until your model converges. Remember that the more difficult your problem, the more epochs your model must train for before loss starts to decrease.</p></td>
</tr>
<tr class="row-odd"><td><p>Regularization</p></td>
<td><p>First, ensure your model can predict without regularization on the training data. Then add regularization only if your model is overfitting on training data. Regularization methods differ for linear and nonlinear models.<br><br>For linear models, choose L1 regularization if you need to reduce your model‚Äôs size. Choose L2 regularization if you prefer increased model stability. Increasing your model‚Äôs stability makes your model training more reproducible. Find the correct value of the regularization rate, , by starting at 1e-5 and tuning that value through trial and error.<br><br>To regularize a deep neural network model, use <a class="reference external" href="https://developers.google.com/machine-learning/glossary/#dropout_regularization">Dropout regularization</a>. Dropout removes a random selection of a fixed percentage of the neurons in a network layer for a single gradient step. Typically, dropout will improve generalization at a dropout rate of between 10% and 50% of neurons.</p></td>
</tr>
<tr class="row-even"><td><p>Training epochs</p></td>
<td><p>You should train for at least one epoch, and continue to train so long as you are not overfitting.</p></td>
</tr>
<tr class="row-odd"><td><p>Batch size</p></td>
<td><p>Typically, the batch size of a¬†<a class="reference external" href="https://developers.google.com/machine-learning/glossary/#mini-batch">mini-batch</a>¬†is between 10 and 1000. For¬†<a class="reference external" href="https://developers.google.com/machine-learning/glossary/#SGD">SGD</a>, the batch size is 1. The upper bound on your batch size is limited by the amount of data that can fit in your machine‚Äôs memory. The lower bound on batch size depends on your data and algorithm. However, using a smaller batch size lets your gradient update more often per epoch, which can result in a larger decrease in loss per epoch. Furthermore, models trained using smaller batches generalize better. For details, see¬†<a class="reference external" href="https://arxiv.org/pdf/1609.04836.pdf">On large-batch training for deep learning: Generalization gap and sharp minima</a>¬†N. S. Keskar, D. Mudigere, J. Nocedal, M. Smelyanskiy, and P. T. P. Tang. ICLR, 2017. Prefer using the smallest batch sizes that result in stable training.</p></td>
</tr>
<tr class="row-even"><td><p>Depth and width of layers</p></td>
<td><p>In a neural network, depth refers to the number of layers, and width refers to the number of neurons per layer. Increase depth and width as the complexity of the corresponding problem increases. Adjust your depth and width by following these steps:<br><br>1. Start with 1 fully-connected hidden layer with the same width as your input layer.<br>2. For regression, set the output layer‚Äôs width to 1. For classification, set the output layer‚Äôs width to the number of classes.<br>3. If your model does not work, and you think your model needs to be deeper to learn your problem, then increase depth linearly by adding a fully-connected hidden layer at a time. The hidden layer‚Äôs width depends on your problem. A commonly-used approach is to use the same width as the previous hidden layer, and then discover the appropriate width through trial-and-error.<br><br>The change in width of successive layers also depends on your problem. A practice drawn from common observation is to set a layer‚Äôs width equal to or less than the width of the previous layer. Remember, the depth and width don‚Äôt have to be exactly right. You‚Äôll tune their values later when you optimize your model.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="interpreting-loss-curves">
<h3><span class="section-number">36.3.3. </span>Interpreting loss curves<a class="headerlink" href="#interpreting-loss-curves" title="Permalink to this headline">#</a></h3>
<p>Machine learning would be a breeze if all our¬†<a class="reference external" href="https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss">loss curves</a>¬†looked like this the first time we trained our model:</p>
<figure class="align-default">
<img alt="../_images/metric-curve-ideal.svg" src="../_images/metric-curve-ideal.svg" /></figure>
<p>But in reality, loss curves can be quite challenging to interpret. Use your understanding of loss curves to answer the following questions.</p>
<p><strong>1. My model won‚Äôt train!</strong></p>
<p>Your friend Mel and you continue working on a unicorn appearance predictor. Here‚Äôs your first loss curve.</p>
<figure class="align-default">
<img alt="../_images/metric-curve-ex03.svg" src="../_images/metric-curve-ex03.svg" /></figure>
<p>Your model is not converging. Try these debugging steps:</p>
<ul class="simple">
<li><p>Check if your features can predict the labels by following the steps in <a class="reference external" href="#model-debugging">Model debugging</a>.</p></li>
<li><p>Check your data against a rules to detect bad examples.</p></li>
<li><p>If training looks unstable, as in this plot, then reduce your learning rate to prevent the model from bouncing around in parameter space.</p></li>
<li><p>Simplify your dataset to 10 examples that you know your model can predict. Obtain a very low loss on the reduced dataset. Then continue debugging your model on the full dataset.</p></li>
<li><p>Simplify your model and ensure the model outperforms your baseline. Then incrementally add complexity to the model.</p></li>
</ul>
<p><strong>2. My loss exploded!</strong></p>
<p>Mel shows you another curve. What‚Äôs going wrong here and how can she fix it? Write your answer below.</p>
<figure class="align-default">
<img alt="../_images/metric-curve-ex02.svg" src="../_images/metric-curve-ex02.svg" /></figure>
<p>A large increase in loss is typically caused by anomalous values in input data. Possible causes are:</p>
<ul class="simple">
<li><p>NaNs in input data.</p></li>
<li><p>Exploding gradient due to anomalous data.</p></li>
<li><p>Division by zero.</p></li>
<li><p>Logarithm of zero or negative numbers.</p></li>
</ul>
<p>To fix an exploding loss, check for anomalous data in your batches, and in your engineered data. If the anomaly appears problematic, then investigate the cause. Otherwise, if the anomaly looks like outlying data, then ensure the outliers are evenly distributed between batches by shuffling your data.</p>
<p><strong>3. My metrics are contradictory!</strong></p>
<p>Mel wants your take on another curve. What‚Äôs going wrong and how can she fix it? Write your answer below.</p>
<figure class="align-default">
<img alt="../_images/metric-curve-ex04.svg" src="../_images/metric-curve-ex04.svg" /></figure>
<p>The recall is stuck at 0 because your examples‚Äô classification probability is never higher than the¬†<a class="reference external" href="https://developers.google.com/machine-learning/glossary#classification_threshold">threshold</a>¬†for positive classification. This situation often occurs in problems with a large¬†<a class="reference external" href="https://developers.google.com/machine-learning/glossary#class_imbalanced_data_set">class imbalance</a>. Remember that ML libraries, such as TF Keras, typically use a default threshold of 0.5 to calculate classification metrics.</p>
<p>Try these steps:</p>
<ul class="simple">
<li><p>Lower your classification threshold.</p></li>
<li><p>Check threshold-invariant metrics, such as AUC.</p></li>
</ul>
<p><strong>4. Testing loss is too damn high!</strong></p>
<p>Mel shows you the loss curves for training and testing datasets and asks ‚ÄúWhat‚Äôs wrong?‚Äù Write your answer below.</p>
<figure class="align-default">
<img alt="../_images/metric-curve-ex01.svg" src="../_images/metric-curve-ex01.svg" /></figure>
<p>Your model is overfitting to the training data. Try these steps:</p>
<ul class="simple">
<li><p>Reduce model capacity.</p></li>
<li><p>Add regularization.</p></li>
<li><p>Check that the training and test splits are statistically equivalent.</p></li>
</ul>
<p><strong>5. My model gets stuck.</strong></p>
<p>You‚Äôre patient when Mel returns a few days later with yet another curve. What‚Äôs going wrong here and how can Mel fix it?</p>
<figure class="align-default">
<img alt="../_images/metric-curve-ex05.svg" src="../_images/metric-curve-ex05.svg" /></figure>
<p>Your loss is showing repetitive, step-like behavior. The input data seen by your model probably is itself exhibiting repetitive behavior. Ensure that shuffling is removing repetitive behavior from input data.</p>
<p><strong>It‚Äôs working!</strong></p>
<p>‚ÄúIt‚Äôs working perfectly now!‚Äù Mel exclaims. She leans back into her chair triumphantly and heaves a big sigh. The curve looks great and you beam with accomplishment. Mel and you take a moment to discuss the following additional checks for validating your model.</p>
<ul class="simple">
<li><p>real-world metrics</p></li>
<li><p>baselines</p></li>
<li><p>absolute loss for regression problems</p></li>
<li><p>other metrics for classification problems</p></li>
</ul>
<figure class="align-default">
<img alt="../_images/metric-curve-ex06.svg" src="../_images/metric-curve-ex06.svg" /></figure>
</section>
</section>
<section id="model-optimization">
<h2><span class="section-number">36.4. </span>Model optimization<a class="headerlink" href="#model-optimization" title="Permalink to this headline">#</a></h2>
<p>Once the model is working, it‚Äôs time to optimize the model‚Äôs quality. Follow the steps below.</p>
<section id="add-useful-features">
<h3><span class="section-number">36.4.1. </span>Add useful features<a class="headerlink" href="#add-useful-features" title="Permalink to this headline">#</a></h3>
<p>The model performance could be improved by adding features that encode information not yet encoded by the existing features. Correlation matrices could be used to find linear correlations between individual features and labels. To detect nonlinear correlations between features and labels, the model must be trained with and without the feature, or combination of features, and check for an increase in model quality. The feature‚Äôs inclusion must be justified by an increase in model quality.</p>
</section>
<section id="tune-hyperparameters">
<h3><span class="section-number">36.4.2. </span>Tune hyperparameters<a class="headerlink" href="#tune-hyperparameters" title="Permalink to this headline">#</a></h3>
<p>Values of hyperparameters make your model work. However, these hyperparameter values can still be tuned. The values could be tuned manually by trial and error, but manual tuning is time-consuming. Instead, consider using an AutoML hyperparameter tuning service, such as¬†<a class="reference external" href="https://cloud.google.com/ml-engine/docs/tensorflow/hyperparameter-tuning-overview">Google Cloud Machine Learning hyperparameter tuning</a>, <a class="reference external" href="https://github.com/awslabs/autogluon">Auto Gluon</a>, etc. With different sets of hyperparameters, the same model may perform drastically differently on the same dataset. Keep in mind that not all hyperparameters are created equal. A model could be more sensitive to one hyperparameter.</p>
</section>
<section id="tune-model-depth-and-width">
<h3><span class="section-number">36.4.3. </span>Tune model depth and width<a class="headerlink" href="#tune-model-depth-and-width" title="Permalink to this headline">#</a></h3>
<p>While debugging the model, its depth and width are increased to improve the model performance In contrast, during model optimization, the mode depth and width could be either increased or decreased depending on the goals. If the model quality is adequate, then try reducing overfitting and training time by decreasing depth and width. Specifically, try halving the width at each successive layer. Since the model quality will also decrease, it is always a tradeoff to balance quality with overfitting and training time.</p>
<p>Conversely, if the goal is to have higher model quality, then try increasing depth and width. Remember that increases in depth and width are practically limited by accompanying increases in training time and overfitting. To understand overfitting.</p>
<p>Since depth and width are hyperparameters, hyperparameter tuning could be used to optimize depth and width.</p>
</section>
</section>
<section id="your-turn">
<h2><span class="section-number">36.5. </span>Your turn! üöÄ<a class="headerlink" href="#your-turn" title="Permalink to this headline">#</a></h2>
<p>Understanding the challenges in Machine Learning debugging by completing the <a class="reference internal" href="../assignments/machine-learning-productionization/counterintuitive-challenges-in-ml-debugging.html"><span class="doc std std-doc">Counterintuitive Challenges in ML Debugging</span></a>.</p>
<p>Apply the debugging concepts learned by completing the following:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../assignments/machine-learning-productionization/debugging-in-regression.html"><span class="doc std std-doc">Case Study: Debugging in Regression</span></a></p></li>
<li><p><a class="reference internal" href="../assignments/machine-learning-productionization/debugging-in-classification.html"><span class="doc std std-doc">Case Study: Debugging in Classification</span></a></p></li>
</ul>
</section>
<section id="self-study">
<h2><span class="section-number">36.6. </span>Self study<a class="headerlink" href="#self-study" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://blog.statsbot.co/machine-learning-algorithms-183cc73197c">Machine Learning Algorithms: Which One to Choose for Your Problem</a> by Daniil Korbut, Stats and Bots, 2017.</p></li>
</ul>
</section>
<section id="acknowledgments">
<h2><span class="section-number">36.7. </span>Acknowledgments<a class="headerlink" href="#acknowledgments" title="Permalink to this headline">#</a></h2>
<p>Thanks to Google for creating the open-source course <a class="reference external" href="https://developers.google.com/machine-learning/testing-debugging">Testing and Debugging in Machine Learning</a> which is licensed under <a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a>. It contributes to the majority of <a class="reference external" href="#model-evaluation">Model evaluation</a>, <a class="reference external" href="#model-deugging-improvement">Model debugging &amp; improvement</a>, <a class="reference external" href="#model-optimization">Model optimization</a>, and assignments.</p>
<p>Thanks to <a class="reference external" href="https://github.com/chiphuyen">&#64;chiphuyen</a> for creating the <a class="reference external" href="https://huyenchip.com/machine-learning-systems-design/toc.html">Machine Learning Systems Design</a> which inspires some of the contents in this section.</p>
<hr class="docutils" />
<div class="docutils container" id="id6">
<dl class="citation">
<dt class="label" id="id31"><span class="brackets"><a class="fn-backref" href="#id3">wha</a></span></dt>
<dd><p>What is transfer learning? [examples &amp; newbie-friendly guide]. URL: <a class="reference external" href="https://www.v7labs.com/blog/transfer-learning-guide, https://www.v7labs.com/blog/transfer-learning-guide">https://www.v7labs.com/blog/transfer-learning-guide, https://www.v7labs.com/blog/transfer-learning-guide</a> (visited on 2022-07-31).</p>
</dd>
<dt class="label" id="id30"><span class="brackets"><a class="fn-backref" href="#id1">int19</a></span></dt>
<dd><p>Ml | introduction to transfer learning. November 2019. URL: <a class="reference external" href="https://www.geeksforgeeks.org/ml-introduction-to-transfer-learning/">https://www.geeksforgeeks.org/ml-introduction-to-transfer-learning/</a> (visited on 2022-07-31).</p>
</dd>
<dt class="label" id="id28"><span class="brackets"><a class="fn-backref" href="#id5">Ng17</a></span></dt>
<dd><p>Andrew Ng. <em>Machine Learning Yearning</em>. Online Draft, 2017. URL: <a class="reference external" href="https://github.com/ajaymache/machine-learning-yearning">https://github.com/ajaymache/machine-learning-yearning</a>.</p>
</dd>
<dt class="label" id="id29"><span class="brackets"><a class="fn-backref" href="#id4">Ska20</a></span></dt>
<dd><p>Piotr Skalski. Preventing deep neural network from overfitting. February 2020. URL: <a class="reference external" href="https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a">https://towardsdatascience.com/preventing-deep-neural-network-from-overfitting-953458db800a</a> (visited on 2022-07-31).</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ocademy-ai/machine-learning",
            ref: "release",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./machine-learning-productionization"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
    <script type="text/javascript">
        function init() {
            WaveDrom.ProcessAll();
        }
        window.onload = init;
    </script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="data-engineering.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">35. </span>Data engineering</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="model-deployment.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">37. </span>Model deployment</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ocademy<br/>
  
      &copy; Copyright 2022-2023.<br/>
    <div class="extra_footer">
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> Text content of this work is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>